# NLP_project_36


Project 35. Recommender Systems  
This project aims to test various recommendation systems strategies utilizing collaborative filtering, item-user collaborative filtering and content-based filtering. Consider the Deskdrop dataset, which contains a set of shared articles (shared_articles.csv) and a set of interaction modes (users_interactions.csv), which include View, Like, Comment, Follow and Bookmark. The file can be accessed at Recommender Systems in Python 101 | Kaggle, where some initial coding for data handling is also available. In this case, the items correspond to the articles and the user rating can be created by utilizing the information about View, Like, Comment, Follow and Bookmark. 
1.	Instead of using the interpretation provided in the source code of the provided link, we shall interpret the ranking as follows: Ranking = 5 if there is a Like regardless the presence of other attributes. Ranking =4 if there is a Follow and Bookmark. Ranking =3 if there is Follow or Bookmark but not both of them. Ranking =2 is there is Comment and not (Bookmark or Follow or Like). Ranking =1 if there is View only. Write down a script that generates the user-item rating according to the previous construction. We shall consider only those users who rated at least three articles and ignore other users. Similarly, we shall consider only articles, which have been rated by at least two users. Finally, in order to evaluate the performance of various algorithms, perform a random 80%-20% split of original dataset between training and testing, respectively.
2.	Study the metrics Recall@N, which evaluates whether the interacted item is among the top N items in the ranked list of 101 recommendations for a user. See, also the NDCG@N, which takes into account the rank of the relevant item in the ranked list. The provided link Recommender Systems in Python 101 | Kaggle already include exemplifications of these. Inspire from the provided code to deliver an item related collaborative filtering implementation. Test the performance of the recommender system in terms of Recall@N and NDCG@N evaluations.
3.	Repeat 2) when using user-related collaborative filtering algorithm.
4.	Now we want to use the content of the comment section in the Deskdrop file as a guidelines for the recommendation. For this purpose, we first interpret the likeness and unlikeness using sentiment analysis. Use Vader sentiment analyzer to infer the aggregate sentiment score of each comment. Consider the vector carrying the ranting values and the vector carrying the corresponding sentiment score. Calculate Pearson correlation to find out whether the rankings are positively correlated with the sentiment scores.
5.	Consider the length of the comment text in terms of number of tokens it contains as an indicator variable. Write a script that generates this indicator variable and calculate Pearson correlation between rating vector and length indicator variable. 
6.	Consider another indicator, which consists of the proportion of the stopwords and uncommon characters in each comment text. Write a script that calculates this indicator variable and calculates its Pearson correlation with rating scores.
7.	Study the implementation in Recommender Systems in Python 101 | Kaggle where the content based filtering is built using tf-idf vector of the message content, we want to replace the tf-idf by a simple sentiment analyzer result using vader. Suggest a script that implements this paradigm and perform its evaluation using Recall@N and NDCG@N metrics.
8.	repeat 7) when the content of message is constituted by a vector corresponding to the concatenation of [Positive Sentiment score, Negative Sentiment Score, Length of the message, Ratio of stopwords /uncommon characters, Number of Personal Pronouns].   
9.	identify appropriate literature that comments on the findings in previous steps and discuss the limitation of overall approach.   
![image](https://github.com/MK473203/NLP_project_36/assets/118449659/9dc9b8dd-7546-43b1-91c3-a8264324aa98)
