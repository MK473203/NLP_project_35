{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sklearn\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import edit_distance as ed\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.sparse import csc_matrix, lil_matrix, csr_matrix\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "import torch\n",
    "#import torchtext\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv(\"shared_articles.csv\", delimiter= ',')\n",
    "interactions = pd.read_csv(\"users_interactions.csv\", delimiter= ',')\n",
    "comments = pd.read_csv(\"comments.csv\", delimiter= ',', usecols=[0, 1, 4])\n",
    "\n",
    "#print(articles.head(5))\n",
    "#print(interactions.head(5))\n",
    "#print(comments.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.229339528708928"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "#Pre-processing, labeling event ratings\n",
    "\n",
    "def pre_process(data, exists=True):\n",
    "\tif exists:\n",
    "\t\tdata = pd.read_csv('df.csv', delimiter= ',')\n",
    "\t\treturn(data)\n",
    "\telse: \n",
    "\t\tdata['eventRating'] = 0.0\n",
    "\t\tdf = data.groupby(by=['personId','contentId']).sum()\n",
    "\t\t\n",
    "\t\tfor _, row in df.iterrows():\n",
    "\t\t\tif \"LIKE\" in row['eventType']:\n",
    "\t\t\t\tdata.loc[(data['personId'] == row.name[0]) & (data['contentId'] == row.name[1]), 'eventRating'] = 5.0\n",
    "\t\t\telif \"FOLLOW\" in row['eventType'] and \"BOOKMARK\" in row['eventType']:\n",
    "\t\t\t\tdata.loc[(data['personId'] == row.name[0]) & (data['contentId'] == row.name[1]), 'eventRating'] = 4.0\n",
    "\t\t\telif \"FOLLOW\" in row['eventType'] or \"BOOKMARK\" in row['eventType']:\n",
    "\t\t\t\tdata.loc[(data['personId'] == row.name[0]) & (data['contentId'] == row.name[1]), 'eventRating'] = 3.0\n",
    "\t\t\telif \"COMMENT CREATED\" in row['eventType']:\n",
    "\t\t\t\tdata.loc[(data['personId'] == row.name[0]) & (data['contentId'] == row.name[1]), 'eventRating'] = 2.0\n",
    "\t\t\telif \"VIEW\" in row['eventType']:\n",
    "\t\t\t\tdata.loc[(data['personId'] == row.name[0]) & (data['contentId'] == row.name[1]), 'eventRating'] = 1.0\n",
    "\t\t\n",
    "\t\tdata.to_csv('df.csv')\n",
    "\t\treturn(data)\n",
    "\n",
    "#set to False if eventRatings has not been created yet\n",
    "interactions = pre_process(interactions, os.path.isfile(\"df.csv\"))\n",
    "np.mean(interactions[\"eventRating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users: 1895\n",
      "articles with at least 2 interactions: 2744\n",
      "users with at least 3 interactions: 1400\n",
      "number of interactions: 72312\n",
      "number of interactions from users with at least 3 interactions: 71244\n",
      "number of interactions users with at least 3 interactions and with articles of at least 2 interactions 70849\n",
      "num articles: 2760\n",
      "number of of unique user/item interactions: 1400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>contentId</th>\n",
       "      <th>-9222795471790223670</th>\n",
       "      <th>-9216926795620865886</th>\n",
       "      <th>-9194572880052200111</th>\n",
       "      <th>-9192549002213406534</th>\n",
       "      <th>-9190737901804729417</th>\n",
       "      <th>-9189659052158407108</th>\n",
       "      <th>-9176143510534135851</th>\n",
       "      <th>-9171475473795142532</th>\n",
       "      <th>-9166778629773133902</th>\n",
       "      <th>-9161596996229760398</th>\n",
       "      <th>...</th>\n",
       "      <th>9191014301634017491</th>\n",
       "      <th>9207286802575546269</th>\n",
       "      <th>9208127165664287660</th>\n",
       "      <th>9209629151177723638</th>\n",
       "      <th>9209886322932807692</th>\n",
       "      <th>9213260650272029784</th>\n",
       "      <th>9215261273565326920</th>\n",
       "      <th>9217155070834564627</th>\n",
       "      <th>9220445660318725468</th>\n",
       "      <th>9222265156747237864</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-9223121837663643404</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9212075797126931087</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9207251133131336884</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9199575329909162940</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9196668942822132778</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9188188261933657343</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9172914609055320039</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9156344805277471150</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9120685872592674274</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9109785559521267180</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9083704948999852989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9063420486253202900</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9060214117327732109</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9048557723087354030</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9047547311469006438</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9016528795238256703</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9009798162809551896</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-9001583565812478106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8994220765455693336</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-8985529623369322698</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 2744 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "contentId             -9222795471790223670  -9216926795620865886   \n",
       "personId                                                           \n",
       "-9223121837663643404                     0                     0  \\\n",
       "-9212075797126931087                     0                     0   \n",
       "-9207251133131336884                     0                     5   \n",
       "-9199575329909162940                     0                     0   \n",
       "-9196668942822132778                     0                     0   \n",
       "-9188188261933657343                     0                     0   \n",
       "-9172914609055320039                     0                     0   \n",
       "-9156344805277471150                     0                     0   \n",
       "-9120685872592674274                     0                     0   \n",
       "-9109785559521267180                     0                     0   \n",
       "-9083704948999852989                     0                     0   \n",
       "-9063420486253202900                     0                     0   \n",
       "-9060214117327732109                     0                     0   \n",
       "-9048557723087354030                     0                     0   \n",
       "-9047547311469006438                     0                     0   \n",
       "-9016528795238256703                     0                     0   \n",
       "-9009798162809551896                     0                     0   \n",
       "-9001583565812478106                     0                     0   \n",
       "-8994220765455693336                     0                     0   \n",
       "-8985529623369322698                     0                     0   \n",
       "\n",
       "contentId             -9194572880052200111  -9192549002213406534   \n",
       "personId                                                           \n",
       "-9223121837663643404                     0                     0  \\\n",
       "-9212075797126931087                     0                     0   \n",
       "-9207251133131336884                     0                     0   \n",
       "-9199575329909162940                     0                     0   \n",
       "-9196668942822132778                     0                     0   \n",
       "-9188188261933657343                     0                     0   \n",
       "-9172914609055320039                     0                     0   \n",
       "-9156344805277471150                     0                     0   \n",
       "-9120685872592674274                     0                     0   \n",
       "-9109785559521267180                     0                     0   \n",
       "-9083704948999852989                     0                     0   \n",
       "-9063420486253202900                     0                     0   \n",
       "-9060214117327732109                     0                     0   \n",
       "-9048557723087354030                     0                     0   \n",
       "-9047547311469006438                     0                     0   \n",
       "-9016528795238256703                     0                     1   \n",
       "-9009798162809551896                     0                     0   \n",
       "-9001583565812478106                     0                     1   \n",
       "-8994220765455693336                     0                     0   \n",
       "-8985529623369322698                     0                     0   \n",
       "\n",
       "contentId             -9190737901804729417  -9189659052158407108   \n",
       "personId                                                           \n",
       "-9223121837663643404                     0                     0  \\\n",
       "-9212075797126931087                     0                     0   \n",
       "-9207251133131336884                     0                     0   \n",
       "-9199575329909162940                     0                     0   \n",
       "-9196668942822132778                     0                     0   \n",
       "-9188188261933657343                     0                     0   \n",
       "-9172914609055320039                     0                     0   \n",
       "-9156344805277471150                     0                     0   \n",
       "-9120685872592674274                     0                     0   \n",
       "-9109785559521267180                     0                     0   \n",
       "-9083704948999852989                     0                     0   \n",
       "-9063420486253202900                     0                     0   \n",
       "-9060214117327732109                     0                     0   \n",
       "-9048557723087354030                     0                     0   \n",
       "-9047547311469006438                     0                     0   \n",
       "-9016528795238256703                     0                     0   \n",
       "-9009798162809551896                     0                     0   \n",
       "-9001583565812478106                     0                     0   \n",
       "-8994220765455693336                     0                     0   \n",
       "-8985529623369322698                     0                     0   \n",
       "\n",
       "contentId             -9176143510534135851  -9171475473795142532   \n",
       "personId                                                           \n",
       "-9223121837663643404                     0                     0  \\\n",
       "-9212075797126931087                     0                     0   \n",
       "-9207251133131336884                     0                     0   \n",
       "-9199575329909162940                     0                     0   \n",
       "-9196668942822132778                     0                     0   \n",
       "-9188188261933657343                     0                     0   \n",
       "-9172914609055320039                     0                     0   \n",
       "-9156344805277471150                     0                     0   \n",
       "-9120685872592674274                     0                     0   \n",
       "-9109785559521267180                     0                     0   \n",
       "-9083704948999852989                     0                     0   \n",
       "-9063420486253202900                     0                     0   \n",
       "-9060214117327732109                     0                     0   \n",
       "-9048557723087354030                     0                     0   \n",
       "-9047547311469006438                     0                     0   \n",
       "-9016528795238256703                     1                     0   \n",
       "-9009798162809551896                     0                     0   \n",
       "-9001583565812478106                     0                     0   \n",
       "-8994220765455693336                     0                     0   \n",
       "-8985529623369322698                     0                     0   \n",
       "\n",
       "contentId             -9166778629773133902  -9161596996229760398  ...   \n",
       "personId                                                          ...   \n",
       "-9223121837663643404                     0                     0  ...  \\\n",
       "-9212075797126931087                     0                     0  ...   \n",
       "-9207251133131336884                     0                     0  ...   \n",
       "-9199575329909162940                     0                     0  ...   \n",
       "-9196668942822132778                     0                     0  ...   \n",
       "-9188188261933657343                     0                     0  ...   \n",
       "-9172914609055320039                     0                     0  ...   \n",
       "-9156344805277471150                     0                     0  ...   \n",
       "-9120685872592674274                     0                     0  ...   \n",
       "-9109785559521267180                     0                     0  ...   \n",
       "-9083704948999852989                     0                     0  ...   \n",
       "-9063420486253202900                     0                     0  ...   \n",
       "-9060214117327732109                     0                     0  ...   \n",
       "-9048557723087354030                     0                     0  ...   \n",
       "-9047547311469006438                     0                     0  ...   \n",
       "-9016528795238256703                     0                     0  ...   \n",
       "-9009798162809551896                     0                     0  ...   \n",
       "-9001583565812478106                     0                     0  ...   \n",
       "-8994220765455693336                     0                     0  ...   \n",
       "-8985529623369322698                     0                     0  ...   \n",
       "\n",
       "contentId              9191014301634017491   9207286802575546269   \n",
       "personId                                                           \n",
       "-9223121837663643404                     0                     0  \\\n",
       "-9212075797126931087                     0                     0   \n",
       "-9207251133131336884                     0                     0   \n",
       "-9199575329909162940                     0                     0   \n",
       "-9196668942822132778                     0                     0   \n",
       "-9188188261933657343                     0                     0   \n",
       "-9172914609055320039                     0                     0   \n",
       "-9156344805277471150                     0                     0   \n",
       "-9120685872592674274                     0                     0   \n",
       "-9109785559521267180                     0                     0   \n",
       "-9083704948999852989                     0                     0   \n",
       "-9063420486253202900                     0                     0   \n",
       "-9060214117327732109                     0                     0   \n",
       "-9048557723087354030                     0                     0   \n",
       "-9047547311469006438                     0                     0   \n",
       "-9016528795238256703                     0                     1   \n",
       "-9009798162809551896                     0                     0   \n",
       "-9001583565812478106                     0                     0   \n",
       "-8994220765455693336                     0                     0   \n",
       "-8985529623369322698                     0                     0   \n",
       "\n",
       "contentId              9208127165664287660   9209629151177723638   \n",
       "personId                                                           \n",
       "-9223121837663643404                     0                     0  \\\n",
       "-9212075797126931087                     0                     0   \n",
       "-9207251133131336884                     0                     0   \n",
       "-9199575329909162940                     0                     0   \n",
       "-9196668942822132778                     0                     0   \n",
       "-9188188261933657343                     0                     0   \n",
       "-9172914609055320039                     0                     0   \n",
       "-9156344805277471150                     0                     0   \n",
       "-9120685872592674274                     0                     0   \n",
       "-9109785559521267180                     0                     0   \n",
       "-9083704948999852989                     0                     0   \n",
       "-9063420486253202900                     0                     0   \n",
       "-9060214117327732109                     0                     0   \n",
       "-9048557723087354030                     0                     0   \n",
       "-9047547311469006438                     0                     0   \n",
       "-9016528795238256703                     0                     0   \n",
       "-9009798162809551896                     0                     0   \n",
       "-9001583565812478106                     0                     0   \n",
       "-8994220765455693336                     0                     0   \n",
       "-8985529623369322698                     0                     0   \n",
       "\n",
       "contentId              9209886322932807692   9213260650272029784   \n",
       "personId                                                           \n",
       "-9223121837663643404                     0                     0  \\\n",
       "-9212075797126931087                     0                     0   \n",
       "-9207251133131336884                     0                     0   \n",
       "-9199575329909162940                     0                     0   \n",
       "-9196668942822132778                     0                     0   \n",
       "-9188188261933657343                     0                     0   \n",
       "-9172914609055320039                     0                     0   \n",
       "-9156344805277471150                     0                     0   \n",
       "-9120685872592674274                     0                     0   \n",
       "-9109785559521267180                     0                     0   \n",
       "-9083704948999852989                     0                     0   \n",
       "-9063420486253202900                     0                     0   \n",
       "-9060214117327732109                     0                     0   \n",
       "-9048557723087354030                     0                     0   \n",
       "-9047547311469006438                     0                     0   \n",
       "-9016528795238256703                     0                     0   \n",
       "-9009798162809551896                     0                     0   \n",
       "-9001583565812478106                     0                     0   \n",
       "-8994220765455693336                     0                     0   \n",
       "-8985529623369322698                     0                     0   \n",
       "\n",
       "contentId              9215261273565326920   9217155070834564627   \n",
       "personId                                                           \n",
       "-9223121837663643404                     0                     0  \\\n",
       "-9212075797126931087                     0                     0   \n",
       "-9207251133131336884                     0                     0   \n",
       "-9199575329909162940                     0                     0   \n",
       "-9196668942822132778                     0                     0   \n",
       "-9188188261933657343                     0                     0   \n",
       "-9172914609055320039                     0                     0   \n",
       "-9156344805277471150                     0                     0   \n",
       "-9120685872592674274                     0                     0   \n",
       "-9109785559521267180                     0                     0   \n",
       "-9083704948999852989                     0                     0   \n",
       "-9063420486253202900                     0                     0   \n",
       "-9060214117327732109                     0                     0   \n",
       "-9048557723087354030                     0                     0   \n",
       "-9047547311469006438                     0                     0   \n",
       "-9016528795238256703                     0                     0   \n",
       "-9009798162809551896                     0                     0   \n",
       "-9001583565812478106                     0                     0   \n",
       "-8994220765455693336                     0                     0   \n",
       "-8985529623369322698                     0                     0   \n",
       "\n",
       "contentId              9220445660318725468   9222265156747237864  \n",
       "personId                                                          \n",
       "-9223121837663643404                     0                     0  \n",
       "-9212075797126931087                     0                     0  \n",
       "-9207251133131336884                     0                     0  \n",
       "-9199575329909162940                     0                     0  \n",
       "-9196668942822132778                     0                     0  \n",
       "-9188188261933657343                     0                     0  \n",
       "-9172914609055320039                     0                     0  \n",
       "-9156344805277471150                     0                     0  \n",
       "-9120685872592674274                     0                     0  \n",
       "-9109785559521267180                     0                     0  \n",
       "-9083704948999852989                     0                     0  \n",
       "-9063420486253202900                     0                     0  \n",
       "-9060214117327732109                     0                     0  \n",
       "-9048557723087354030                     0                     0  \n",
       "-9047547311469006438                     0                     0  \n",
       "-9016528795238256703                     0                     0  \n",
       "-9009798162809551896                     0                     0  \n",
       "-9001583565812478106                     0                     0  \n",
       "-8994220765455693336                     0                     0  \n",
       "-8985529623369322698                     0                     0  \n",
       "\n",
       "[20 rows x 2744 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "#function that filters dataset according to wanted number of user and article interactions and computes popularity ranking of given set \n",
    "def filter_df(data, articles, user_interactions_at_least, article_interactions_at_least, pivot=True):\n",
    "\n",
    "    #Selecting articles and users with enough interactions\n",
    "    users_interactions_count = data.groupby(['personId', 'contentId']).size().groupby('personId').size()\n",
    "    print('number of users:', len(users_interactions_count))\n",
    "    users_with_enough_interactions_df = users_interactions_count[users_interactions_count >= user_interactions_at_least].reset_index()[['personId']]\n",
    "\n",
    "    article_interactions_count = data.groupby(['personId', 'contentId']).size().groupby('contentId').size()\n",
    "    articles_with_enough_interactions_df = article_interactions_count[article_interactions_count >= article_interactions_at_least].reset_index()[['contentId']]\n",
    "\n",
    "    print(\"articles with at least\", article_interactions_at_least, \"interactions:\", len(articles_with_enough_interactions_df))\n",
    "    print(\"users with at least\", user_interactions_at_least, \"interactions:\", len(users_with_enough_interactions_df))\n",
    "    print('number of interactions:', len(data))\n",
    "    interactions_from_selected_users_df = data.merge(users_with_enough_interactions_df, \n",
    "                how = 'right',\n",
    "                left_on = 'personId',\n",
    "                right_on = 'personId')\n",
    "    print('number of interactions from users with at least 3 interactions:', len(interactions_from_selected_users_df))\n",
    "\n",
    "\n",
    "    interactions_from_selected_users_df = interactions_from_selected_users_df.merge(articles_with_enough_interactions_df, \n",
    "                how = 'right',\n",
    "                left_on = 'contentId',\n",
    "                right_on = 'contentId')\n",
    "    print(\"number of interactions users with at least 3 interactions and with articles of at least 2 interactions\", len(interactions_from_selected_users_df))\n",
    "\n",
    "    #article_interactions_count = data.groupby(['personId', 'contentId']).size().groupby('contentId').size()\n",
    "    #articles_with_enough_interactions_df = article_interactions_count[article_interactions_count >= article_interactions_at_least].reset_index()[['contentId']]\n",
    "    articles_fil = articles[articles['contentId'].isin(articles_with_enough_interactions_df['contentId'])]\n",
    "    print(\"num articles:\", len(articles_fil))\n",
    "\n",
    "    #select unique item/user interactions\n",
    "    if  pivot==False:\n",
    "        #interactions_filtered = interactions_from_selected_users_df.groupby(['personId', 'contentId'])['eventRating'].sum().reset_index() \n",
    "        interactions_filtered = interactions_from_selected_users_df[['personId', 'contentId','eventRating']].drop_duplicates()\n",
    "        #item_popularity = interactions_selected.groupby('contentId')['eventRating'].sum().sort_values(ascending=False).reset_index()\n",
    "    else:\n",
    "        interactions_df =interactions_from_selected_users_df[['personId', 'contentId','eventRating']]\n",
    "        interactions_filtered = interactions_from_selected_users_df[['personId', 'contentId','eventRating']]\n",
    "        interactions_filtered = interactions_filtered.pivot_table(index='personId', columns='contentId', values='eventRating', fill_value=0)\n",
    "    \n",
    "    item_popularity = []\n",
    "\n",
    "    print('number of of unique user/item interactions:', len(interactions_filtered))\n",
    "\n",
    "    return(interactions_filtered, interactions_df, articles_fil)\n",
    "\n",
    "interactions_selected, interactions_df, articles = filter_df(data=interactions, articles=articles, user_interactions_at_least=3, article_interactions_at_least=2, pivot=True)  \n",
    "interactions_selected.head(20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True ...  True  True  True]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "user_ids = list(interactions_selected.index)\n",
    "content_ids = list(interactions_selected.T.index)\n",
    "#mask = np.random.rand(len(interactions_selected)) < 0.8\n",
    "#train_set = interactions_selected[mask] \n",
    "#test_set = interactions_selected[~mask] \n",
    "\n",
    "#test_set.head(10)\n",
    "print(user_ids==interactions_selected.index.unique().values)\n",
    "len(interactions_selected.index.unique().values)\n",
    "\n",
    "print(885269153482673496 in content_ids)\n",
    "#print(len(user_ids), ((interactions_df[interactions_df[\"personId\"]].drop_duplicates)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 56679\n",
      "Test set size: 14170\n",
      "[]\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#indexing by personId\n",
    "pre_processed_data_index = interactions_df.set_index('personId')\n",
    "#pre_processed_data_index = interactions_selected\n",
    "\n",
    "#train-test split\n",
    "train_set, test_set = train_test_split(interactions_df,  stratify=interactions_df['personId'], train_size=0.80)\n",
    "train_set_index = train_set.set_index('personId')\n",
    "test_set_index = test_set.set_index('personId')\n",
    "\n",
    "#train_set_index = train_set\n",
    "#test_set_index = test_set\n",
    "\n",
    "\n",
    "print('Train set size:', len(train_set))\n",
    "print('Test set size:', len(test_set))\n",
    "af=[0 for i in range(0, len(list(test_set_index.index.unique().values))) if not (list(test_set_index.index.unique().values))[i] in user_ids]\n",
    "print(af)\n",
    "print((885269153482673496 in train_set.index.unique().values))\n",
    "885269153482673496 in interactions_df['personId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.neighbors import NearestNeighbors\n",
    "#knn = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "#knn.fit(train_set)\n",
    "#distances, indices = knn.kneighbors(test_set, n_neighbors=101)\n",
    "\n",
    "#indices[0][0]\n",
    "#test_set.iloc[[0,2,3]]\n",
    "\n",
    "#idx = test_set.index.get_loc(-8802075878443651241)\n",
    "#nearest_rows = indices[idx]\n",
    "#print(idx)\n",
    "#print(np.max(nearest_rows))\n",
    "#print(interactions_selected[-9216926795620865886])\n",
    "\n",
    "#interactions_selected.corrwith(interactions_selected[-9216926795620865886]).sort_values(ascending=False).head(10)\n",
    "#user_id = -8802075878443651241\n",
    "#user_list = interactions[interactions['personId'] == user_id]\n",
    "#highest_rated_item = user_list[user_list['eventRating'] == max(user_list['eventRating'])]['contentId'].iloc[0]\n",
    "#print(movie_id)\n",
    "\n",
    "\n",
    "#print(list(range(len(interactions_selected[\"personId\"]))))\n",
    "#item_matrix_sparse = csr_matrix(interactions_selected.T)\n",
    "#user_matrix_sparse = csr_matrix(interactions_selected)\n",
    "\n",
    "#users = dict(zip(user_ids, list(range(len(interactions_df[\"personId\"])))))\n",
    "#contents = dict(zip(content_ids, list(range(len(interactions_df[\"contentId\"])))))\n",
    "#users_inv = dict(zip(list(range(len(interactions_df[\"personId\"]))), user_ids))\n",
    "#contents_inv = dict(zip(list(range(len(interactions_df[\"contentId\"]))), content_ids))\n",
    "\n",
    "#def find_similar(id, matrix, dictionary, dictionary_inv, k):\n",
    "#     \n",
    "#    neighbour_ids = []\n",
    "#     \n",
    " #   idx = dictionary[id]\n",
    "  #  vec = matrix[idx]\n",
    "#    k+=1\n",
    "#    kNN = NearestNeighbors(n_neighbors=k, algorithm=\"brute\", metric='cosine')\n",
    "#    kNN.fit(matrix)\n",
    "#    vec = vec.reshape(1,-1)\n",
    "#    neighbour = kNN.kneighbors(vec, return_distance=False)\n",
    "#    for i in range(0,k):\n",
    "#        n = neighbour.item(i)\n",
    "#        neighbour_ids.append(dictionary_inv[n])\n",
    "#    neighbour_ids.pop(0)\n",
    "#    return neighbour_ids\n",
    "\n",
    "#similar_ids = find_similar(content_id, item_matrix_sparse, contents, contents_inv, 10)\n",
    "#print(similar_ids)\n",
    "\n",
    "#tm= train_set_index.pivot_table(index='personId', columns='contentId', values='eventRating', fill_value=0)\n",
    "#tm.head(10)\n",
    "\n",
    "#kNN = NearestNeighbors(n_neighbors=k, algorithm=\"brute\", metric='cosine')\n",
    "#kNN.fit(matrix)\n",
    "\n",
    "def find_similar(self, id, matrix, dictionary, dictionary_inv, k):\n",
    "     \n",
    "        neighbour_ids = []\n",
    "        idx = dictionary.get(id)\n",
    "        #print(\"item name:\", id, \"item dict index:\", idx)\n",
    "        vec = matrix[idx]\n",
    "        k+=1\n",
    "        kNN = NearestNeighbors(n_neighbors=k, algorithm=\"brute\", metric='cosine')\n",
    "        kNN.fit(matrix)\n",
    "        vec = vec.reshape(1,-1)\n",
    "        neighbour = kNN.kneighbors(vec, return_distance=False)\n",
    "        for i in range(0,k):\n",
    "            n = neighbour.item(i)\n",
    "            neighbour_ids.append(dictionary_inv.get(n))\n",
    "        neighbour_ids.pop(0)\n",
    "        return neighbour_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>contentId</th>\n",
       "      <th>eventRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50241</th>\n",
       "      <td>9210530975708218054</td>\n",
       "      <td>3660989387512978561</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50226</th>\n",
       "      <td>9210530975708218054</td>\n",
       "      <td>3660989387512978561</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22078</th>\n",
       "      <td>1493119272824026132</td>\n",
       "      <td>-3678789633202302491</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22077</th>\n",
       "      <td>1493119272824026132</td>\n",
       "      <td>-3678789633202302491</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22076</th>\n",
       "      <td>1493119272824026132</td>\n",
       "      <td>-3678789633202302491</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10540</th>\n",
       "      <td>-3992639648918314515</td>\n",
       "      <td>-6590819806697898649</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>-3992639648918314515</td>\n",
       "      <td>-6590819806697898649</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53082</th>\n",
       "      <td>-3203894957285229214</td>\n",
       "      <td>4428409432282393251</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37156</th>\n",
       "      <td>-9016528795238256703</td>\n",
       "      <td>569574447134368517</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37155</th>\n",
       "      <td>-9016528795238256703</td>\n",
       "      <td>569574447134368517</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  personId            contentId  eventRating\n",
       "50241  9210530975708218054  3660989387512978561          5.0\n",
       "50226  9210530975708218054  3660989387512978561          5.0\n",
       "22078  1493119272824026132 -3678789633202302491          5.0\n",
       "22077  1493119272824026132 -3678789633202302491          5.0\n",
       "22076  1493119272824026132 -3678789633202302491          5.0\n",
       "...                    ...                  ...          ...\n",
       "10540 -3992639648918314515 -6590819806697898649          5.0\n",
       "10541 -3992639648918314515 -6590819806697898649          5.0\n",
       "53082 -3203894957285229214  4428409432282393251          5.0\n",
       "37156 -9016528795238256703   569574447134368517          5.0\n",
       "37155 -9016528795238256703   569574447134368517          5.0\n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class CFrecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Collaborative Filtering'\n",
    "    \n",
    "    def __init__(self, items=None, item_based=True):\n",
    "        self.item_matrix_sparse = csr_matrix(interactions_selected.T)\n",
    "        self.user_matrix_sparse = csr_matrix(interactions_selected)\n",
    "\n",
    "        self.users = dict(zip(user_ids, list(range(len(user_ids)))))\n",
    "        self.contents = dict(zip(content_ids, list(range(len(content_ids)))))\n",
    "        self.users_inv = dict(zip(list(range(len(user_ids))), user_ids))\n",
    "        self.contents_inv = dict(zip(list(range(len(content_ids))), content_ids))\n",
    "\n",
    "        self.item_based = item_based\n",
    "        self.items = items\n",
    "\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "    \n",
    "    def find_similar(self, id, matrix, dictionary, dictionary_inv, k):\n",
    "     \n",
    "        neighbour_ids = []\n",
    "        idx = dictionary.get(id)\n",
    "        #print(\"item name:\", id, \"item dict index:\", idx)\n",
    "        vec = matrix[idx]\n",
    "        k+=1\n",
    "        kNN = NearestNeighbors(n_neighbors=k, algorithm=\"brute\", metric='cosine')\n",
    "        kNN.fit(matrix)\n",
    "        vec = vec.reshape(1,-1)\n",
    "        neighbour = kNN.kneighbors(vec, return_distance=False)\n",
    "        for i in range(0,k):\n",
    "            n = neighbour.item(i)\n",
    "            neighbour_ids.append(dictionary_inv.get(n))\n",
    "        neighbour_ids.pop(0)\n",
    "        return neighbour_ids\n",
    "    \n",
    "    def users_highest_item(self, user_id):\n",
    "        user_list = interactions_df[interactions_df['personId'] == user_id]\n",
    "        highest_rated_item = user_list[user_list['eventRating'] == max(user_list['eventRating'])]['contentId'].iloc[0]\n",
    "        #print(highest_rated_item) \n",
    "        return(highest_rated_item)\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=101, verbose=False):\n",
    "\n",
    "        if self.item_based:\n",
    "            #find users highest rated item, then find similar items to it using cosine similarity\n",
    "            similar_item_to = self.users_highest_item(user_id)\n",
    "            recommended_items = self.find_similar(id=similar_item_to, matrix=self.item_matrix_sparse, dictionary=self.contents, dictionary_inv=self.contents_inv, k=topn)\n",
    "            recommendations = interactions_df[interactions_df['contentId'].isin(recommended_items)]\n",
    "\n",
    "        else:\n",
    "            #find similar users using cosine similarity, then find highest rated item for each highest rating user\n",
    "            similar_user_to = self.find_similar(id=user_id, matrix=self.user_matrix_sparse, dictionary=self.users, dictionary_inv=self.users_inv, k=topn)\n",
    "            recommended_items = [self.users_highest_item(user) for user in similar_user_to]\n",
    "            recommendations = interactions_df[interactions_df['contentId'].isin(recommended_items)]\n",
    "\n",
    "        #sort recommended items based on event rating\n",
    "        #print(len(recommendations))\n",
    "        #sorted_user_predictions = recommendations.sort_values(ascending=False).reset_index()\n",
    "\n",
    "        # Recommend the highest predicted rating items that user has not interacted with\n",
    "        #print(recommendations)\n",
    "        recommendations_df = recommendations[~recommendations['contentId'].isin(items_to_ignore)].sort_values(by='eventRating', ascending = False).head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items, how = 'left', \n",
    "                                                          left_on = 'contentId', \n",
    "                                                          right_on = 'contentId')[['eventRating', 'contentId', 'title', 'url', 'lang']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "\n",
    "#users = dict(zip(user_ids, list(range(len(interactions_df[\"personId\"])))))    \n",
    "#print(users.get(list(test_set.T.index)[0]))    \n",
    "user_recommender_model = CFrecommender(items=articles, item_based=False)\n",
    "item_recommender_model = CFrecommender(items=articles, item_based=True)\n",
    "item_recommender_model.recommend_items(-9016528795238256703)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recall_n:\n",
    "\n",
    "    def get_items_interacted(self, person_id, interactions_dat):\n",
    "        # Get the user's data and merge in the movie information.\n",
    "        interacted_items = interactions_dat.loc[person_id]['contentId']\n",
    "        return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])\n",
    "\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=12):\n",
    "        interacted_items = self.get_items_interacted(person_id, pre_processed_data_index)\n",
    "        all_items = set(articles['contentId'])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(list(non_interacted_items), sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):        \n",
    "            try:\n",
    "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "            except:\n",
    "                index = -1\n",
    "            hit = int(index in range(0, topn))\n",
    "            return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        #Getting the items in test set\n",
    "        interacted_values_testset = test_set_index.loc[person_id]\n",
    "        if type(interacted_values_testset['contentId']) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset['contentId'])\n",
    "        else:\n",
    "            person_interacted_items_testset = set([int(interacted_values_testset['contentId'])])  \n",
    "        interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "        #Getting a ranked recommendation list from a model for a given user\n",
    "        #print(person_id)\n",
    "        person_recs_df = model.recommend_items(person_id, \n",
    "                                               items_to_ignore=self.get_items_interacted(person_id, train_set_index), topn=1000)\n",
    "\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        #For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            #Getting a random sample (100) items the user has not interacted \n",
    "            #(to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n",
    "                                                                          sample_size=101, \n",
    "                                                                          seed=item_id%(2**32))\n",
    "\n",
    "            #Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            #Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['contentId'].isin(items_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['contentId'].values\n",
    "            #Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        #Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
    "        #when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {'hits@5_count':hits_at_5_count, \n",
    "                          'hits@10_count':hits_at_10_count, \n",
    "                          'interacted_count': interacted_items_count_testset,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        #print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(list(test_set_index.index.unique().values)):\n",
    "            #print(len(list(test_set_index.index.unique().values)), len(user_ids))\n",
    "            #if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)  \n",
    "            person_metrics['_person_id'] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics).sort_values('interacted_count', ascending=False)\n",
    "        \n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "recall_n_evaluator = Recall_n() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NDCG:\n",
    "\n",
    "    def dcg_at_k(self, r, k, method=0):\n",
    "        \"\"\"Score is discounted cumulative gain (dcg)\n",
    "        Relevance is positive real values.  Can use binary\n",
    "        as the previous methods.\n",
    "        Example from\n",
    "        http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "        >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "        >>> dcg_at_k(r, 1)\n",
    "        3.0\n",
    "        >>> dcg_at_k(r, 1, method=1)\n",
    "        3.0\n",
    "        >>> dcg_at_k(r, 2)\n",
    "        5.0\n",
    "        >>> dcg_at_k(r, 2, method=1)\n",
    "        4.2618595071429155\n",
    "        >>> dcg_at_k(r, 10)\n",
    "        9.6051177391888114\n",
    "        >>> dcg_at_k(r, 11)\n",
    "        9.6051177391888114\n",
    "        Args:\n",
    "            r: Relevance scores (list or numpy) in rank order\n",
    "                (first element is the first item)\n",
    "            k: Number of results to consider\n",
    "            method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                    If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "        Returns:\n",
    "            Discounted cumulative gain\n",
    "        \"\"\"\n",
    "        r = np.asfarray(r)[:k]\n",
    "        if r.size:\n",
    "            if method == 0:\n",
    "                return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "            elif method == 1:\n",
    "                return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "            else:\n",
    "                raise ValueError('method must be 0 or 1.')\n",
    "        return 0.\n",
    "\n",
    "\n",
    "    def ndcg_at_k(self, r, k, method=0):\n",
    "        \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
    "        Relevance is positive real values.  Can use binary\n",
    "        as the previous methods.\n",
    "        Example from\n",
    "        http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "        >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "        >>> ndcg_at_k(r, 1)\n",
    "        1.0\n",
    "        >>> r = [2, 1, 2, 0]\n",
    "        >>> ndcg_at_k(r, 4)\n",
    "        0.9203032077642922\n",
    "        >>> ndcg_at_k(r, 4, method=1)\n",
    "        0.96519546960144276\n",
    "        >>> ndcg_at_k([0], 1)\n",
    "        0.0\n",
    "        >>> ndcg_at_k([1], 2)\n",
    "        1.0\n",
    "        Args:\n",
    "            r: Relevance scores (list or numpy) in rank order\n",
    "                (first element is the first item)\n",
    "            k: Number of results to consider\n",
    "            method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                    If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "        Returns:\n",
    "            Normalized discounted cumulative gain\n",
    "        \"\"\"\n",
    "        dcg_max = self.dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "        if not dcg_max:\n",
    "            return 0.\n",
    "        return self.dcg_at_k(r, k, method) / dcg_max\n",
    "    \n",
    "    def get_items_interacted(self, person_id, interactions_dat):\n",
    "        # Get the user's data and merge in the movie information.\n",
    "        interacted_items = interactions_dat.loc[person_id]['contentId']\n",
    "        return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id, k):\n",
    "        #Getting the items in test set\n",
    "        interacted_values_testset = test_set_index.loc[person_id]\n",
    "        if type(interacted_values_testset['contentId']) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset['contentId'])\n",
    "        else:\n",
    "            person_interacted_items_testset = set([int(interacted_values_testset['contentId'])])  \n",
    "        interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "        #Getting a ranked recommendation list from a model for a given user\n",
    "\n",
    "        personal_recommendations = model.recommend_items(person_id, items_to_ignore=self.get_items_interacted(person_id, train_set_index), topn=101)\n",
    "        ndcg = self.ndcg_at_k(personal_recommendations['eventRating'], k)\n",
    "\n",
    "        random.seed(12)\n",
    "        personal_recommendations_rand = random.sample(list(interactions_df['eventRating']), 1000)\n",
    "        ndcg_rand = self.ndcg_at_k(personal_recommendations_rand, k)\n",
    "\n",
    "        person_metrics = {'ndcg':ndcg,\n",
    "                          'ndcg_rand': ndcg_rand,\n",
    "                          'comp_rand': (ndcg-ndcg_rand),\n",
    "                          'interacted_count': interacted_items_count_testset}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model, k):\n",
    "            #print('Running evaluation for users')\n",
    "            people_metrics = []\n",
    "            for idx, person_id in enumerate(list(test_set_index.index.unique().values)):\n",
    "                person_metrics = self.evaluate_model_for_user(model, person_id, k)  \n",
    "                person_metrics['_person_id'] = person_id\n",
    "                people_metrics.append(person_metrics)\n",
    "            print('%d users processed' % idx)\n",
    "\n",
    "            detailed_results_df = pd.DataFrame(people_metrics).sort_values('interacted_count', ascending=False)\n",
    "            ndcg = detailed_results_df['ndcg'].sum() / len(detailed_results_df)\n",
    "            ndcg_comp = detailed_results_df['comp_rand'].sum() / len(detailed_results_df)\n",
    "            global_metrics = {'modelName': model.get_model_name(),\n",
    "                            'ndcg': ndcg,\n",
    "                            'ndcg_comp': ndcg_comp}    \n",
    "            return global_metrics, detailed_results_df    \n",
    "\n",
    "recall_ndcg_evaluator = NDCG() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-based recommendation model: Recall_N:\n",
      "1355 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Collaborative Filtering', 'recall@5': 0.0177035490605428, 'recall@10': 0.023215031315240085}\n",
      "Item-based recommendation model: NDCG:\n",
      "1355 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Collaborative Filtering', 'ndcg': 1.0, 'ndcg_comp': 0.5174000115547485}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_rand</th>\n",
       "      <th>comp_rand</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>_person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>258</td>\n",
       "      <td>3609194402293569455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>258</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>232</td>\n",
       "      <td>-1443636648652872475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>187</td>\n",
       "      <td>-2626634673110551643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>137</td>\n",
       "      <td>-3596626804281480007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>118</td>\n",
       "      <td>2416280733544962613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>117</td>\n",
       "      <td>3636910968448833585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>116</td>\n",
       "      <td>-2979881261169775358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>108</td>\n",
       "      <td>3302556033962996625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>103</td>\n",
       "      <td>-9016528795238256703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ndcg  ndcg_rand  comp_rand  interacted_count           _person_id\n",
       "0     1.0     0.4826     0.5174               258  3609194402293569455\n",
       "36    1.0     0.4826     0.5174               258 -1032019229384696495\n",
       "106   1.0     0.4826     0.5174               232 -1443636648652872475\n",
       "83    1.0     0.4826     0.5174               187 -2626634673110551643\n",
       "97    1.0     0.4826     0.5174               137 -3596626804281480007\n",
       "42    1.0     0.4826     0.5174               118  2416280733544962613\n",
       "60    1.0     0.4826     0.5174               117  3636910968448833585\n",
       "95    1.0     0.4826     0.5174               116 -2979881261169775358\n",
       "18    1.0     0.4826     0.5174               108  3302556033962996625\n",
       "2     1.0     0.4826     0.5174               103 -9016528795238256703"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating Item-based model\n",
    "\n",
    "print('Item-based recommendation model: Recall_N:')\n",
    "pop_global_metrics, pop_detailed_results_df = recall_n_evaluator.evaluate_model(item_recommender_model)\n",
    "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\n",
    "pop_detailed_results_df.head(10)\n",
    "\n",
    "print('Item-based recommendation model: NDCG:')\n",
    "pop_global_metrics, pop_detailed_results_df = recall_ndcg_evaluator.evaluate_model(item_recommender_model, k=101)\n",
    "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\n",
    "pop_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based recommendation model: Recall_N:\n",
      "1355 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Collaborative Filtering', 'recall@5': 0.014029227557411273, 'recall@10': 0.015949895615866388}\n",
      "User-based recommendation model: NDCG:\n",
      "1355 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Collaborative Filtering', 'ndcg': 1.0, 'ndcg_comp': 0.5174000115547485}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_rand</th>\n",
       "      <th>comp_rand</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>_person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>258</td>\n",
       "      <td>3609194402293569455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>258</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>232</td>\n",
       "      <td>-1443636648652872475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>187</td>\n",
       "      <td>-2626634673110551643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>137</td>\n",
       "      <td>-3596626804281480007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>118</td>\n",
       "      <td>2416280733544962613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>117</td>\n",
       "      <td>3636910968448833585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>116</td>\n",
       "      <td>-2979881261169775358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>108</td>\n",
       "      <td>3302556033962996625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>103</td>\n",
       "      <td>-9016528795238256703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ndcg  ndcg_rand  comp_rand  interacted_count           _person_id\n",
       "0     1.0     0.4826     0.5174               258  3609194402293569455\n",
       "36    1.0     0.4826     0.5174               258 -1032019229384696495\n",
       "106   1.0     0.4826     0.5174               232 -1443636648652872475\n",
       "83    1.0     0.4826     0.5174               187 -2626634673110551643\n",
       "97    1.0     0.4826     0.5174               137 -3596626804281480007\n",
       "42    1.0     0.4826     0.5174               118  2416280733544962613\n",
       "60    1.0     0.4826     0.5174               117  3636910968448833585\n",
       "95    1.0     0.4826     0.5174               116 -2979881261169775358\n",
       "18    1.0     0.4826     0.5174               108  3302556033962996625\n",
       "2     1.0     0.4826     0.5174               103 -9016528795238256703"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('User-based recommendation model: Recall_N:')\n",
    "pop_global_metrics, pop_detailed_results_df = recall_n_evaluator.evaluate_model(user_recommender_model)\n",
    "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\n",
    "pop_detailed_results_df.head(10)\n",
    "\n",
    "print('User-based recommendation model: NDCG:')\n",
    "pop_global_metrics, pop_detailed_results_df = recall_ndcg_evaluator.evaluate_model(user_recommender_model, k=101)\n",
    "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\n",
    "pop_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-6\n",
    "# Function for generating and plotting pearson correlation scores\n",
    "\n",
    "\"\"\"\n",
    "\tTakes two item-user matrices and calculates pearson correlation first on a per-user basis and plots them. \n",
    "\tThen the correlation scores are averaged to see if there is a more global correlation between the two scoring systems.\n",
    "\n",
    "\tAssumes that the rows represent items (documents) and the columns represent users \n",
    "\tand that the rows and columns are in the same order between the matrices\n",
    "\"\"\"\n",
    "def pearson_analyze(M1, M2):\n",
    "\tcorrelations = []\n",
    "\tp_scores = []\n",
    "\n",
    "\tfor col_index in range(M1.get_shape()[1]):\n",
    "\t\tuser_vec_1 = M1.getcol(col_index).toarray().flatten()\n",
    "\t\tuser_vec_2 = M2.getcol(col_index).toarray().flatten()\n",
    "\n",
    "\t\t# Documents the user hasn't interacted with should not affect the correlation\n",
    "\t\tnonzero_elements = [user_vec_1[i] != 0 and user_vec_2[i] != 0 for i, _ in enumerate(user_vec_1)]\n",
    "\n",
    "\t\tuser_vec_1 = user_vec_1[nonzero_elements]\n",
    "\t\tuser_vec_2 = user_vec_2[nonzero_elements]\n",
    "\n",
    "\t\tif len(user_vec_1) < 2 or len(user_vec_2) < 2:\n",
    "\t\t\tcorrelations += [np.nan]\n",
    "\t\t\tp_scores += [np.nan]\n",
    "\t\telse:\n",
    "\t\t\tresult = pearsonr(user_vec_1, user_vec_2)\n",
    "\t\t\tcorrelations += [result[0]]\n",
    "\t\t\tp_scores += [result[1]]\n",
    "\t\n",
    "\tprint(correlations)\n",
    "\tprint(p_scores)\n",
    "\n",
    "\tfig, ax = plt.subplots()\n",
    "\tplt.xlim(-1.1,1.1)\n",
    "\tax.scatter(correlations, [0] * len(correlations))\n",
    "\tax.set(yticklabels=[])\n",
    "\tax.tick_params(left=False)\n",
    "\n",
    "\tprint(\"Average correlation between users: \" + str(np.nanmean(correlations)))\n",
    "\tprint(\"Average two-tailed p-value between users: \" + str(np.nanmean(p_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mk473\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "# Generate item-user matrix of the ratings generated in previous tasks\n",
    "\n",
    "unique_users = comments[\"personId\"].unique()\n",
    "unique_items = comments[\"contentId\"].unique()\n",
    "\n",
    "unique_users.sort()\n",
    "unique_items.sort()\n",
    "\n",
    "event_rating_matrix = csc_matrix((len(unique_items), len(unique_users)), dtype=float)\n",
    "\n",
    "for index, row in interactions.iterrows():\n",
    "\titem_index = np.where(unique_items == row[\"contentId\"])[0]\n",
    "\tuser_index = np.where(unique_users == row[\"personId\"])[0]\n",
    "\n",
    "\tif len(item_index) > 0 and len(user_index) > 0:\n",
    "\t\tevent_rating_matrix[item_index[0], user_index[0]] = row['eventRating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mk473\\AppData\\Roaming\\Python\\Python311\\site-packages\\scipy\\stats\\_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 0.8701834994322271, nan, nan, nan, 0.7282857650564181, nan, nan, nan, 0.7436880695485402, nan, nan, nan, nan, -1.0, nan, nan, nan, nan, nan, 1.0, 0.933715920413735, nan, nan, nan, nan, nan, nan, nan, -0.3053921602750109, nan, nan, nan, nan, nan, nan, 0.5494715472463982, nan, nan, nan, 0.9516507564270372, nan, nan, nan, nan, nan, -0.14454983983924735, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, -0.30482039522022825, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.9475219378626141, nan, nan, nan, nan, 0.7048228408285259, nan, nan, 1.0, 0.6289885892563474, nan, nan, 0.8647826863066554, nan, 0.04972740334068845, nan, nan, nan, nan, nan, nan, nan, nan, 0.6811503764465061, 0.12357472726465157, -0.549556867976393, 0.6640833235684831, nan, 0.5648426009487244, 0.32717341708256353, nan, nan, 0.9990368367465591, nan, nan, nan, 0.33448747562053277, -1.0, 0.1343967311897509, nan, nan, nan, nan, nan, 0.9723947647950538, nan, nan, 0.446799212619983, nan, 0.9960368966744811, -0.01653240023812924, 0.9999641671569273, 0.551834045536668, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.5281124364304813, nan, nan, nan, nan, nan, nan, 1.0, 0.708807948106029, nan, nan, nan, 0.324204390802869, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 1.0, -0.13568063314562262, -0.2845272837969094, nan, nan, nan, nan, nan, nan, 0.8477728799692399, nan, nan, nan, nan, -0.32992141116493023, 0.16459890217549095, nan, 0.9950536003641601, nan, nan, nan, 0.31521594916605233, nan, nan, nan, 0.6265799490944925, nan, 0.04363449335685024, nan, 0.7348579428279213, nan, 1.0, nan, nan, nan, nan, nan, nan, 0.2616731340042991, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.3859166821927993, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.731593977377255, nan, nan, nan, 1.0, nan, nan, nan, nan, nan, nan, nan, 0.7509636114912449, nan, 1.0, nan, 1.0, 0.44798573337733766, nan, 0.4739056599488912, nan, 0.8019543118585543, nan, nan, nan, nan, nan, nan, 0.4941033413450079, nan, nan, nan]\n",
      "[nan, 0.05504094779316051, nan, nan, nan, 0.011036668007530382, nan, nan, nan, 0.25631193045145984, nan, nan, nan, nan, 1.0, nan, nan, nan, nan, nan, 1.0, 0.006444756632998135, nan, nan, nan, nan, nan, nan, nan, 0.5053845338064518, nan, nan, nan, nan, nan, nan, 0.6296581505147089, nan, nan, nan, 0.19877213417404876, nan, nan, nan, nan, nan, 0.6375300512420792, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.6951796047797718, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.20715804385014275, nan, nan, nan, nan, 0.295177159171474, nan, nan, 1.0, 0.2556409874871223, nan, nan, 0.3349122207935738, nan, 0.9069147130224828, nan, nan, nan, nan, nan, nan, nan, nan, 0.3188496235534939, 0.8430611424165427, 0.25865128883813293, 0.01851327912047877, nan, 0.11304949228310544, 0.09575214513451069, nan, nan, 0.027943444393069103, nan, nan, nan, 0.0005902549430429289, 1.0, 0.7738959866343456, nan, nan, nan, nan, nan, 0.027605235204946066, nan, nan, 0.4506568179291618, nan, 0.05669651338527374, 0.9572498727368024, 0.005389358222435038, 0.44816595446333185, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.3603016660109517, nan, nan, nan, nan, nan, nan, 1.0, 0.07456944424071196, nan, nan, nan, 0.07025549754857381, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 1.0, 0.5575956217872057, 0.6426777479421636, nan, nan, nan, nan, nan, nan, 0.06964629437328458, nan, nan, nan, nan, 0.3518555037375929, 0.835401097824509, nan, 0.06334595680352217, nan, nan, nan, 0.5428361771245442, nan, nan, nan, 0.03912623992404688, nan, 0.8822540355091286, nan, 0.15720879230424434, nan, 1.0, nan, nan, nan, nan, nan, nan, 0.34614488253120373, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.10269796764467282, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.03913222763953503, nan, nan, nan, 1.0, nan, nan, nan, nan, nan, nan, nan, 0.14348276021941067, nan, 1.0, nan, 1.0, 0.37297480101841646, nan, 0.6856875383710416, nan, 0.19804568814144563, nan, nan, nan, nan, nan, nan, 0.14661927985559217, nan, nan, nan]\n",
      "Average correlation between users: 0.4889094590600429\n",
      "Average two-tailed p-value between users: 0.4345515255256246\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4\n",
    "# Generate item-user matrix from comments using vader sentiment analyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "vader_item_user_matrix = csc_matrix((len(unique_items), len(unique_users)), dtype=float)\n",
    "\n",
    "for index, row in comments.iterrows():\n",
    "\titem_index = np.where(unique_items == row[\"contentId\"])[0][0]\n",
    "\tuser_index = np.where(unique_users == row[\"personId\"])[0][0]\n",
    "\tvader_item_user_matrix[item_index, user_index] = vader.polarity_scores(row[\"comment\"])[\"compound\"]\n",
    "\n",
    "pearson_analyze(vader_item_user_matrix, event_rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, -0.7701943058336475, nan, nan, nan, -0.12312495393875672, nan, nan, nan, -0.029447165605417658, nan, nan, nan, nan, -1.0, nan, nan, nan, nan, nan, -1.0, -0.3779996308599157, nan, nan, nan, nan, nan, nan, nan, 0.12724156228098904, nan, nan, nan, nan, nan, nan, -0.9862882588590003, nan, nan, nan, -0.9494068060614245, nan, nan, nan, nan, nan, 0.15932154194206447, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.2540393520155438, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.20283444547569918, nan, nan, nan, nan, -0.27739848860379895, nan, nan, -1.0, -0.5043328788113142, nan, nan, 0.29369235682058215, nan, 0.22874655675079553, nan, nan, nan, nan, nan, nan, nan, nan, 0.13423121104280486, -0.8465889640802727, -0.9542731412018022, -0.0003377542923783672, nan, -0.16707997602864472, -0.09312424557661782, nan, nan, 0.5228913141327353, nan, nan, nan, -0.3092209497852341, -1.0, 0.01907310532678911, nan, nan, nan, nan, nan, 0.12708768311331403, nan, nan, -0.3720831589352263, nan, -0.7487531163446872, -0.5395482433073802, 0.9164001198048586, 0.04045566970313677, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.29982659674039464, nan, nan, nan, nan, nan, nan, 1.0, 0.11513852845136135, nan, nan, nan, -0.033078628050181275, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, -1.0, 0.04032607074369008, -0.8869450393056669, nan, nan, nan, nan, nan, nan, -0.7439346238055395, nan, nan, nan, nan, -0.07724557111310364, 0.012976074710847635, nan, -0.5852057359806528, nan, nan, nan, -0.8473580505290219, nan, nan, nan, -0.3875629789095878, nan, -0.3292989773156644, nan, 0.8614069322727202, nan, 1.0, nan, nan, nan, nan, nan, nan, -0.392099000466113, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, -0.12265688807058686, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.5592662217588737, -0.6512859308475528, nan, nan, nan, 1.0, nan, nan, nan, nan, nan, nan, nan, -0.204938571969597, nan, -1.0, nan, -1.0, -0.18133256746545834, nan, -0.21392520643571386, nan, 0.3508232077228117, nan, nan, nan, nan, nan, nan, -0.008070490141177007, nan, nan, nan]\n",
      "[nan, 0.07314789075309557, nan, nan, nan, 0.7030388201218565, nan, nan, nan, 0.9705528343945824, nan, nan, nan, nan, 1.0, nan, nan, nan, nan, nan, 1.0, 0.4600055505938858, nan, nan, nan, nan, nan, nan, nan, 0.7857324217953323, nan, nan, nan, nan, nan, nan, 0.10554530527073851, nan, nan, nan, 0.05059319393857553, nan, nan, nan, nan, nan, 0.5864117236370341, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.6800605908220378, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.7435251143559831, nan, nan, nan, nan, 0.722601511396201, nan, nan, 1.0, 0.3862314633851684, nan, nan, 0.706307643179418, nan, 0.5538453676727139, nan, nan, nan, nan, nan, nan, nan, nan, 0.8657687889571952, 0.07044718673962314, 0.0030886122358669923, 0.9991688079225274, nan, 0.6674464510799812, 0.6440834527778077, nan, nan, 0.6497067140838481, nan, nan, nan, 0.0013287888649801216, 1.0, 0.9676263799844415, nan, nan, nan, nan, nan, 0.8729123168866859, nan, nan, 0.46763195125538465, nan, 0.46130573202104597, 0.037909867397075345, 0.2621627593270517, 0.9595443302968631, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.6240482852049323, nan, nan, nan, nan, nan, nan, 1.0, 0.8058278124532151, nan, nan, nan, 0.8573683479278782, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 1.0, 0.8585838841808342, 0.044850048173441265, nan, nan, nan, nan, nan, nan, 0.14942807734475685, nan, nan, nan, nan, 0.8214024978875181, 0.9870239252891524, nan, 0.6020274928395158, nan, nan, nan, 0.033171101615711206, nan, nan, nan, 0.2389237123557294, nan, 0.2307159784698637, nan, 0.06063245063517642, nan, 1.0, nan, nan, nan, nan, nan, nan, 0.14831925612641347, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.606433842936788, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.1917894853405691, 0.08021855487144208, nan, nan, nan, 1.0, nan, nan, nan, nan, nan, nan, nan, 0.7409023326737731, nan, 1.0, nan, 1.0, 0.7309823922125112, nan, 0.8627502313884826, nan, 0.6491767922771883, nan, nan, nan, nan, nan, nan, 0.9823469526387303, nan, nan, nan]\n",
      "Average correlation between users: -0.204071504061002\n",
      "Average two-tailed p-value between users: 0.6026992627211578\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5\n",
    "# Same as #4 but the vader scores are replaced with the comments' size in tokens\n",
    "\n",
    "token_item_user_matrix = csc_matrix((len(unique_items), len(unique_users)), dtype=float)\n",
    "\n",
    "for index, row in comments.iterrows():\n",
    "\titem_index = np.where(unique_items == row[\"contentId\"])[0][0]\n",
    "\tuser_index = np.where(unique_users == row[\"personId\"])[0][0]\n",
    "\ttoken_item_user_matrix[item_index, user_index] = len(word_tokenize(row[\"comment\"]))\n",
    "\n",
    "pearson_analyze(token_item_user_matrix, event_rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, -0.838092151120853, nan, nan, nan, -0.24121008958538528, nan, nan, nan, -0.6182203990363625, nan, nan, nan, nan, -1.0, nan, nan, nan, nan, nan, -1.0, -0.026555207395802326, nan, nan, nan, nan, nan, nan, nan, -0.1007990052981007, nan, nan, nan, nan, nan, nan, -0.8788127063065245, nan, nan, nan, -0.16531163063339518, nan, nan, nan, nan, nan, 0.2910458226635454, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, -0.04180800007523098, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, -0.14961494836016365, nan, nan, nan, nan, -0.6825531852641651, nan, nan, -1.0, 0.4152799057041826, nan, nan, 0.6447771391916297, nan, -0.42621629626756496, nan, nan, nan, nan, nan, nan, nan, nan, -0.5650777225573528, -0.9217917747017879, -0.31164739068869207, -0.19810216404623876, nan, -0.15064702861547383, -0.10482918577075936, nan, nan, -1.0, nan, nan, nan, -0.057112655450696076, 1.0, 0.2519167274263862, nan, nan, nan, nan, nan, -0.6162915083777221, nan, nan, 0.36975046473512363, nan, -0.8358469058799619, 0.12638988745941906, -0.25178412790223154, -0.2407582994011872, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.6960808491867013, nan, nan, nan, nan, nan, nan, 1.0, 0.2291418437565786, nan, nan, nan, 0.3671260885902113, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, -0.1347787349551238, -0.5853412545610049, nan, nan, nan, nan, nan, nan, -0.5098482418943733, nan, nan, nan, nan, 0.11171381908200587, 0.1446983548629387, nan, -0.5386070613367309, nan, nan, nan, -0.6612846818503924, nan, nan, nan, -0.36085328566464114, nan, 0.002412383532920226, nan, 0.5553151083243961, nan, 1.0, nan, nan, nan, nan, nan, nan, -0.1744494847194433, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.08594918512382729, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.5220070135081856, -0.514710855454549, nan, nan, nan, -1.0, nan, nan, nan, nan, nan, nan, nan, 0.07327998453933984, nan, -1.0, nan, 1.0, -0.5173672418343191, nan, 0.5768512550167466, nan, 0.6426840325058729, nan, nan, nan, nan, nan, nan, 0.3295010528644386, nan, nan, nan]\n",
      "[nan, 0.07627755033738541, nan, nan, nan, 0.4749035236434499, nan, nan, nan, 0.5757078363516468, nan, nan, nan, nan, 1.0, nan, nan, nan, nan, nan, 1.0, 0.9601765519941232, nan, nan, nan, nan, nan, nan, nan, 0.8297463031820602, nan, nan, nan, nan, nan, nan, 0.31667254552581514, nan, nan, nan, 0.8942740200182605, nan, nan, nan, nan, nan, 0.3346688658421847, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.9467839124169488, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.8503850516398364, nan, nan, nan, nan, 0.3174468147358349, nan, nan, 1.0, 0.48686665007566704, nan, nan, 0.3552228608083703, nan, 0.25265430651316606, nan, nan, nan, nan, nan, nan, nan, nan, 0.6176923480427927, 0.025944841080271272, 0.5476631495318383, 0.5832613410064835, nan, 0.7217813041568167, 0.617998249086793, nan, nan, 1.0, nan, nan, nan, 0.5724771215579357, 1.0, 0.5857730198035981, nan, nan, nan, nan, nan, 0.38370849162227794, nan, nan, 0.5401777555723084, nan, 0.3699541436209969, 0.6807463493871427, 0.8379654129813691, 0.8452077764813806, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.19169353960383598, nan, nan, nan, nan, nan, nan, 1.0, 0.6623028934203172, nan, nan, nan, 0.04219050594892712, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.5498356860895663, 0.2997895601415564, nan, nan, nan, nan, nan, nan, 0.3801789400642805, nan, nan, nan, nan, 0.7586530336231851, 0.8553016451370614, nan, 0.6379014918894069, nan, nan, nan, 0.15266202330896422, nan, nan, nan, 0.30563917291511034, nan, 0.993192152457709, nan, 0.3311901291472206, nan, 1.0, nan, nan, nan, nan, nan, nan, 0.5340581732120601, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.7186269273043449, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.22944294300403478, 0.19182117087113243, nan, nan, nan, 1.0, nan, nan, nan, nan, nan, nan, nan, 0.9067805987191138, nan, 1.0, nan, 1.0, 0.29319068791628666, nan, 0.6085624437121189, nan, 0.3573159674941271, nan, nan, nan, nan, nan, nan, 0.3525065704866884, nan, nan, nan]\n",
      "Average correlation between users: -0.1330733717821963\n",
      "Average two-tailed p-value between users: 0.5992495725580634\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6\n",
    "# Same as #4 but the vader scores are replaced with the comments' ratio of stopwords and words with uncommon characters to other words\n",
    "\n",
    "stopwords_list = stopwords.words(\"english\") + stopwords.words('portuguese')\n",
    "\n",
    "stopword_ratio_item_user_matrix = csc_matrix((len(unique_items), len(unique_users)), dtype=float)\n",
    "\n",
    "for index, row in comments.iterrows():\n",
    "\titem_index = np.where(unique_items == row[\"contentId\"])[0][0]\n",
    "\tuser_index = np.where(unique_users == row[\"personId\"])[0][0]\n",
    "\n",
    "\ttokens = word_tokenize(row[\"comment\"])\n",
    "\n",
    "\tstopwords_and_uncommon_chars = [token for token in tokens if token.lower() in stopwords_list or not token.isalpha()]\n",
    "\n",
    "\tstopword_ratio_item_user_matrix[item_index, user_index] = len(stopwords_and_uncommon_chars) / len(tokens)\n",
    "\n",
    "pearson_analyze(stopword_ratio_item_user_matrix, event_rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.028, 0.822, 0.149, 0.9992], [0.0, 0.845, 0.155, 0.9917], [0.014, 0.94, 0.046, 0.8442], [0.034, 0.813, 0.153, 0.9997], [0.023, 0.835, 0.141, 0.998], [0.03, 0.966, 0.004, -0.946], [0.008, 0.946, 0.046, 0.9967], [0.027, 0.892, 0.081, 0.9996], [0.011, 0.889, 0.1, 0.9771], [0.065, 0.809, 0.126, 0.9993], [0.012, 0.862, 0.126, 0.9984], [0.015, 0.985, 0.0, -0.6808], [0.031, 0.963, 0.006, -0.9924], [0.008, 0.857, 0.135, 0.9986], [0.0, 0.836, 0.164, 0.9764], [0.029, 0.773, 0.198, 0.9987], [0.043, 0.946, 0.011, -0.9371], [0.033, 0.85, 0.118, 0.9979], [0.022, 0.978, 0.0, -0.3595], [0.01, 0.99, 0.0, -0.3736], [0.07, 0.857, 0.074, -0.7647], [0.04, 0.8, 0.16, 0.9989], [0.012, 0.849, 0.139, 0.9866], [0.0, 0.892, 0.108, 0.9825], [0.016, 0.893, 0.091, 0.9936], [0.0, 1.0, 0.0, 0.0], [0.089, 0.846, 0.065, -0.9353], [0.012, 0.858, 0.13, 0.997], [0.173, 0.803, 0.024, -0.9832], [0.055, 0.894, 0.051, 0.3182], [0.014, 0.89, 0.097, 0.985], [0.077, 0.843, 0.08, -0.3532], [0.086, 0.79, 0.124, 0.9994], [0.059, 0.798, 0.143, 0.999], [0.0, 0.982, 0.018, 0.34], [0.07, 0.856, 0.073, 0.7412], [0.028, 0.88, 0.092, 0.9507], [0.032, 0.889, 0.079, 0.9983], [0.095, 0.838, 0.067, -0.9245], [0.071, 0.794, 0.135, 0.9993], [0.034, 0.748, 0.218, 0.9981], [0.048, 0.88, 0.072, 0.9381], [0.038, 0.808, 0.154, 0.9996], [0.002, 0.809, 0.189, 0.999], [0.0, 0.883, 0.117, 0.9826], [0.082, 0.794, 0.125, 0.9996], [0.054, 0.803, 0.143, 0.9975], [0.01, 0.935, 0.055, 0.9655], [0.019, 0.861, 0.12, 0.9984], [0.043, 0.841, 0.116, 0.9703], [0.035, 0.896, 0.069, 0.9895], [0.063, 0.853, 0.084, 0.9834], [0.058, 0.805, 0.137, 0.996], [0.023, 0.898, 0.08, 0.9473], [0.008, 0.802, 0.19, 0.9983], [0.028, 0.89, 0.082, 0.9973], [0.0, 0.945, 0.055, 0.92], [0.002, 0.911, 0.087, 0.9941], [0.075, 0.783, 0.142, 0.9966], [0.03, 0.912, 0.058, 0.8509], [0.01, 0.828, 0.162, 0.9883], [0.032, 0.824, 0.144, 0.9995], [0.0, 0.801, 0.199, 0.9967], [0.021, 0.946, 0.034, 0.8658], [0.031, 0.873, 0.096, 0.9969], [0.008, 0.928, 0.064, 0.836], [0.027, 0.869, 0.104, 0.9442], [0.0, 0.761, 0.239, 0.9909], [0.011, 0.909, 0.08, 0.9863], [0.023, 0.921, 0.057, 0.9905], [0.028, 0.846, 0.126, 1.0], [0.021, 0.886, 0.093, 0.997], [0.024, 0.881, 0.095, 0.9999], [0.12, 0.758, 0.122, -0.754], [0.04, 0.96, 0.0, -0.6808], [0.005, 0.947, 0.048, 0.9573], [0.045, 0.829, 0.126, 0.9997], [0.0, 0.946, 0.054, 0.743], [0.026, 0.899, 0.076, 0.9909], [0.015, 0.854, 0.131, 0.9997], [0.002, 0.934, 0.064, 0.9909], [0.013, 0.848, 0.139, 0.9904], [0.024, 0.791, 0.185, 0.9976], [0.001, 0.869, 0.131, 0.9995], [0.007, 0.89, 0.103, 0.9948], [0.008, 0.898, 0.094, 0.9969], [0.057, 0.872, 0.07, 0.2023], [0.013, 0.913, 0.073, 0.8772], [0.011, 0.886, 0.103, 0.9967], [0.025, 0.888, 0.087, 0.991], [0.011, 0.861, 0.129, 0.9979], [0.0, 0.918, 0.082, 0.9509], [0.049, 0.867, 0.085, 0.9869], [0.06, 0.822, 0.118, 0.9874], [0.055, 0.799, 0.146, 0.9986], [0.014, 0.891, 0.095, 0.9875], [0.0, 0.969, 0.031, 0.5023], [0.007, 0.907, 0.086, 0.9979], [0.057, 0.874, 0.069, 0.2255], [0.012, 0.889, 0.099, 0.9913], [0.036, 0.901, 0.063, 0.8794], [0.052, 0.761, 0.187, 0.998], [0.034, 0.907, 0.058, 0.9773], [0.0, 1.0, 0.0, 0.0], [0.011, 0.875, 0.115, 0.9973], [0.02, 0.868, 0.112, 0.9652], [0.078, 0.836, 0.086, 0.9526], [0.009, 0.835, 0.156, 0.9963], [0.018, 0.91, 0.073, 0.9991], [0.032, 0.874, 0.094, 0.996], [0.048, 0.952, 0.0, -0.8541], [0.038, 0.797, 0.165, 0.9999], [0.026, 0.862, 0.112, 0.9538], [0.059, 0.853, 0.087, 0.972], [0.02, 0.88, 0.1, 0.9991], [0.025, 0.885, 0.09, 0.9433], [0.051, 0.927, 0.022, -0.4588], [0.031, 0.871, 0.098, 0.9942], [0.014, 0.88, 0.106, 0.9796], [0.023, 0.944, 0.032, 0.9472], [0.009, 0.889, 0.103, 0.9919], [0.019, 0.918, 0.063, 0.9834], [0.015, 0.89, 0.095, 0.974], [0.013, 0.909, 0.078, 0.9647], [0.0, 0.84, 0.16, 0.9825], [0.0, 1.0, 0.0, 0.0], [0.015, 0.977, 0.009, -0.2185], [0.043, 0.815, 0.142, 0.9998], [0.004, 0.842, 0.154, 0.9989], [0.055, 0.802, 0.142, 0.9985], [0.0, 0.902, 0.098, 0.9893], [0.045, 0.808, 0.147, 0.9986], [0.011, 0.825, 0.164, 0.9966], [0.029, 0.816, 0.155, 0.9992], [0.028, 0.831, 0.141, 0.9996], [0.013, 0.832, 0.156, 0.997], [0.018, 0.842, 0.14, 0.9987], [0.06, 0.861, 0.079, 0.8934], [0.0, 0.865, 0.135, 0.9914], [0.05, 0.883, 0.066, 0.4523], [0.031, 0.969, 0.0, -0.8807], [0.021, 0.82, 0.16, 0.9999], [0.08, 0.864, 0.056, -0.8559], [0.023, 0.94, 0.037, 0.5351], [0.033, 0.843, 0.124, 0.998], [0.04, 0.869, 0.091, 0.9698], [0.028, 0.972, 0.0, -0.7815], [0.008, 0.924, 0.068, 0.936], [0.0, 0.795, 0.205, 0.9794], [0.0, 0.759, 0.241, 0.9903], [0.0, 0.924, 0.076, 0.9771], [0.091, 0.819, 0.089, -0.1109], [0.036, 0.904, 0.06, 0.8383], [0.041, 0.832, 0.127, 0.9927], [0.073, 0.777, 0.15, 0.9923], [0.047, 0.843, 0.11, 0.9897], [0.0, 0.849, 0.151, 0.9976], [0.019, 0.89, 0.091, 0.9693], [0.032, 0.882, 0.086, 0.9623], [0.045, 0.86, 0.094, 0.9551], [0.006, 0.927, 0.067, 0.8666], [0.036, 0.923, 0.042, 0.126], [0.04, 0.836, 0.125, 0.9962], [0.026, 0.972, 0.002, -0.975], [0.011, 0.889, 0.1, 0.7579], [0.005, 0.921, 0.074, 0.9766], [0.014, 0.906, 0.08, 0.9903], [0.01, 0.929, 0.06, 0.9897], [0.016, 0.89, 0.094, 0.9784], [0.026, 0.831, 0.143, 0.9997], [0.014, 0.875, 0.111, 0.9952], [0.004, 0.887, 0.109, 0.9934], [0.024, 0.85, 0.126, 0.9989], [0.075, 0.852, 0.073, 0.5905], [0.014, 0.861, 0.125, 0.9921], [0.023, 0.956, 0.021, 0.7514], [0.014, 0.986, 0.0, -0.5803], [0.03, 0.858, 0.112, 0.9936], [0.037, 0.947, 0.016, -0.6561], [0.043, 0.857, 0.1, 0.9965], [0.018, 0.875, 0.107, 0.9996], [0.013, 0.871, 0.117, 0.999], [0.009, 0.875, 0.117, 0.9975], [0.032, 0.885, 0.083, 0.9961], [0.008, 0.992, 0.0, -0.296], [0.04, 0.944, 0.016, -0.8271], [0.058, 0.784, 0.159, 0.9997], [0.016, 0.984, 0.0, -0.7998], [0.045, 0.789, 0.165, 0.9996], [0.016, 0.984, 0.0, -0.7998], [0.026, 0.79, 0.184, 0.9995], [0.02, 0.816, 0.164, 0.999], [0.094, 0.775, 0.131, 0.9903], [0.026, 0.888, 0.085, 0.9865], [0.049, 0.816, 0.135, 0.9991], [0.017, 0.813, 0.17, 0.9967], [0.026, 0.788, 0.186, 0.9997], [0.008, 0.799, 0.194, 0.9907], [0.014, 0.879, 0.107, 0.9903], [0.053, 0.837, 0.11, 0.9542], [0.027, 0.973, 0.0, -0.8807], [0.019, 0.981, 0.0, -0.296], [0.0, 0.905, 0.095, 0.6996], [0.017, 0.814, 0.169, 0.9994], [0.025, 0.952, 0.024, -0.1027], [0.063, 0.937, 0.0, -0.8402], [0.056, 0.854, 0.09, 0.9959], [0.023, 0.97, 0.007, -0.9482], [0.019, 0.875, 0.106, 0.9627], [0.018, 0.875, 0.107, 0.9991], [0.083, 0.83, 0.087, -0.0655], [0.01, 0.886, 0.104, 0.9837], [0.041, 0.801, 0.158, 0.9999], [0.009, 0.875, 0.116, 0.9932], [0.013, 0.677, 0.31, 0.9921], [0.017, 0.98, 0.003, -0.9484], [0.022, 0.85, 0.129, 0.9983], [0.036, 0.838, 0.126, 0.999], [0.029, 0.971, 0.0, -0.8807], [0.016, 0.835, 0.15, 0.9952], [0.007, 0.829, 0.164, 0.9981], [0.027, 0.961, 0.012, -0.8689], [0.017, 0.835, 0.148, 0.9991], [0.021, 0.979, 0.0, -0.5267], [0.014, 0.986, 0.0, -0.5803], [0.029, 0.971, 0.0, -0.8807], [0.056, 0.84, 0.103, 0.9977], [0.049, 0.803, 0.148, 0.9839], [0.035, 0.865, 0.1, 0.9963], [0.037, 0.882, 0.081, 0.1263], [0.027, 0.958, 0.014, -0.4939], [0.05, 0.849, 0.101, 0.9993], [0.095, 0.849, 0.056, -0.9816], [0.031, 0.867, 0.102, 0.9989], [0.037, 0.843, 0.12, 0.9931], [0.022, 0.844, 0.134, 0.9995], [0.006, 0.901, 0.093, 0.9988], [0.034, 0.856, 0.109, 0.9565], [0.031, 0.791, 0.179, 0.992], [0.015, 0.911, 0.073, 0.9848], [0.045, 0.813, 0.142, 0.9982], [0.009, 0.719, 0.272, 1.0], [0.01, 0.896, 0.095, 0.9325], [0.0, 0.857, 0.143, 0.9661], [0.032, 0.813, 0.155, 0.9999], [0.007, 0.905, 0.088, 0.9897], [0.098, 0.806, 0.096, 0.8832], [0.044, 0.83, 0.126, 0.9941], [0.016, 0.87, 0.114, 0.9946], [0.005, 0.913, 0.082, 0.9705], [0.023, 0.872, 0.105, 0.9654], [0.016, 0.874, 0.11, 0.9977], [0.031, 0.969, 0.0, -0.932], [0.03, 0.823, 0.147, 0.9993], [0.039, 0.917, 0.044, 0.1543], [0.018, 0.977, 0.005, -0.6908], [0.021, 0.822, 0.157, 0.9967], [0.005, 0.857, 0.137, 0.9992], [0.096, 0.76, 0.143, 0.941], [0.023, 0.977, 0.0, -0.798], [0.045, 0.955, 0.0, -0.4184], [0.149, 0.783, 0.068, -0.9836], [0.006, 0.918, 0.076, 0.9727], [0.022, 0.865, 0.113, 0.9766], [0.032, 0.888, 0.08, 0.9898], [0.04, 0.917, 0.044, -0.0413], [0.025, 0.958, 0.017, -0.6852], [0.034, 0.862, 0.104, 0.9994], [0.0, 0.952, 0.048, 0.8834], [0.028, 0.826, 0.146, 0.9994], [0.004, 0.859, 0.137, 0.9925], [0.014, 0.89, 0.096, 0.9968], [0.056, 0.865, 0.079, 0.1348], [0.007, 0.849, 0.144, 0.9952], [0.02, 0.934, 0.046, 0.9474], [0.105, 0.82, 0.075, -0.9983], [0.027, 0.968, 0.005, -0.9463], [0.01, 0.848, 0.141, 0.9984], [0.0, 0.985, 0.015, 0.0516], [0.041, 0.942, 0.016, -0.4939], [0.046, 0.814, 0.14, 0.9969], [0.027, 0.871, 0.102, 0.9763], [0.0, 0.904, 0.096, 0.9818], [0.046, 0.831, 0.123, 0.9989], [0.024, 0.884, 0.092, 0.9997], [0.057, 0.897, 0.046, 0.35], [0.043, 0.881, 0.076, 0.8648], [0.051, 0.865, 0.084, 0.9691], [0.081, 0.784, 0.135, 0.9993], [0.024, 0.976, 0.0, -0.5267], [0.063, 0.833, 0.104, 0.9825], [0.03, 0.97, 0.0, -0.7783], [0.041, 0.809, 0.15, 0.9975], [0.033, 0.967, 0.0, -0.9805], [0.014, 0.878, 0.108, 0.993], [0.037, 0.963, 0.0, -0.7783], [0.025, 0.869, 0.106, 0.7845], [0.007, 0.921, 0.072, 0.9559], [0.004, 0.939, 0.057, 0.9943], [0.023, 0.951, 0.025, 0.2837], [0.04, 0.705, 0.255, 0.9984], [0.037, 0.819, 0.144, 0.9952], [0.031, 0.853, 0.116, 0.9997], [0.0, 0.921, 0.079, 0.9618], [0.064, 0.765, 0.172, 0.9923], [0.023, 0.977, 0.0, -0.9562], [0.021, 0.814, 0.165, 0.9994], [0.016, 0.874, 0.11, 0.995], [0.02, 0.892, 0.088, 0.9798], [0.014, 0.984, 0.002, -0.9785], [0.005, 0.893, 0.102, 0.9937], [0.024, 0.851, 0.125, 0.993], [0.161, 0.699, 0.14, -0.9295], [0.058, 0.853, 0.089, 0.958], [0.026, 0.816, 0.159, 0.9984], [0.069, 0.799, 0.132, 0.9984], [0.023, 0.97, 0.007, -0.802], [0.047, 0.828, 0.125, 0.9981], [0.035, 0.871, 0.094, 0.9916], [0.012, 0.862, 0.126, 0.9895], [0.008, 0.945, 0.047, 0.8516], [0.054, 0.825, 0.121, 0.9669], [0.015, 0.767, 0.218, 0.9997], [0.031, 0.837, 0.132, 0.9998], [0.045, 0.884, 0.071, 0.8122], [0.017, 0.914, 0.069, 0.9719], [0.009, 0.923, 0.068, 0.9776], [0.025, 0.966, 0.009, -0.6636], [0.005, 0.941, 0.054, 0.882], [0.014, 0.839, 0.147, 0.9981], [0.045, 0.803, 0.152, 0.9918], [0.012, 0.882, 0.106, 0.9936], [0.038, 0.856, 0.106, 0.9924], [0.031, 0.866, 0.103, 0.9991], [0.018, 0.863, 0.119, 0.9964], [0.011, 0.901, 0.088, 0.9984], [0.084, 0.842, 0.074, -0.9959], [0.046, 0.907, 0.047, 0.0387], [0.062, 0.747, 0.191, 0.9992], [0.094, 0.718, 0.188, 0.7906], [0.013, 0.785, 0.201, 0.9986], [0.019, 0.867, 0.114, 0.9985], [0.029, 0.868, 0.104, 0.9919], [0.047, 0.921, 0.032, -0.7096], [0.005, 0.887, 0.108, 0.9959], [0.034, 0.966, 0.0, -0.9804], [0.031, 0.959, 0.011, -0.886], [0.024, 0.93, 0.047, 0.7202], [0.018, 0.855, 0.128, 0.9982], [0.012, 0.98, 0.008, -0.6843], [0.128, 0.768, 0.105, -0.9923], [0.034, 0.856, 0.11, 0.9902], [0.02, 0.855, 0.125, 0.9961], [0.17, 0.707, 0.122, -0.9989], [0.07, 0.857, 0.073, -0.6452], [0.049, 0.809, 0.142, 0.9875], [0.022, 0.787, 0.19, 0.9993], [0.0, 0.921, 0.079, 0.6369], [0.016, 0.801, 0.183, 0.9982], [0.03, 0.933, 0.037, 0.5411], [0.028, 0.866, 0.106, 0.9991], [0.013, 0.956, 0.031, 0.4939], [0.012, 0.903, 0.085, 0.9619], [0.006, 0.99, 0.004, -0.4137], [0.015, 0.874, 0.111, 0.9924], [0.035, 0.901, 0.064, 0.2263], [0.017, 0.826, 0.158, 0.9612], [0.022, 0.978, 0.0, -0.9456], [0.015, 0.982, 0.003, -0.7882], [0.004, 0.982, 0.013, 0.6553], [0.0, 0.871, 0.129, 0.8225], [0.009, 0.869, 0.122, 0.9983], [0.021, 0.854, 0.125, 0.9987], [0.029, 0.882, 0.089, 0.9986], [0.027, 0.888, 0.085, 0.9857], [0.018, 0.982, 0.0, -0.7783], [0.024, 0.964, 0.012, -0.3873], [0.016, 0.93, 0.054, 0.9929], [0.113, 0.836, 0.051, -0.9999], [0.09, 0.8, 0.11, 0.9257], [0.094, 0.793, 0.112, 0.9696], [0.003, 0.981, 0.016, 0.7906], [0.026, 0.835, 0.139, 0.9964], [0.041, 0.825, 0.134, 0.6808], [0.015, 0.95, 0.036, 0.4939], [0.022, 0.871, 0.107, 0.9973], [0.029, 0.873, 0.097, 0.9979], [0.022, 0.869, 0.109, 0.9988], [0.109, 0.803, 0.088, -0.9994], [0.057, 0.73, 0.213, 0.9999], [0.032, 0.837, 0.131, 0.9915], [0.034, 0.878, 0.088, 0.9997], [0.083, 0.718, 0.199, 0.9989], [0.138, 0.766, 0.096, -0.9787], [0.008, 0.903, 0.089, 0.9965], [0.044, 0.817, 0.139, 0.9993], [0.011, 0.845, 0.144, 0.9993], [0.025, 0.975, 0.0, -0.9595], [0.013, 0.875, 0.112, 0.9986], [0.008, 0.91, 0.081, 0.9912], [0.004, 0.933, 0.064, 0.9637], [0.033, 0.875, 0.092, 0.9604], [0.057, 0.886, 0.057, 0.4348], [0.035, 0.772, 0.193, 0.9948], [0.017, 0.983, 0.0, -0.6808], [0.054, 0.804, 0.142, 0.9993], [0.107, 0.893, 0.0, -0.9498], [0.012, 0.859, 0.129, 0.999], [0.113, 0.771, 0.117, -0.0818], [0.04, 0.815, 0.145, 0.9999], [0.026, 0.887, 0.086, 0.4588], [0.031, 0.867, 0.103, 0.9997], [0.021, 0.97, 0.009, -0.8591], [0.074, 0.926, 0.0, -0.6705], [0.015, 0.877, 0.108, 0.9998], [0.117, 0.859, 0.024, -0.9504], [0.048, 0.866, 0.087, 0.9915], [0.0, 0.9, 0.1, 0.6249], [0.0, 0.817, 0.183, 0.8513], [0.0, 0.967, 0.033, 0.25], [0.018, 0.91, 0.072, 0.9918], [0.0, 0.753, 0.247, 0.9246], [0.062, 0.717, 0.221, 0.9001], [0.025, 0.799, 0.177, 0.836], [0.0, 0.899, 0.101, 0.6369], [0.0, 0.956, 0.044, 0.3182], [0.043, 0.778, 0.179, 0.9987], [0.042, 0.958, 0.0, -0.9567], [0.045, 0.86, 0.095, 0.9992], [0.005, 0.919, 0.076, 0.9963], [0.028, 0.866, 0.106, 0.9968], [0.045, 0.874, 0.081, 0.9984], [0.0, 0.917, 0.083, 0.7579], [0.023, 0.818, 0.159, 0.996], [0.02, 0.837, 0.142, 0.9992], [0.017, 0.786, 0.197, 0.9967], [0.02, 0.842, 0.138, 0.8573], [0.017, 0.832, 0.151, 0.997], [0.019, 0.949, 0.031, 0.792], [0.018, 0.954, 0.028, 0.9341], [0.025, 0.964, 0.012, -0.9267], [0.014, 0.946, 0.041, 0.8883], [0.063, 0.817, 0.12, 0.9981], [0.026, 0.856, 0.118, 0.9806], [0.049, 0.853, 0.097, 0.9865], [0.033, 0.967, 0.0, -0.9705], [0.0, 0.894, 0.106, 0.9246], [0.005, 0.985, 0.01, 0.49], [0.015, 0.897, 0.088, 0.9967], [0.103, 0.772, 0.125, 0.992], [0.0, 0.899, 0.101, 0.9944], [0.007, 0.88, 0.113, 0.9887], [0.0, 0.903, 0.097, 0.7096], [0.004, 0.867, 0.129, 0.9946], [0.063, 0.843, 0.094, 0.6805], [0.053, 0.881, 0.067, -0.1901], [0.02, 0.915, 0.065, 0.9978], [0.015, 0.87, 0.115, 0.9985], [0.078, 0.837, 0.085, 0.4879], [0.073, 0.796, 0.13, 0.9973], [0.075, 0.792, 0.133, 0.998], [0.084, 0.768, 0.148, 0.9136], [0.048, 0.832, 0.12, 0.9999], [0.038, 0.832, 0.13, 0.9991], [0.115, 0.83, 0.054, -0.9641], [0.022, 0.886, 0.092, 0.9153], [0.01, 0.796, 0.194, 0.9997], [0.043, 0.827, 0.13, 0.9979], [0.0, 1.0, 0.0, 0.0], [0.033, 0.849, 0.118, 0.9996], [0.01, 0.869, 0.121, 0.9935], [0.046, 0.952, 0.002, -0.9874], [0.019, 0.847, 0.134, 0.9995], [0.016, 0.984, 0.0, -0.9081], [0.011, 0.922, 0.067, 0.9568], [0.013, 0.919, 0.067, 0.9942], [0.044, 0.835, 0.122, 0.9981], [0.0, 1.0, 0.0, 0.0], [0.05, 0.814, 0.136, 0.9971], [0.035, 0.793, 0.172, 1.0], [0.057, 0.836, 0.107, 0.9939], [0.02, 0.97, 0.01, -0.9173], [0.015, 0.973, 0.013, -0.1531], [0.0, 0.869, 0.131, 0.9726], [0.02, 0.82, 0.161, 0.9992], [0.117, 0.787, 0.096, -0.9821], [0.117, 0.787, 0.096, -0.9821], [0.044, 0.923, 0.033, 0.4781], [0.0, 0.888, 0.112, 0.9313], [0.0, 0.901, 0.099, 0.992], [0.023, 0.876, 0.101, 0.9933], [0.005, 0.912, 0.084, 0.9778], [0.0, 1.0, 0.0, 0.0], [0.021, 0.904, 0.075, 0.9912], [0.059, 0.761, 0.18, 0.9991], [0.049, 0.951, 0.0, -0.6808], [0.004, 0.855, 0.14, 0.9902], [0.09, 0.784, 0.126, 0.9953], [0.023, 0.971, 0.006, -0.7579], [0.012, 0.986, 0.002, -0.885], [0.024, 0.925, 0.051, 0.983], [0.069, 0.728, 0.203, 0.8751], [0.026, 0.842, 0.132, 0.9967], [0.026, 0.874, 0.1, 0.9954], [0.013, 0.886, 0.101, 0.9985], [0.004, 0.798, 0.198, 0.9972], [0.005, 0.902, 0.093, 0.9793], [0.036, 0.794, 0.169, 0.9985], [0.032, 0.878, 0.09, 0.9645], [0.142, 0.811, 0.047, -0.9974], [0.025, 0.865, 0.11, 0.9997], [0.06, 0.788, 0.152, 0.9994], [0.0, 0.897, 0.103, 0.9396], [0.039, 0.801, 0.16, 0.9999], [0.051, 0.801, 0.148, 0.9999], [0.055, 0.945, 0.0, -0.879], [0.025, 0.886, 0.089, 0.9973], [0.025, 0.886, 0.089, 0.9973], [0.025, 0.886, 0.089, 0.9973], [0.032, 0.888, 0.08, 0.9889], [0.029, 0.957, 0.015, -0.296], [0.025, 0.886, 0.089, 0.9973], [0.009, 0.855, 0.136, 0.9988], [0.018, 0.861, 0.121, 0.9773], [0.014, 0.839, 0.148, 0.9981], [0.024, 0.933, 0.043, 0.8546], [0.026, 0.873, 0.101, 0.9949], [0.031, 0.864, 0.105, 0.9885], [0.031, 0.867, 0.101, 0.9965], [0.043, 0.957, 0.0, -0.5994], [0.0, 0.86, 0.14, 0.8074], [0.044, 0.81, 0.146, 0.9985], [0.054, 0.828, 0.118, 0.9062], [0.023, 0.977, 0.0, -0.3595], [0.012, 0.963, 0.025, 0.3182], [0.021, 0.874, 0.106, 0.9947], [0.009, 0.986, 0.004, -0.5719], [0.0, 0.931, 0.069, 0.5267], [0.03, 0.831, 0.139, 0.9982], [0.07, 0.891, 0.04, -0.2714], [0.017, 0.983, 0.0, -0.7088], [0.045, 0.79, 0.165, 0.9996], [0.025, 0.895, 0.08, 0.9912], [0.025, 0.966, 0.009, -0.8346], [0.041, 0.944, 0.015, -0.8634], [0.012, 0.894, 0.094, 0.9757], [0.0, 0.771, 0.229, 0.9876], [0.0, 0.771, 0.229, 0.9876], [0.0, 0.771, 0.229, 0.9876], [0.018, 0.977, 0.004, -0.807], [0.072, 0.789, 0.139, 0.9693], [0.024, 0.887, 0.088, 0.9698], [0.045, 0.855, 0.1, 0.9046], [0.026, 0.821, 0.153, 0.9865], [0.121, 0.737, 0.142, 0.7564], [0.0, 0.86, 0.14, 0.969], [0.087, 0.763, 0.15, 0.9989], [0.035, 0.965, 0.0, -0.5267], [0.0, 1.0, 0.0, 0.0], [0.014, 0.902, 0.084, 0.9294], [0.021, 0.824, 0.155, 0.9998], [0.0, 0.956, 0.044, 0.8922], [0.049, 0.862, 0.089, 0.9994], [0.011, 0.823, 0.166, 0.9999], [0.034, 0.824, 0.142, 0.9678], [0.04, 0.831, 0.129, 0.9992], [0.011, 0.887, 0.102, 0.9931], [0.0, 0.843, 0.157, 0.9946], [0.02, 0.871, 0.109, 0.9956], [0.033, 0.826, 0.141, 0.9719], [0.058, 0.813, 0.128, 0.9999], [0.022, 0.978, 0.0, -0.6597], [0.055, 0.809, 0.137, 0.9996], [0.092, 0.802, 0.106, 0.9962], [0.083, 0.837, 0.08, -0.9844], [0.041, 0.869, 0.091, 0.9982], [0.009, 0.855, 0.136, 0.9848], [0.009, 0.89, 0.101, 0.9928], [0.038, 0.881, 0.081, 0.9923], [0.052, 0.796, 0.152, 0.9983], [0.011, 0.937, 0.051, 0.977], [0.039, 0.856, 0.106, 0.9962], [0.078, 0.795, 0.127, 0.9774], [0.021, 0.755, 0.223, 0.9715], [0.01, 0.851, 0.139, 0.9996], [0.035, 0.854, 0.111, 0.9997], [0.028, 0.845, 0.126, 0.9994], [0.025, 0.924, 0.051, 0.4963], [0.073, 0.858, 0.069, -0.4631], [0.031, 0.855, 0.115, 0.9994], [0.046, 0.814, 0.14, 0.9986], [0.028, 0.903, 0.069, 0.9809], [0.04, 0.849, 0.111, 0.9989], [0.063, 0.855, 0.082, 0.6667], [0.024, 0.871, 0.105, 0.9903], [0.092, 0.766, 0.141, 0.9972], [0.022, 0.878, 0.1, 0.9988], [0.01, 0.876, 0.114, 0.9975], [0.066, 0.785, 0.149, 0.9979], [0.014, 0.899, 0.088, 0.9976], [0.045, 0.955, 0.0, -0.8402], [0.034, 0.866, 0.1, 0.7964], [0.0, 1.0, 0.0, 0.0], [0.017, 0.97, 0.013, 0.477], [0.009, 0.898, 0.093, 0.9734], [0.006, 0.935, 0.059, 0.9869], [0.026, 0.896, 0.078, 0.9933], [0.042, 0.841, 0.117, 0.9908], [0.051, 0.75, 0.199, 0.9993], [0.009, 0.836, 0.155, 0.9913], [0.049, 0.819, 0.132, 0.9994], [0.019, 0.955, 0.026, 0.7964], [0.009, 0.898, 0.093, 0.9734], [0.027, 0.967, 0.006, -0.8689], [0.073, 0.832, 0.095, 0.495], [0.054, 0.883, 0.062, 0.4228], [0.084, 0.818, 0.098, 0.7729], [0.107, 0.738, 0.154, 0.8435], [0.068, 0.864, 0.068, -0.635], [0.095, 0.83, 0.075, -0.5241], [0.085, 0.764, 0.151, 0.9894], [0.012, 0.969, 0.019, 0.6553], [0.0, 0.774, 0.226, 0.9888], [0.025, 0.975, 0.0, -0.5267], [0.009, 0.991, 0.0, -0.3595], [0.03, 0.873, 0.096, 0.9996], [0.041, 0.836, 0.123, 0.9992], [0.044, 0.819, 0.137, 0.9999], [0.1, 0.843, 0.057, -0.9613], [0.0, 0.774, 0.226, 0.9888], [0.009, 0.898, 0.093, 0.9734], [0.0, 0.912, 0.088, 0.836], [0.02, 0.826, 0.154, 0.9988], [0.02, 0.848, 0.132, 0.9983], [0.097, 0.785, 0.118, 0.9694], [0.036, 0.952, 0.012, -0.5106], [0.019, 0.972, 0.008, -0.5638], [0.024, 0.976, 0.0, -0.9413], [0.033, 0.858, 0.109, 0.998], [0.035, 0.872, 0.093, 0.9997], [0.013, 0.907, 0.08, 0.9952], [0.003, 0.987, 0.01, 0.6249], [0.028, 0.961, 0.011, -0.7269], [0.034, 0.966, 0.0, -0.885], [0.03, 0.873, 0.096, 0.9996], [0.075, 0.79, 0.136, 0.9995], [0.013, 0.819, 0.168, 0.9897], [0.017, 0.914, 0.069, 0.9989], [0.019, 0.906, 0.075, 0.9952], [0.027, 0.828, 0.144, 0.9991], [0.017, 0.888, 0.095, 0.988], [0.0, 0.874, 0.126, 0.992], [0.089, 0.741, 0.17, 0.9993], [0.028, 0.891, 0.081, 0.9763], [0.04, 0.765, 0.195, 0.9985], [0.043, 0.957, 0.0, -0.9517], [0.012, 0.89, 0.098, 0.9972], [0.011, 0.986, 0.003, -0.5994], [0.034, 0.966, 0.0, -0.5267], [0.03, 0.951, 0.019, -0.3094], [0.022, 0.976, 0.002, -0.9337], [0.041, 0.959, 0.0, -0.9657], [0.091, 0.823, 0.085, 0.1434], [0.061, 0.819, 0.12, 0.9998], [0.021, 0.965, 0.014, -0.1027], [0.004, 0.921, 0.075, 0.9833], [0.053, 0.829, 0.118, 0.9846], [0.059, 0.846, 0.095, 0.9998], [0.019, 0.882, 0.099, 0.9892], [0.006, 0.994, 0.0, -0.296], [0.065, 0.82, 0.115, 0.9946], [0.016, 0.979, 0.006, -0.8674], [0.022, 0.978, 0.0, -0.6808], [0.031, 0.964, 0.005, -0.9468], [0.017, 0.97, 0.013, 0.477], [0.004, 0.807, 0.188, 0.998], [0.073, 0.777, 0.15, 0.9993], [0.02, 0.98, 0.0, -0.5267], [0.011, 0.989, 0.0, -0.296], [0.005, 0.845, 0.149, 0.9979], [0.022, 0.978, 0.0, -0.6808], [0.008, 0.91, 0.082, 0.991], [0.024, 0.85, 0.127, 0.9981], [0.0, 1.0, 0.0, 0.0], [0.022, 0.901, 0.077, 0.999], [0.019, 0.899, 0.082, 0.9972], [0.004, 0.892, 0.105, 0.9747], [0.026, 0.79, 0.184, 0.9995], [0.01, 0.892, 0.098, 0.9944], [0.013, 0.983, 0.004, -0.4404], [0.025, 0.849, 0.126, 0.9992], [0.044, 0.781, 0.175, 0.9997], [0.066, 0.867, 0.067, 0.0495], [0.025, 0.883, 0.091, 0.9759], [0.028, 0.929, 0.043, 0.6361], [0.041, 0.856, 0.103, 0.9997], [0.02, 0.866, 0.114, 0.9879], [0.03, 0.782, 0.188, 0.9997], [0.014, 0.837, 0.15, 0.9995], [0.095, 0.755, 0.15, 0.9917], [0.015, 0.902, 0.083, 0.9118], [0.032, 0.84, 0.128, 0.9992], [0.008, 0.887, 0.104, 0.9995], [0.071, 0.859, 0.07, 0.1496], [0.162, 0.763, 0.075, -0.9835], [0.096, 0.819, 0.085, -0.992], [0.02, 0.863, 0.117, 0.9815], [0.0, 0.889, 0.111, 0.925], [0.016, 0.978, 0.006, -0.9336], [0.029, 0.971, 0.0, -0.5267], [0.044, 0.871, 0.084, 0.9949], [0.043, 0.835, 0.122, 0.9967], [0.012, 0.848, 0.14, 0.9903], [0.005, 0.862, 0.133, 0.9984], [0.007, 0.98, 0.013, 0.5267], [0.009, 0.878, 0.113, 0.9944], [0.024, 0.845, 0.13, 0.9996], [0.024, 0.869, 0.108, 0.9575], [0.083, 0.777, 0.139, 0.9788], [0.042, 0.901, 0.057, 0.1027], [0.022, 0.978, 0.0, -0.69], [0.013, 0.846, 0.141, 0.9995], [0.02, 0.938, 0.042, 0.9122], [0.066, 0.824, 0.11, 0.9544], [0.036, 0.805, 0.16, 0.961], [0.033, 0.941, 0.026, -0.128], [0.013, 0.886, 0.101, 0.9956], [0.014, 0.88, 0.106, 0.9346], [0.021, 0.867, 0.111, 0.9995], [0.053, 0.947, 0.0, -0.9081], [0.011, 0.989, 0.0, -0.6808], [0.006, 0.889, 0.106, 0.9973], [0.03, 0.868, 0.103, 0.9992], [0.049, 0.819, 0.133, 0.9989], [0.008, 0.904, 0.088, 0.9652], [0.059, 0.811, 0.131, 0.9874], [0.0, 1.0, 0.0, 0.0], [0.017, 0.881, 0.102, 0.9542], [0.022, 0.808, 0.171, 0.9976], [0.018, 0.982, 0.0, -0.6808], [0.016, 0.866, 0.118, 0.972], [0.0, 0.959, 0.041, 0.7227], [0.027, 0.874, 0.098, 0.9958], [0.012, 0.983, 0.005, -0.4342], [0.021, 0.876, 0.103, 0.9909], [0.043, 0.931, 0.027, -0.5562], [0.088, 0.912, 0.0, -0.755], [0.028, 0.865, 0.107, 0.9977], [0.018, 0.879, 0.102, 0.9983], [0.083, 0.917, 0.0, -0.9678], [0.043, 0.838, 0.119, 0.9997], [0.017, 0.983, 0.0, -0.8997], [0.017, 0.899, 0.084, 0.9915], [0.044, 0.802, 0.154, 0.9943], [0.027, 0.84, 0.133, 0.9907], [0.0, 0.937, 0.063, 0.6326], [0.033, 0.961, 0.005, -0.9457], [0.0, 1.0, 0.0, 0.0], [0.025, 0.777, 0.198, 0.9994], [0.057, 0.774, 0.169, 0.8818], [0.067, 0.84, 0.093, 0.9934], [0.007, 0.865, 0.128, 0.9922], [0.007, 0.865, 0.128, 0.9922], [0.037, 0.776, 0.187, 0.9916], [0.103, 0.805, 0.092, -0.9459], [0.04, 0.96, 0.0, -0.9195], [0.036, 0.964, 0.0, -0.5267], [0.013, 0.83, 0.157, 0.998], [0.026, 0.962, 0.012, -0.6124], [0.011, 0.905, 0.083, 0.9766], [0.011, 0.905, 0.083, 0.9766], [0.028, 0.833, 0.138, 0.9996], [0.015, 0.816, 0.168, 0.9994], [0.035, 0.872, 0.092, 0.9931], [0.01, 0.981, 0.009, 0.3313], [0.098, 0.737, 0.164, 0.9996], [0.022, 0.969, 0.009, -0.6037], [0.014, 0.9, 0.086, 0.9949], [0.01, 0.884, 0.106, 0.9657], [0.0, 0.981, 0.019, 0.3818], [0.036, 0.791, 0.173, 0.9997], [0.01, 0.868, 0.122, 0.9988], [0.042, 0.874, 0.084, 0.9068], [0.0, 1.0, 0.0, 0.0], [0.029, 0.849, 0.122, 0.99], [0.044, 0.956, 0.0, -0.6808], [0.101, 0.873, 0.027, -0.8834], [0.081, 0.919, 0.0, -0.9081], [0.009, 0.877, 0.113, 0.996], [0.018, 0.906, 0.076, 0.9983], [0.015, 0.977, 0.008, -0.7037], [0.069, 0.837, 0.095, 0.9141], [0.022, 0.835, 0.143, 0.9935], [0.0, 0.845, 0.155, 0.986], [0.046, 0.859, 0.095, 0.9987], [0.038, 0.828, 0.135, 0.9872], [0.029, 0.971, 0.0, -0.5267], [0.024, 0.928, 0.048, 0.7605], [0.013, 0.89, 0.097, 0.9993], [0.075, 0.833, 0.091, 0.9769], [0.0, 1.0, 0.0, 0.0], [0.038, 0.882, 0.08, 0.998], [0.008, 0.913, 0.08, 0.9972], [0.021, 0.843, 0.136, 0.9996], [0.003, 0.877, 0.12, 0.9969], [0.037, 0.879, 0.083, 0.9961], [0.017, 0.859, 0.125, 0.9955], [0.009, 0.866, 0.126, 0.9934], [0.011, 0.989, 0.0, -0.296], [0.031, 0.872, 0.097, 0.9851], [0.0, 0.946, 0.054, 0.8625], [0.075, 0.856, 0.069, -0.9162], [0.013, 0.987, 0.0, -0.6808], [0.012, 0.886, 0.102, 0.9952], [0.006, 0.889, 0.105, 0.9958], [0.062, 0.937, 0.0, -0.7783], [0.0, 0.717, 0.283, 0.9817], [0.046, 0.944, 0.01, -0.9337], [0.01, 0.912, 0.078, 0.9294], [0.03, 0.896, 0.075, 0.9171], [0.035, 0.847, 0.118, 0.9998], [0.011, 0.989, 0.0, -0.8402], [0.011, 0.968, 0.021, 0.908], [0.035, 0.823, 0.142, 0.9999], [0.043, 0.765, 0.192, 0.9983], [0.009, 0.859, 0.131, 0.9995], [0.025, 0.971, 0.004, -0.9737], [0.012, 0.861, 0.127, 0.998], [0.078, 0.811, 0.111, 0.9828], [0.045, 0.921, 0.034, -0.9457], [0.045, 0.848, 0.107, 0.9996], [0.042, 0.779, 0.178, 0.9996], [0.013, 0.903, 0.084, 0.9965], [0.006, 0.904, 0.09, 0.962], [0.022, 0.81, 0.168, 0.9936], [0.056, 0.818, 0.127, 0.9997], [0.0, 0.9, 0.1, 0.9936], [0.019, 0.969, 0.012, -0.34], [0.022, 0.875, 0.103, 0.9976], [0.027, 0.871, 0.102, 0.9978], [0.035, 0.849, 0.116, 0.9991], [0.027, 0.845, 0.128, 0.9856], [0.016, 0.814, 0.17, 0.9998], [0.027, 0.96, 0.013, -0.5574], [0.124, 0.704, 0.172, 0.9951], [0.006, 0.782, 0.212, 0.9988], [0.012, 0.988, 0.0, -0.296], [0.007, 0.884, 0.109, 0.991], [0.035, 0.965, 0.0, -0.9081], [0.0, 0.928, 0.072, 0.8316], [0.0, 0.777, 0.223, 0.9313], [0.012, 0.822, 0.166, 0.9994], [0.017, 0.983, 0.0, -0.8299], [0.006, 0.881, 0.113, 0.9989], [0.05, 0.854, 0.096, 0.9575], [0.0, 0.981, 0.019, 0.8173], [0.033, 0.967, 0.0, -0.7998], [0.078, 0.784, 0.138, 0.9994], [0.017, 0.964, 0.019, 0.2342], [0.036, 0.951, 0.013, -0.4939], [0.0, 0.908, 0.092, 0.9951], [0.023, 0.935, 0.042, 0.7964], [0.017, 0.885, 0.097, 0.9747], [0.006, 0.819, 0.175, 0.9978], [0.065, 0.802, 0.133, 0.9989], [0.006, 0.818, 0.176, 0.9988], [0.037, 0.958, 0.005, -0.9633], [0.14, 0.787, 0.073, -0.9859], [0.023, 0.848, 0.13, 0.9987], [0.014, 0.872, 0.114, 0.9989], [0.016, 0.984, 0.0, -0.5267], [0.04, 0.852, 0.108, 0.9911], [0.03, 0.897, 0.073, 0.9982], [0.0, 0.9, 0.1, 0.8881], [0.012, 0.916, 0.071, 0.8658], [0.024, 0.881, 0.095, 0.9709], [0.012, 0.988, 0.0, -0.296], [0.028, 0.851, 0.121, 0.9977], [0.036, 0.832, 0.132, 0.9922], [0.02, 0.969, 0.012, -0.8385], [0.026, 0.974, 0.0, -0.9473], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.014, 0.974, 0.012, -0.5615], [0.095, 0.698, 0.207, 0.9983], [0.012, 0.957, 0.031, 0.4215], [0.022, 0.962, 0.015, -0.7506], [0.0, 0.977, 0.023, 0.4019], [0.035, 0.89, 0.074, 0.8931], [0.064, 0.773, 0.163, 0.9932], [0.013, 0.97, 0.017, 0.186], [0.0, 0.846, 0.154, 0.9906], [0.039, 0.947, 0.014, -0.4939], [0.033, 0.967, 0.0, -0.5267], [0.021, 0.87, 0.109, 0.9974], [0.05, 0.95, 0.0, -0.8402], [0.008, 0.992, 0.0, -0.6553], [0.046, 0.801, 0.152, 0.9975], [0.019, 0.94, 0.041, 0.7494], [0.0, 0.886, 0.114, 0.9829], [0.029, 0.806, 0.165, 0.9994], [0.04, 0.948, 0.013, -0.8875], [0.01, 0.901, 0.089, 0.9845], [0.045, 0.844, 0.111, 0.9933], [0.014, 0.87, 0.117, 0.9598], [0.021, 0.971, 0.007, -0.8967], [0.051, 0.815, 0.134, 0.9907], [0.077, 0.816, 0.107, 0.9994], [0.069, 0.866, 0.065, -0.3797], [0.061, 0.817, 0.122, 1.0], [0.032, 0.958, 0.01, -0.902], [0.02, 0.978, 0.002, -0.9465], [0.01, 0.85, 0.14, 0.9856], [0.028, 0.965, 0.007, -0.7351], [0.016, 0.901, 0.083, 0.9978], [0.0, 0.929, 0.071, 0.9414], [0.018, 0.891, 0.091, 0.9965], [0.034, 0.843, 0.123, 0.9956], [0.052, 0.865, 0.083, 0.9706], [0.038, 0.864, 0.098, 0.9976], [0.0, 1.0, 0.0, 0.0], [0.0, 0.967, 0.033, 0.6166], [0.062, 0.81, 0.127, 0.9887], [0.022, 0.88, 0.099, 0.9449], [0.03, 0.76, 0.21, 0.9998], [0.004, 0.77, 0.226, 0.999], [0.007, 0.906, 0.087, 0.9771], [0.073, 0.901, 0.026, -0.6249], [0.044, 0.822, 0.134, 0.9958], [0.028, 0.951, 0.021, -0.0258], [0.016, 0.879, 0.105, 0.9993], [0.082, 0.788, 0.129, 0.9996], [0.058, 0.762, 0.18, 0.9994], [0.036, 0.964, 0.0, -0.9441], [0.016, 0.833, 0.151, 0.9982], [0.019, 0.922, 0.059, 0.9686], [0.028, 0.824, 0.148, 0.9966], [0.041, 0.959, 0.0, -0.968], [0.033, 0.962, 0.004, -0.9892], [0.022, 0.891, 0.087, 0.9964], [0.021, 0.973, 0.005, -0.9106], [0.026, 0.879, 0.095, 0.9966], [0.0, 0.911, 0.089, 0.996], [0.033, 0.888, 0.079, 0.5859], [0.029, 0.841, 0.131, 0.999], [0.031, 0.853, 0.116, 0.9913], [0.055, 0.815, 0.13, 0.9792], [0.0, 0.795, 0.205, 0.9939], [0.075, 0.795, 0.13, 0.9477], [0.032, 0.799, 0.169, 0.9995], [0.012, 0.852, 0.136, 0.9987], [0.026, 0.974, 0.0, -0.5267], [0.028, 0.972, 0.0, -0.9081], [0.037, 0.948, 0.016, -0.8534], [0.031, 0.84, 0.129, 0.9996], [0.016, 0.886, 0.098, 0.9545], [0.101, 0.899, 0.0, -0.6597], [0.054, 0.868, 0.079, 0.973], [0.023, 0.897, 0.08, 0.9972], [0.066, 0.831, 0.103, 0.9838], [0.025, 0.975, 0.0, -0.9822], [0.019, 0.957, 0.024, 0.1506], [0.021, 0.855, 0.124, 0.9985], [0.102, 0.782, 0.116, 0.8394], [0.091, 0.712, 0.197, 0.9938], [0.157, 0.737, 0.106, -0.9964], [0.021, 0.838, 0.141, 0.999], [0.027, 0.863, 0.111, 0.9544], [0.011, 0.989, 0.0, -0.8402], [0.091, 0.851, 0.058, -0.1154], [0.027, 0.833, 0.139, 0.9996], [0.025, 0.975, 0.0, -0.296], [0.012, 0.947, 0.041, 0.6486], [0.034, 0.93, 0.036, 0.2023], [0.03, 0.874, 0.097, 0.9999], [0.022, 0.802, 0.176, 0.9998], [0.057, 0.8, 0.143, 0.9989], [0.066, 0.759, 0.175, 0.9983], [0.054, 0.821, 0.125, 0.9998], [0.044, 0.818, 0.138, 0.9997], [0.0, 1.0, 0.0, 0.0], [0.018, 0.953, 0.029, 0.9185], [0.038, 0.962, 0.0, -0.5267], [0.038, 0.954, 0.008, -0.99], [0.013, 0.961, 0.026, 0.6553], [0.019, 0.978, 0.003, -0.9706], [0.025, 0.969, 0.006, -0.9545], [0.014, 0.986, 0.0, -0.5267], [0.095, 0.773, 0.131, 0.9984], [0.048, 0.831, 0.121, 0.9984], [0.047, 0.867, 0.086, 0.9814], [0.011, 0.704, 0.286, 0.9944], [0.047, 0.867, 0.086, 0.9814], [0.01, 0.855, 0.136, 0.9783], [0.041, 0.846, 0.113, 0.9961], [0.04, 0.862, 0.098, 0.9973], [0.017, 0.892, 0.09, 0.999], [0.053, 0.947, 0.0, -0.9565], [0.071, 0.929, 0.0, -0.9657], [0.038, 0.854, 0.108, 0.9997], [0.0, 0.887, 0.113, 0.9896], [0.0, 0.753, 0.247, 0.9403], [0.072, 0.777, 0.151, 0.9982], [0.05, 0.912, 0.038, -0.0516], [0.004, 0.836, 0.16, 0.9992], [0.023, 0.968, 0.009, -0.4588], [0.014, 0.885, 0.1, 0.9995], [0.014, 0.986, 0.0, -0.7599], [0.003, 0.903, 0.094, 0.988], [0.063, 0.836, 0.1, 0.9746], [0.028, 0.936, 0.036, -0.0516], [0.018, 0.958, 0.024, -0.1635], [0.006, 0.854, 0.141, 0.9993], [0.019, 0.981, 0.0, -0.6808], [0.036, 0.956, 0.008, -0.9956], [0.004, 0.911, 0.085, 0.9954], [0.011, 0.885, 0.104, 0.9839], [0.012, 0.881, 0.106, 0.9804], [0.098, 0.774, 0.128, 0.9835], [0.007, 0.945, 0.048, 0.891], [0.02, 0.886, 0.093, 0.9886], [0.065, 0.818, 0.118, 0.9965], [0.0, 0.86, 0.14, 0.9081], [0.017, 0.979, 0.004, -0.8284], [0.014, 0.986, 0.0, -0.296], [0.031, 0.852, 0.117, 0.9899], [0.029, 0.96, 0.011, -0.8271], [0.066, 0.799, 0.135, 0.9998], [0.06, 0.86, 0.08, 0.9906], [0.023, 0.865, 0.112, 0.999], [0.009, 0.991, 0.0, -0.25], [0.018, 0.887, 0.096, 0.8953], [0.057, 0.761, 0.182, 0.9973], [0.057, 0.943, 0.0, -0.9595], [0.031, 0.84, 0.129, 0.9993], [0.019, 0.968, 0.013, -0.264], [0.019, 0.922, 0.059, 0.9698], [0.006, 0.872, 0.122, 0.9985], [0.01, 0.923, 0.067, 0.9842], [0.033, 0.905, 0.063, 0.7562], [0.011, 0.85, 0.139, 0.9969], [0.011, 0.897, 0.092, 0.9805], [0.026, 0.911, 0.062, 0.8817], [0.007, 0.895, 0.098, 0.9945], [0.006, 0.889, 0.105, 0.9874], [0.034, 0.844, 0.122, 0.9764], [0.017, 0.959, 0.024, 0.5621], [0.063, 0.929, 0.009, -0.8668], [0.062, 0.871, 0.067, 0.8667], [0.074, 0.926, 0.0, -0.9776], [0.091, 0.829, 0.081, -0.6799], [0.026, 0.835, 0.139, 0.9985], [0.016, 0.901, 0.084, 0.9958], [0.069, 0.843, 0.088, 0.9832], [0.011, 0.828, 0.161, 0.9997], [0.067, 0.823, 0.111, 0.9948], [0.064, 0.749, 0.187, 0.9999], [0.035, 0.87, 0.095, 0.9459], [0.036, 0.877, 0.087, 0.9879], [0.016, 0.887, 0.097, 0.9994], [0.01, 0.869, 0.12, 0.9973], [0.031, 0.859, 0.11, 0.9998], [0.022, 0.814, 0.164, 0.9966], [0.144, 0.749, 0.107, -0.9839], [0.027, 0.831, 0.143, 0.9999], [0.021, 0.867, 0.112, 0.9966], [0.01, 0.845, 0.145, 0.9987], [0.03, 0.847, 0.123, 0.9982], [0.063, 0.835, 0.102, 0.999], [0.1, 0.9, 0.0, -0.9576], [0.003, 0.943, 0.054, 0.9793], [0.032, 0.867, 0.101, 0.9959], [0.027, 0.826, 0.147, 0.9999], [0.031, 0.957, 0.012, -0.9697], [0.035, 0.801, 0.164, 0.9997], [0.0, 0.975, 0.025, 0.5983], [0.025, 0.906, 0.069, 0.9066], [0.03, 0.835, 0.135, 0.9998], [0.038, 0.79, 0.172, 0.9992], [0.032, 0.729, 0.239, 0.9201], [0.029, 0.89, 0.081, 0.9645], [0.024, 0.862, 0.114, 0.9999], [0.03, 0.852, 0.118, 0.9987], [0.009, 0.85, 0.14, 0.994], [0.0, 0.801, 0.199, 0.9168], [0.048, 0.687, 0.265, 0.9911], [0.017, 0.859, 0.124, 0.9876], [0.022, 0.829, 0.149, 0.9411], [0.0, 0.83, 0.17, 0.9745], [0.026, 0.79, 0.184, 0.9995], [0.015, 0.797, 0.188, 0.9998], [0.017, 0.869, 0.114, 0.9991], [0.036, 0.871, 0.093, 0.9967], [0.018, 0.696, 0.286, 0.9959], [0.03, 0.97, 0.0, -0.5267], [0.013, 0.987, 0.0, -0.296], [0.014, 0.827, 0.158, 0.9983], [0.026, 0.972, 0.002, -0.9397], [0.069, 0.792, 0.138, 0.9983], [0.018, 0.859, 0.123, 0.8248], [0.045, 0.842, 0.113, 0.9939], [0.036, 0.81, 0.155, 0.9973], [0.051, 0.914, 0.036, -0.8276], [0.018, 0.859, 0.123, 0.8248], [0.014, 0.98, 0.006, -0.6688], [0.057, 0.92, 0.022, -0.6597], [0.045, 0.832, 0.123, 0.9985], [0.015, 0.873, 0.112, 0.9984], [0.037, 0.893, 0.069, 0.9964], [0.034, 0.963, 0.003, -0.9791], [0.037, 0.785, 0.178, 0.9977], [0.026, 0.898, 0.075, 0.9873], [0.089, 0.81, 0.101, 0.9948], [0.019, 0.799, 0.181, 0.9993], [0.015, 0.867, 0.118, 0.9993], [0.026, 0.885, 0.089, 0.9989], [0.057, 0.927, 0.017, -0.6671], [0.04, 0.854, 0.106, 0.9996], [0.007, 0.986, 0.006, 0.0516], [0.039, 0.883, 0.079, 0.9875], [0.022, 0.978, 0.0, -0.9863], [0.037, 0.809, 0.154, 0.9996], [0.022, 0.925, 0.054, 0.7827], [0.016, 0.959, 0.025, 0.4714], [0.031, 0.853, 0.116, 0.9989], [0.03, 0.97, 0.0, -0.8807], [0.019, 0.981, 0.0, -0.7622], [0.022, 0.978, 0.0, -0.7783], [0.022, 0.973, 0.005, -0.6641], [0.021, 0.901, 0.078, 0.9432], [0.0, 0.95, 0.05, 0.9253], [0.037, 0.853, 0.11, 0.9923], [0.01, 0.983, 0.007, -0.1027], [0.042, 0.859, 0.099, 0.9941], [0.005, 0.868, 0.127, 0.9972], [0.022, 0.873, 0.106, 0.9944], [0.017, 0.957, 0.026, 0.6526], [0.044, 0.956, 0.0, -0.5267], [0.007, 0.84, 0.153, 0.9958], [0.026, 0.91, 0.064, 0.8482], [0.027, 0.87, 0.103, 0.9936], [0.036, 0.711, 0.253, 0.9993], [0.047, 0.779, 0.175, 0.9938], [0.0, 0.749, 0.251, 0.9944], [0.006, 0.909, 0.085, 0.9948], [0.104, 0.742, 0.154, 0.9957], [0.033, 0.834, 0.132, 0.9998], [0.063, 0.862, 0.076, 0.9695], [0.014, 0.924, 0.062, 0.9748], [0.028, 0.893, 0.079, 0.8909], [0.034, 0.842, 0.124, 0.9996], [0.021, 0.905, 0.074, 0.9796], [0.062, 0.818, 0.12, 0.996], [0.012, 0.843, 0.145, 0.9995], [0.091, 0.798, 0.111, 0.9834], [0.018, 0.934, 0.048, 0.5719], [0.032, 0.873, 0.095, 0.9618], [0.032, 0.956, 0.013, -0.8988], [0.029, 0.971, 0.0, -0.9388], [0.006, 0.985, 0.009, 0.2575], [0.015, 0.826, 0.159, 0.9948], [0.005, 0.779, 0.216, 0.9985], [0.127, 0.773, 0.1, 0.1007], [0.097, 0.782, 0.121, 0.9871], [0.025, 0.952, 0.022, -0.1779], [0.01, 0.899, 0.092, 0.9961], [0.031, 0.874, 0.095, 0.9992], [0.014, 0.917, 0.069, 0.99], [0.037, 0.85, 0.113, 0.9989], [0.035, 0.852, 0.113, 0.9996], [0.023, 0.974, 0.003, -0.91], [0.061, 0.68, 0.258, 0.9907], [0.006, 0.994, 0.0, -0.296], [0.008, 0.87, 0.122, 0.9995], [0.017, 0.967, 0.016, -0.0772], [0.0, 0.899, 0.101, 0.8832], [0.033, 0.946, 0.021, -0.296], [0.028, 0.797, 0.175, 0.9971], [0.053, 0.947, 0.0, -0.8516], [0.05, 0.942, 0.008, -0.9763], [0.011, 0.844, 0.145, 0.9897], [0.025, 0.825, 0.15, 0.9995], [0.021, 0.843, 0.136, 0.9985], [0.031, 0.969, 0.0, -0.784], [0.014, 0.98, 0.005, -0.5897], [0.037, 0.963, 0.0, -0.8402], [0.037, 0.887, 0.076, 0.9912], [0.015, 0.902, 0.083, 0.9857], [0.022, 0.873, 0.105, 0.9936], [0.045, 0.804, 0.152, 0.9998], [0.015, 0.817, 0.168, 0.9991], [0.124, 0.694, 0.183, 0.9948], [0.013, 0.977, 0.01, -0.8656], [0.021, 0.979, 0.0, -0.7783], [0.018, 0.877, 0.105, 0.9987], [0.022, 0.779, 0.199, 0.9819], [0.022, 0.779, 0.199, 0.9819], [0.021, 0.891, 0.087, 0.9478], [0.012, 0.866, 0.122, 0.9952], [0.034, 0.874, 0.092, 0.9578], [0.056, 0.853, 0.092, 0.8575], [0.047, 0.813, 0.14, 0.9959], [0.033, 0.872, 0.094, 0.9971], [0.02, 0.887, 0.092, 0.999], [0.048, 0.786, 0.166, 0.9993], [0.011, 0.887, 0.103, 0.9988], [0.006, 0.87, 0.124, 0.9885], [0.049, 0.868, 0.083, 0.9874], [0.034, 0.852, 0.114, 0.9987], [0.021, 0.949, 0.03, 0.4391], [0.022, 0.924, 0.054, 0.9938], [0.053, 0.947, 0.0, -0.8807], [0.043, 0.811, 0.146, 0.9996], [0.07, 0.712, 0.218, 0.9997], [0.038, 0.792, 0.17, 0.999], [0.008, 0.787, 0.205, 0.9997], [0.049, 0.822, 0.129, 0.9987], [0.012, 0.979, 0.009, -0.128], [0.026, 0.974, 0.0, -0.9503], [0.004, 0.853, 0.143, 0.9973], [0.014, 0.876, 0.11, 0.9872], [0.0, 0.725, 0.275, 0.9638], [0.024, 0.966, 0.01, -0.4588], [0.002, 0.882, 0.116, 0.9956], [0.065, 0.814, 0.121, 0.9976], [0.0, 0.956, 0.044, 0.6688], [0.012, 0.881, 0.107, 0.973], [0.117, 0.709, 0.174, 0.7184], [0.057, 0.943, 0.0, -0.9576], [0.045, 0.773, 0.182, 0.9998], [0.035, 0.855, 0.11, 0.9997], [0.121, 0.879, 0.0, -0.6808], [0.047, 0.822, 0.131, 0.9997], [0.089, 0.736, 0.175, 0.9999], [0.028, 0.877, 0.095, 0.9995], [0.131, 0.778, 0.091, -0.9972], [0.049, 0.802, 0.149, 0.999], [0.033, 0.826, 0.141, 0.9977], [0.095, 0.757, 0.148, 0.9939], [0.028, 0.963, 0.01, -0.6369], [0.084, 0.747, 0.168, 0.9989], [0.013, 0.886, 0.102, 0.9993], [0.052, 0.875, 0.073, 0.7891], [0.041, 0.867, 0.092, 0.9758], [0.005, 0.865, 0.13, 0.988], [0.08, 0.757, 0.163, 0.8343], [0.013, 0.891, 0.095, 0.9978], [0.032, 0.962, 0.006, -0.9559], [0.012, 0.855, 0.133, 0.9999], [0.009, 0.877, 0.114, 0.9953], [0.057, 0.874, 0.07, 0.0843], [0.039, 0.803, 0.158, 0.9957], [0.0, 0.872, 0.128, 0.6956], [0.016, 0.838, 0.146, 0.9997], [0.022, 0.978, 0.0, -0.9143], [0.0, 1.0, 0.0, 0.0], [0.008, 0.99, 0.003, -0.7131], [0.012, 0.692, 0.296, 0.9943], [0.025, 0.845, 0.13, 0.9994], [0.07, 0.815, 0.115, 0.9986], [0.035, 0.864, 0.101, 0.9995], [0.056, 0.944, 0.0, -0.8883], [0.091, 0.87, 0.039, -0.9966], [0.011, 0.869, 0.12, 0.9997], [0.055, 0.82, 0.125, 0.9997], [0.037, 0.833, 0.131, 0.9998], [0.05, 0.842, 0.108, 0.9994], [0.034, 0.864, 0.102, 0.9948], [0.038, 0.962, 0.0, -0.6808], [0.036, 0.95, 0.014, -0.9825], [0.0, 0.93, 0.07, 0.9669], [0.051, 0.725, 0.224, 0.9972], [0.019, 0.871, 0.11, 0.999], [0.008, 0.883, 0.109, 0.998], [0.053, 0.852, 0.094, 0.9941], [0.016, 0.962, 0.022, 0.2023], [0.036, 0.861, 0.104, 0.9969], [0.025, 0.972, 0.003, -0.8658], [0.019, 0.973, 0.007, -0.8221], [0.024, 0.927, 0.049, 0.5191], [0.007, 0.867, 0.126, 0.9866], [0.012, 0.842, 0.146, 0.9987], [0.018, 0.896, 0.085, 0.9987], [0.0, 0.911, 0.089, 0.9578], [0.03, 0.804, 0.166, 0.9973], [0.022, 0.978, 0.0, -0.7783], [0.091, 0.824, 0.085, -0.9172], [0.007, 0.993, 0.0, -0.296], [0.027, 0.83, 0.143, 0.9904], [0.005, 0.987, 0.008, 0.4404], [0.021, 0.896, 0.083, 0.9964], [0.049, 0.927, 0.024, -0.971], [0.024, 0.86, 0.116, 0.9985], [0.034, 0.906, 0.06, 0.8979], [0.024, 0.968, 0.008, -0.7783], [0.035, 0.932, 0.033, 0.2924], [0.024, 0.889, 0.087, 0.9948], [0.081, 0.75, 0.169, 0.991], [0.024, 0.858, 0.118, 0.9999], [0.011, 0.965, 0.023, 0.508], [0.023, 0.977, 0.0, -0.7783], [0.025, 0.826, 0.149, 0.9943], [0.034, 0.852, 0.114, 0.9977], [0.0, 0.73, 0.27, 0.9371], [0.021, 0.877, 0.102, 0.9702], [0.04, 0.919, 0.041, 0.5574], [0.01, 0.986, 0.004, -0.4019], [0.023, 0.855, 0.122, 0.9978], [0.0, 0.813, 0.187, 0.9872], [0.02, 0.911, 0.069, 0.9788], [0.007, 0.979, 0.015, 0.4588], [0.076, 0.855, 0.069, 0.5267], [0.029, 0.817, 0.153, 0.9981], [0.059, 0.826, 0.115, 0.9999], [0.027, 0.873, 0.1, 0.9957], [0.0, 0.934, 0.066, 0.8625], [0.021, 0.86, 0.119, 0.9953], [0.019, 0.869, 0.112, 0.9746], [0.029, 0.963, 0.007, -0.7845], [0.02, 0.98, 0.0, -0.6808], [0.019, 0.916, 0.065, 0.9986], [0.037, 0.713, 0.249, 0.9999], [0.03, 0.878, 0.091, 0.9928], [0.019, 0.974, 0.007, -0.993], [0.027, 0.962, 0.011, -0.9898], [0.02, 0.969, 0.011, -0.2185], [0.066, 0.934, 0.0, -0.4939], [0.021, 0.976, 0.003, -0.9973], [0.059, 0.803, 0.138, 0.9976], [0.016, 0.835, 0.149, 0.9998], [0.058, 0.832, 0.11, 0.9946], [0.028, 0.831, 0.14, 0.9993], [0.024, 0.853, 0.123, 0.9865], [0.08, 0.82, 0.1, 0.9711], [0.025, 0.954, 0.021, -0.1655], [0.115, 0.782, 0.103, -0.9051], [0.0, 0.976, 0.024, 0.6124], [0.0, 0.98, 0.02, 0.7003], [0.038, 0.817, 0.145, 0.9992], [0.014, 0.986, 0.0, -0.6808], [0.02, 0.975, 0.005, -0.5859], [0.025, 0.975, 0.0, -0.9042], [0.005, 0.866, 0.129, 0.9999], [0.003, 0.911, 0.086, 0.9665], [0.049, 0.872, 0.079, 0.9957], [0.025, 0.876, 0.099, 0.9994], [0.028, 0.833, 0.139, 0.9998], [0.024, 0.878, 0.098, 0.9974], [0.0, 0.839, 0.161, 0.9862], [0.023, 0.885, 0.092, 0.9985], [0.0, 0.848, 0.152, 0.9799], [0.005, 0.858, 0.137, 0.9955], [0.031, 0.969, 0.0, -0.765], [0.023, 0.968, 0.01, -0.6486], [0.007, 0.966, 0.026, 0.5416], [0.022, 0.834, 0.145, 0.9993], [0.017, 0.972, 0.011, -0.6592], [0.052, 0.8, 0.148, 0.999], [0.04, 0.775, 0.184, 0.9801], [0.091, 0.794, 0.115, 0.9953], [0.0, 0.882, 0.118, 0.9517], [0.005, 0.925, 0.07, 0.9779], [0.021, 0.857, 0.121, 0.9992], [0.034, 0.96, 0.006, -0.802], [0.054, 0.946, 0.0, -0.7959], [0.035, 0.824, 0.141, 0.9997], [0.008, 0.868, 0.123, 0.9976], [0.023, 0.961, 0.016, -0.4857], [0.046, 0.815, 0.139, 0.9997], [0.009, 0.991, 0.0, -0.673], [0.058, 0.854, 0.087, 0.9991], [0.043, 0.881, 0.076, 0.9857], [0.048, 0.838, 0.115, 0.998], [0.039, 0.795, 0.166, 0.9996], [0.013, 0.987, 0.0, -0.296], [0.048, 0.952, 0.0, -0.8402], [0.031, 0.849, 0.12, 0.9984], [0.021, 0.915, 0.064, 0.9815], [0.021, 0.878, 0.1, 0.9994], [0.008, 0.946, 0.046, 0.8941], [0.008, 0.832, 0.16, 0.9925], [0.017, 0.977, 0.005, -0.6369], [0.04, 0.944, 0.016, -0.4708], [0.088, 0.813, 0.099, 0.1875], [0.0, 0.942, 0.058, 0.8674], [0.0, 0.913, 0.087, 0.9758], [0.024, 0.889, 0.087, 0.9615], [0.027, 0.77, 0.204, 0.9994], [0.026, 0.891, 0.083, 0.9996], [0.043, 0.945, 0.012, -0.6486], [0.004, 0.884, 0.112, 0.9949], [0.018, 0.876, 0.106, 0.9991], [0.022, 0.978, 0.0, -0.5267], [0.0, 0.867, 0.133, 0.9934], [0.046, 0.843, 0.11, 0.9995], [0.029, 0.851, 0.12, 0.9993], [0.011, 0.94, 0.049, 0.6174], [0.05, 0.818, 0.132, 0.9999], [0.023, 0.977, 0.0, -0.6808], [0.01, 0.987, 0.003, -0.4588], [0.034, 0.966, 0.0, -0.296], [0.037, 0.816, 0.148, 0.9999], [0.0, 0.879, 0.121, 0.9481], [0.091, 0.834, 0.075, -0.9847], [0.025, 0.975, 0.0, -0.9598], [0.049, 0.858, 0.093, 0.9978], [0.032, 0.967, 0.001, -0.9618], [0.017, 0.95, 0.032, 0.1901], [0.043, 0.957, 0.0, -0.6808], [0.031, 0.969, 0.0, -0.7783], [0.011, 0.941, 0.048, 0.765], [0.039, 0.779, 0.183, 0.9993], [0.042, 0.857, 0.101, 0.999], [0.012, 0.921, 0.067, 0.995], [0.009, 0.866, 0.125, 0.9855], [0.039, 0.87, 0.091, 0.9568], [0.011, 0.894, 0.096, 0.9991], [0.04, 0.748, 0.212, 0.9998], [0.033, 0.861, 0.106, 0.9983], [0.024, 0.97, 0.007, -0.8994], [0.038, 0.939, 0.023, -0.4767], [0.022, 0.978, 0.0, -0.5707], [0.106, 0.805, 0.089, -0.6228], [0.007, 0.875, 0.118, 0.9965], [0.0, 1.0, 0.0, 0.0], [0.03, 0.97, 0.0, -0.6553], [0.054, 0.893, 0.054, 0.4649], [0.0, 0.963, 0.037, 0.7013], [0.028, 0.972, 0.0, -0.9274], [0.037, 0.838, 0.126, 0.6486], [0.045, 0.809, 0.146, 0.9997], [0.045, 0.809, 0.146, 0.9997], [0.045, 0.809, 0.146, 0.9997], [0.078, 0.779, 0.144, 0.9897], [0.0, 0.933, 0.067, 0.8957], [0.112, 0.826, 0.062, -0.9977], [0.022, 0.843, 0.135, 0.9995], [0.039, 0.854, 0.107, 0.9988], [0.033, 0.877, 0.09, 0.9995], [0.0, 0.651, 0.349, 0.9686], [0.036, 0.857, 0.108, 0.9992], [0.025, 0.825, 0.151, 0.9956], [0.039, 0.864, 0.097, 0.9999], [0.002, 0.94, 0.059, 0.9841], [0.005, 0.924, 0.071, 0.992], [0.031, 0.911, 0.057, 0.8246], [0.027, 0.968, 0.005, -0.8843], [0.009, 0.953, 0.038, 0.9832], [0.017, 0.847, 0.136, 0.9788], [0.031, 0.853, 0.116, 0.9996], [0.03, 0.961, 0.009, -0.8402], [0.046, 0.851, 0.103, 1.0], [0.0, 1.0, 0.0, 0.0], [0.02, 0.823, 0.157, 0.9996], [0.084, 0.909, 0.007, -0.9806], [0.013, 0.874, 0.113, 0.9964], [0.01, 0.983, 0.008, 0.0], [0.033, 0.965, 0.002, -0.9859], [0.018, 0.724, 0.259, 0.9962], [0.025, 0.962, 0.013, -0.549], [0.066, 0.784, 0.15, 0.9981], [0.022, 0.859, 0.119, 0.9998], [0.0, 0.855, 0.145, 0.9943], [0.026, 0.968, 0.006, -0.7882], [0.045, 0.955, 0.0, -0.9803], [0.028, 0.863, 0.109, 0.9995], [0.018, 0.865, 0.117, 0.9984], [0.021, 0.893, 0.086, 0.9999], [0.048, 0.854, 0.097, 0.9972], [0.029, 0.885, 0.086, 0.6486], [0.008, 0.988, 0.004, -0.8353], [0.079, 0.82, 0.101, 0.9834], [0.006, 0.979, 0.014, 0.8544], [0.01, 0.906, 0.084, 0.986], [0.013, 0.886, 0.102, 0.9984], [0.008, 0.816, 0.176, 0.9968], [0.051, 0.949, 0.0, -0.836], [0.033, 0.859, 0.108, 0.9936], [0.026, 0.802, 0.172, 0.9993], [0.045, 0.828, 0.127, 0.9998], [0.031, 0.853, 0.117, 0.9988], [0.022, 0.811, 0.167, 0.9996], [0.009, 0.981, 0.01, 0.0772], [0.023, 0.937, 0.04, 0.8126], [0.01, 0.945, 0.045, 0.8172], [0.01, 0.919, 0.071, 0.9836], [0.007, 0.838, 0.155, 0.9988], [0.016, 0.904, 0.08, 0.9947], [0.03, 0.803, 0.167, 0.9999], [0.096, 0.786, 0.118, 0.9772], [0.06, 0.902, 0.038, -0.1513], [0.0, 0.954, 0.046, 0.7003], [0.06, 0.719, 0.222, 0.9961], [0.055, 0.782, 0.163, 0.9985], [0.011, 0.989, 0.0, -0.9446], [0.014, 0.983, 0.003, -0.8074], [0.069, 0.712, 0.22, 0.9952], [0.024, 0.879, 0.097, 0.997], [0.033, 0.925, 0.042, 0.3254], [0.039, 0.957, 0.004, -0.9628], [0.028, 0.93, 0.043, 0.798], [0.009, 0.83, 0.161, 0.999], [0.031, 0.839, 0.13, 0.9985], [0.014, 0.976, 0.011, -0.296], [0.071, 0.929, 0.0, -0.9693], [0.016, 0.977, 0.008, -0.9396], [0.062, 0.834, 0.104, 0.9947], [0.014, 0.854, 0.131, 0.944], [0.014, 0.953, 0.033, 0.4215], [0.026, 0.952, 0.022, -0.2244], [0.0, 1.0, 0.0, 0.0], [0.019, 0.976, 0.005, -0.6486], [0.0, 1.0, 0.0, 0.0], [0.03, 0.97, 0.0, -0.875], [0.036, 0.793, 0.171, 0.9999], [0.006, 0.984, 0.011, 0.6531], [0.016, 0.958, 0.026, 0.9264], [0.066, 0.808, 0.126, 0.9537], [0.021, 0.946, 0.033, 0.3612], [0.024, 0.877, 0.099, 0.6908], [0.054, 0.819, 0.127, 0.998], [0.012, 0.976, 0.011, 0.1779], [0.0, 0.851, 0.149, 0.9944], [0.048, 0.952, 0.0, -0.9877], [0.035, 0.868, 0.098, 0.9931], [0.016, 0.82, 0.163, 0.991], [0.025, 0.975, 0.0, -0.9444], [0.039, 0.961, 0.0, -0.9728], [0.058, 0.942, 0.0, -0.7783], [0.013, 0.98, 0.007, -0.8466], [0.04, 0.786, 0.174, 0.9995], [0.053, 0.922, 0.025, -0.3612], [0.034, 0.963, 0.003, -0.9631], [0.026, 0.872, 0.102, 0.8851], [0.004, 0.933, 0.063, 0.9817], [0.025, 0.877, 0.098, 0.9997], [0.029, 0.862, 0.109, 0.9997], [0.043, 0.808, 0.149, 0.9999], [0.019, 0.981, 0.0, -0.743], [0.089, 0.911, 0.0, -0.9657], [0.01, 0.93, 0.06, 0.9451], [0.032, 0.954, 0.014, -0.6369], [0.024, 0.868, 0.108, 0.9997], [0.031, 0.862, 0.107, 0.9989], [0.02, 0.885, 0.095, 0.9936], [0.03, 0.843, 0.128, 1.0], [0.013, 0.97, 0.017, 0.1779], [0.042, 0.958, 0.0, -0.9441], [0.056, 0.872, 0.073, 0.8865], [0.036, 0.89, 0.074, 0.5719], [0.018, 0.867, 0.115, 0.9983], [0.028, 0.891, 0.081, 0.9961], [0.03, 0.782, 0.188, 0.9849], [0.018, 0.93, 0.052, 0.8463], [0.031, 0.969, 0.0, -0.8883], [0.016, 0.984, 0.0, -0.5803], [0.029, 0.971, 0.0, -0.8402], [0.051, 0.874, 0.075, 0.8856], [0.046, 0.914, 0.04, -0.2998], [0.018, 0.982, 0.0, -0.5267], [0.012, 0.894, 0.094, 0.9832], [0.003, 0.984, 0.014, 0.897], [0.016, 0.974, 0.009, -0.2023], [0.082, 0.698, 0.221, 0.9829], [0.051, 0.88, 0.069, 0.9759], [0.06, 0.768, 0.172, 0.9976], [0.069, 0.918, 0.014, -0.9371], [0.053, 0.947, 0.0, -0.9571], [0.027, 0.973, 0.0, -0.9081], [0.0, 0.81, 0.19, 0.886], [0.012, 0.895, 0.093, 0.994], [0.028, 0.965, 0.008, -0.9822], [0.045, 0.819, 0.137, 0.9984], [0.04, 0.832, 0.128, 0.9997], [0.118, 0.787, 0.095, 0.2444], [0.038, 0.869, 0.093, 0.9824], [0.036, 0.896, 0.067, 0.9946], [0.074, 0.83, 0.095, 0.9049], [0.026, 0.946, 0.028, 0.0258], [0.03, 0.962, 0.008, -0.9909], [0.021, 0.961, 0.018, 0.2023], [0.032, 0.787, 0.181, 0.9996], [0.025, 0.861, 0.114, 0.9986], [0.022, 0.978, 0.0, -0.5267], [0.0, 1.0, 0.0, 0.0], [0.021, 0.968, 0.011, -0.4284], [0.032, 0.968, 0.0, -0.7783], [0.004, 0.895, 0.1, 0.9917], [0.037, 0.96, 0.002, -0.9412], [0.078, 0.911, 0.01, -0.9274], [0.049, 0.951, 0.0, -0.7339], [0.151, 0.784, 0.065, -0.9983], [0.036, 0.879, 0.085, 0.88], [0.0, 0.883, 0.117, 0.9376], [0.051, 0.826, 0.122, 0.9654], [0.014, 0.852, 0.135, 0.998], [0.017, 0.981, 0.001, -0.9746], [0.055, 0.882, 0.063, 0.9179], [0.02, 0.852, 0.128, 0.9988], [0.006, 0.916, 0.077, 0.9913], [0.022, 0.978, 0.0, -0.9409], [0.022, 0.978, 0.0, -0.9615], [0.054, 0.839, 0.107, 0.9993], [0.031, 0.969, 0.0, -0.6808], [0.013, 0.981, 0.006, -0.7959], [0.065, 0.809, 0.126, 0.9419], [0.01, 0.891, 0.1, 0.986], [0.031, 0.864, 0.105, 0.9696], [0.007, 0.811, 0.182, 0.9933], [0.056, 0.794, 0.15, 0.9995], [0.048, 0.946, 0.006, -0.9612], [0.012, 0.885, 0.103, 0.9976], [0.083, 0.831, 0.087, 0.5986], [0.039, 0.87, 0.091, 0.9997], [0.033, 0.849, 0.118, 0.9963], [0.025, 0.834, 0.14, 0.9943], [0.02, 0.799, 0.18, 0.964], [0.054, 0.772, 0.174, 0.9786], [0.017, 0.882, 0.101, 0.9908], [0.063, 0.823, 0.113, 0.9924], [0.052, 0.846, 0.102, 0.999], [0.023, 0.886, 0.091, 0.9998], [0.055, 0.814, 0.131, 0.9969], [0.029, 0.802, 0.169, 0.999], [0.021, 0.979, 0.0, -0.6103], [0.027, 0.871, 0.101, 0.9637], [0.032, 0.965, 0.003, -0.9827], [0.005, 0.986, 0.009, 0.3818], [0.043, 0.839, 0.118, 0.9973], [0.034, 0.963, 0.003, -0.9898], [0.092, 0.908, 0.0, -0.9758], [0.027, 0.971, 0.002, -0.933], [0.0, 0.814, 0.186, 0.8932], [0.014, 0.82, 0.166, 0.993], [0.015, 0.978, 0.007, -0.5903], [0.017, 0.983, 0.0, -0.5707], [0.021, 0.979, 0.0, -0.5707], [0.028, 0.837, 0.136, 0.9978], [0.014, 0.961, 0.025, 0.4215], [0.053, 0.947, 0.0, -0.924], [0.0, 0.994, 0.006, 0.3049], [0.024, 0.974, 0.002, -0.9605], [0.009, 0.986, 0.005, -0.3182], [0.023, 0.878, 0.099, 0.9913], [0.019, 0.852, 0.129, 0.9957], [0.0, 0.917, 0.083, 0.9622], [0.0, 0.863, 0.137, 0.9661], [0.0, 0.957, 0.043, 0.4215], [0.02, 0.842, 0.139, 0.9918], [0.056, 0.744, 0.2, 0.9756], [0.056, 0.944, 0.0, -0.8402], [0.032, 0.954, 0.015, -0.9426], [0.027, 0.885, 0.088, 0.9419], [0.029, 0.959, 0.012, -0.7663], [0.031, 0.845, 0.124, 0.9981], [0.013, 0.916, 0.071, 0.9606], [0.017, 0.983, 0.0, -0.8807], [0.006, 0.802, 0.192, 0.9954], [0.011, 0.974, 0.016, 0.0258], [0.046, 0.954, 0.0, -0.8957], [0.013, 0.964, 0.023, 0.5106], [0.039, 0.935, 0.026, -0.6848], [0.027, 0.969, 0.003, -0.9847], [0.011, 0.976, 0.013, 0.3939], [0.011, 0.987, 0.002, -0.934], [0.019, 0.919, 0.062, 0.9605], [0.019, 0.968, 0.014, -0.6293], [0.0, 0.904, 0.096, 0.998], [0.012, 0.864, 0.124, 0.998], [0.059, 0.879, 0.062, 0.9468], [0.029, 0.959, 0.012, -0.8516], [0.076, 0.784, 0.139, 0.9733], [0.018, 0.982, 0.0, -0.6808], [0.021, 0.979, 0.0, -0.6808], [0.032, 0.965, 0.004, -0.8934], [0.018, 0.908, 0.074, 0.9972], [0.013, 0.932, 0.055, 0.9922], [0.035, 0.824, 0.141, 0.9941], [0.028, 0.969, 0.003, -0.9842], [0.045, 0.885, 0.07, 0.9977], [0.0, 0.84, 0.16, 0.8555], [0.05, 0.868, 0.082, 0.9962], [0.016, 0.866, 0.118, 0.999], [0.0, 0.882, 0.118, 0.7506], [0.034, 0.884, 0.082, 0.9987], [0.029, 0.828, 0.143, 0.9992], [0.025, 0.971, 0.004, -0.9549], [0.068, 0.816, 0.117, 0.9951], [0.04, 0.814, 0.146, 0.9994], [0.028, 0.969, 0.002, -0.949], [0.027, 0.967, 0.006, -0.9325], [0.023, 0.847, 0.13, 0.9993], [0.029, 0.83, 0.141, 0.9786], [0.024, 0.849, 0.127, 0.9986], [0.025, 0.846, 0.129, 0.9993], [0.016, 0.882, 0.102, 0.9957], [0.038, 0.956, 0.006, -0.8963], [0.021, 0.87, 0.109, 0.9988], [0.029, 0.897, 0.075, 0.9041], [0.024, 0.841, 0.135, 0.9998], [0.07, 0.794, 0.136, 0.9995], [0.02, 0.975, 0.005, -0.9692], [0.0, 1.0, 0.0, 0.0], [0.077, 0.86, 0.064, -0.6492], [0.015, 0.905, 0.08, 0.9969], [0.011, 0.811, 0.178, 0.9863], [0.04, 0.819, 0.141, 0.9994], [0.0, 1.0, 0.0, 0.0], [0.021, 0.862, 0.117, 0.9996], [0.02, 0.741, 0.239, 0.9975], [0.03, 0.833, 0.137, 0.9988], [0.02, 0.974, 0.006, -0.6808], [0.044, 0.823, 0.133, 0.9934], [0.042, 0.821, 0.137, 0.9992], [0.009, 0.887, 0.104, 0.9446], [0.014, 0.887, 0.098, 0.9834], [0.005, 0.882, 0.113, 0.9876], [0.059, 0.87, 0.071, 0.9817], [0.032, 0.957, 0.011, -0.9022], [0.014, 0.911, 0.075, 0.9928], [0.023, 0.971, 0.006, -0.8898], [0.02, 0.967, 0.013, -0.5349], [0.006, 0.912, 0.082, 0.9828], [0.025, 0.834, 0.141, 0.9946], [0.02, 0.861, 0.119, 0.8957], [0.031, 0.969, 0.0, -0.4939], [0.052, 0.808, 0.141, 1.0], [0.07, 0.93, 0.0, -0.9477], [0.017, 0.854, 0.129, 0.9808], [0.053, 0.767, 0.18, 0.9997], [0.012, 0.863, 0.125, 0.9969], [0.012, 0.988, 0.0, -0.8176], [0.045, 0.955, 0.0, -0.5267], [0.017, 0.91, 0.074, 0.9988], [0.022, 0.966, 0.012, -0.2263], [0.017, 0.903, 0.08, 0.9972], [0.026, 0.837, 0.137, 0.994], [0.019, 0.976, 0.005, -0.6705], [0.024, 0.858, 0.118, 0.9964], [0.057, 0.761, 0.182, 0.9998], [0.044, 0.824, 0.132, 0.9994], [0.032, 0.968, 0.0, -0.7783], [0.02, 0.956, 0.024, 0.1027], [0.057, 0.83, 0.113, 0.9978], [0.031, 0.94, 0.029, 0.1027], [0.021, 0.979, 0.0, -0.8316], [0.0, 0.788, 0.212, 0.993], [0.02, 0.956, 0.024, 0.593], [0.019, 0.815, 0.166, 0.9986], [0.0, 0.902, 0.098, 0.9769], [0.038, 0.839, 0.123, 0.9993], [0.01, 0.982, 0.008, -0.1027], [0.01, 0.874, 0.117, 0.9719], [0.033, 0.699, 0.268, 0.9978], [0.138, 0.776, 0.087, -0.9961], [0.005, 0.93, 0.064, 0.9827], [0.023, 0.823, 0.155, 0.9984], [0.015, 0.957, 0.027, 0.0644], [0.052, 0.874, 0.074, 0.7868], [0.048, 0.835, 0.118, 0.9911], [0.022, 0.978, 0.0, -0.5267], [0.045, 0.871, 0.084, 0.9893], [0.011, 0.903, 0.086, 0.9797], [0.027, 0.973, 0.0, -0.8864], [0.05, 0.795, 0.155, 0.9997], [0.016, 0.971, 0.013, -0.3612], [0.028, 0.835, 0.138, 0.989], [0.0, 1.0, 0.0, 0.0], [0.019, 0.845, 0.136, 0.9993], [0.038, 0.962, 0.0, -0.9393], [0.0, 0.953, 0.047, 0.872], [0.048, 0.862, 0.09, 0.9568], [0.016, 0.901, 0.083, 0.9733], [0.0, 0.923, 0.077, 0.9468], [0.016, 0.87, 0.114, 0.9974], [0.017, 0.872, 0.111, 0.9955], [0.014, 0.986, 0.0, -0.296], [0.094, 0.768, 0.138, 0.9934], [0.045, 0.838, 0.117, 0.999], [0.035, 0.839, 0.126, 0.9996], [0.027, 0.963, 0.01, -0.8089], [0.041, 0.851, 0.108, 0.996], [0.038, 0.915, 0.047, 0.3561], [0.055, 0.945, 0.0, -0.5267], [0.058, 0.814, 0.128, 0.9977], [0.032, 0.968, 0.0, -0.2263], [0.052, 0.819, 0.129, 0.9999], [0.015, 0.913, 0.072, 0.9728], [0.037, 0.789, 0.174, 0.9995], [0.013, 0.894, 0.093, 0.9977], [0.026, 0.901, 0.073, 0.9912], [0.054, 0.798, 0.148, 0.9814], [0.034, 0.821, 0.145, 0.9951], [0.012, 0.881, 0.107, 0.996], [0.016, 0.917, 0.067, 0.8625], [0.039, 0.908, 0.053, 0.6517], [0.01, 0.99, 0.0, -0.296], [0.032, 0.857, 0.111, 0.9792], [0.029, 0.971, 0.0, -0.6808], [0.0, 0.989, 0.011, 0.3182], [0.014, 0.976, 0.009, -0.128], [0.024, 0.96, 0.016, 0.5466], [0.0, 0.926, 0.074, 0.8677], [0.064, 0.769, 0.167, 0.9998], [0.035, 0.88, 0.085, 0.9739], [0.025, 0.89, 0.084, 0.9854], [0.0, 0.931, 0.069, 0.9828], [0.203, 0.62, 0.177, -0.9668], [0.0, 0.889, 0.111, 0.9894], [0.034, 0.867, 0.099, 0.999], [0.02, 0.89, 0.09, 0.9989], [0.0, 0.868, 0.132, 0.9864], [0.01, 0.89, 0.1, 0.9861], [0.052, 0.948, 0.0, -0.8402], [0.019, 0.856, 0.125, 0.8519], [0.044, 0.902, 0.054, 0.128], [0.065, 0.825, 0.11, 0.9852], [0.057, 0.793, 0.15, 0.9965], [0.064, 0.803, 0.133, 0.9986], [0.008, 0.934, 0.058, 0.9399], [0.019, 0.846, 0.135, 0.9985], [0.006, 0.945, 0.05, 0.9129], [0.014, 0.876, 0.11, 0.9994], [0.025, 0.945, 0.03, 0.4152], [0.012, 0.864, 0.124, 0.9981], [0.034, 0.888, 0.078, 0.9988], [0.045, 0.942, 0.013, -0.6486], [0.066, 0.842, 0.092, 0.9995], [0.011, 0.969, 0.02, 0.4404], [0.064, 0.816, 0.12, 0.9951], [0.071, 0.811, 0.118, 0.9967], [0.046, 0.954, 0.0, -0.7783], [0.032, 0.832, 0.136, 0.9961], [0.016, 0.819, 0.165, 0.9984], [0.024, 0.847, 0.129, 0.9993], [0.025, 0.865, 0.109, 0.9998], [0.015, 0.847, 0.138, 0.9977], [0.092, 0.85, 0.057, -0.9112], [0.026, 0.896, 0.077, 0.7815], [0.074, 0.793, 0.133, 0.9977], [0.062, 0.834, 0.103, 0.9925], [0.026, 0.974, 0.0, -0.8807], [0.02, 0.965, 0.015, -0.128], [0.021, 0.979, 0.0, -0.8529], [0.038, 0.761, 0.201, 0.8338], [0.017, 0.872, 0.111, 0.9991], [0.018, 0.972, 0.01, -0.6628], [0.021, 0.889, 0.091, 0.9872], [0.116, 0.813, 0.07, -0.9991], [0.026, 0.963, 0.011, -0.4753], [0.037, 0.891, 0.072, 0.802], [0.0, 0.915, 0.085, 0.9355], [0.016, 0.984, 0.0, -0.9517], [0.027, 0.819, 0.153, 0.9992], [0.024, 0.972, 0.004, -0.7717], [0.035, 0.807, 0.158, 0.9999], [0.0, 0.87, 0.13, 0.7269], [0.006, 0.994, 0.0, -0.4184], [0.02, 0.856, 0.124, 0.9821], [0.024, 0.863, 0.113, 0.9985], [0.014, 0.851, 0.135, 0.9995], [0.0, 1.0, 0.0, 0.0], [0.038, 0.962, 0.0, -0.296], [0.03, 0.855, 0.115, 0.9888], [0.027, 0.798, 0.174, 0.9986], [0.02, 0.886, 0.094, 0.9996], [0.06, 0.691, 0.249, 0.9987], [0.007, 0.849, 0.143, 0.9876], [0.013, 0.802, 0.185, 0.9993], [0.022, 0.842, 0.135, 0.9973], [0.01, 0.99, 0.0, -0.296], [0.025, 0.887, 0.088, 0.9961], [0.048, 0.834, 0.119, 0.9997], [0.019, 0.977, 0.004, -0.7998], [0.043, 0.813, 0.144, 0.9996], [0.096, 0.781, 0.122, 0.9973], [0.011, 0.789, 0.2, 0.9996], [0.067, 0.85, 0.082, 0.9343], [0.013, 0.893, 0.094, 0.9992], [0.036, 0.964, 0.0, -0.6808], [0.059, 0.791, 0.151, 0.9966], [0.044, 0.871, 0.085, 0.9907], [0.034, 0.966, 0.0, -0.6808], [0.024, 0.916, 0.06, 0.9874], [0.087, 0.784, 0.129, 0.8821], [0.094, 0.82, 0.086, -0.8375], [0.035, 0.841, 0.123, 0.9995], [0.026, 0.839, 0.135, 0.999], [0.025, 0.877, 0.097, 0.9963], [0.134, 0.725, 0.141, 0.9263], [0.0, 0.654, 0.346, 0.9652], [0.0, 0.888, 0.112, 0.5859], [0.009, 0.89, 0.102, 0.9977], [0.022, 0.868, 0.111, 0.9983], [0.02, 0.914, 0.066, 0.9869], [0.015, 0.888, 0.097, 0.9996], [0.005, 0.988, 0.007, 0.2225], [0.004, 0.926, 0.07, 0.9776], [0.009, 0.872, 0.119, 0.9986], [0.009, 0.986, 0.005, -0.4098], [0.013, 0.969, 0.018, 0.6808], [0.029, 0.971, 0.0, -0.6114], [0.027, 0.883, 0.09, 0.9898], [0.007, 0.822, 0.171, 0.9908], [0.02, 0.901, 0.079, 0.8807], [0.047, 0.874, 0.079, 0.956], [0.025, 0.846, 0.129, 0.9993], [0.0, 0.947, 0.053, 0.3612], [0.065, 0.757, 0.178, 0.9975], [0.009, 0.896, 0.094, 0.9522], [0.038, 0.853, 0.109, 0.9962], [0.063, 0.812, 0.124, 0.9905], [0.011, 0.968, 0.022, 0.6662], [0.011, 0.979, 0.01, -0.1179], [0.019, 0.886, 0.095, 0.999], [0.03, 0.937, 0.033, 0.8474], [0.012, 0.844, 0.144, 0.9797], [0.013, 0.837, 0.15, 0.9963], [0.095, 0.861, 0.045, -0.9896], [0.137, 0.764, 0.099, -0.9919], [0.007, 0.786, 0.207, 0.9997], [0.008, 0.927, 0.064, 0.946], [0.016, 0.84, 0.144, 0.991], [0.0, 0.934, 0.066, 0.6249], [0.013, 0.88, 0.107, 0.9657], [0.009, 0.985, 0.006, -0.1027], [0.011, 0.899, 0.091, 0.989], [0.03, 0.915, 0.055, 0.9752], [0.036, 0.958, 0.005, -0.9876], [0.011, 0.89, 0.099, 0.9925], [0.025, 0.975, 0.0, -0.5267], [0.054, 0.942, 0.003, -0.9678], [0.045, 0.822, 0.133, 0.9968], [0.036, 0.913, 0.05, 0.2157], [0.064, 0.821, 0.116, 0.9888], [0.033, 0.817, 0.15, 0.9976], [0.04, 0.89, 0.071, 0.993], [0.026, 0.97, 0.004, -0.9765], [0.059, 0.89, 0.051, 0.2491], [0.065, 0.817, 0.118, 0.9844], [0.021, 0.946, 0.032, 0.8964], [0.062, 0.938, 0.0, -0.7306], [0.01, 0.832, 0.159, 0.9959], [0.017, 0.983, 0.0, -0.8807], [0.043, 0.824, 0.133, 0.9888], [0.021, 0.953, 0.026, 0.6298], [0.025, 0.865, 0.11, 0.9999], [0.033, 0.862, 0.105, 0.9996], [0.019, 0.874, 0.106, 0.9995], [0.036, 0.96, 0.004, -0.9266], [0.007, 0.822, 0.171, 0.9998], [0.026, 0.964, 0.01, -0.8275], [0.099, 0.805, 0.096, 0.6379], [0.015, 0.985, 0.0, -0.8402], [0.078, 0.776, 0.146, 0.9995], [0.033, 0.937, 0.03, 0.0], [0.0, 0.889, 0.111, 0.7506], [0.112, 0.797, 0.091, -0.984], [0.028, 0.892, 0.08, 0.9925], [0.029, 0.867, 0.104, 0.9924], [0.057, 0.84, 0.102, 0.9983], [0.012, 0.988, 0.0, -0.296], [0.007, 0.982, 0.011, 0.6072], [0.013, 0.946, 0.042, 0.9647], [0.01, 0.931, 0.059, 0.9718], [0.008, 0.983, 0.009, 0.0772], [0.028, 0.972, 0.0, -0.7088], [0.004, 0.847, 0.149, 0.9977], [0.066, 0.821, 0.113, 0.9981], [0.008, 0.926, 0.065, 0.9656], [0.015, 0.862, 0.123, 0.9995], [0.039, 0.826, 0.135, 0.9934], [0.041, 0.818, 0.141, 0.9994], [0.051, 0.838, 0.111, 0.9926], [0.012, 0.988, 0.0, -0.296], [0.0, 0.901, 0.099, 0.969], [0.016, 0.984, 0.0, -0.8541], [0.009, 0.931, 0.061, 0.9761], [0.02, 0.894, 0.086, 0.9948], [0.009, 0.837, 0.154, 0.9907], [0.016, 0.981, 0.003, -0.924], [0.009, 0.886, 0.106, 0.9217], [0.01, 0.881, 0.109, 0.9868], [0.029, 0.834, 0.137, 0.9993], [0.023, 0.895, 0.082, 0.9923], [0.028, 0.911, 0.06, 0.9893], [0.021, 0.976, 0.003, -0.9378], [0.053, 0.907, 0.04, -0.7834], [0.0, 0.938, 0.062, 0.5423], [0.059, 0.889, 0.052, -0.6486], [0.0, 0.896, 0.104, 0.9946], [0.032, 0.894, 0.073, 0.9446], [0.004, 0.897, 0.099, 0.9898], [0.02, 0.896, 0.085, 0.9895], [0.094, 0.698, 0.208, 0.9961], [0.016, 0.977, 0.007, -0.9344], [0.024, 0.858, 0.118, 0.9999], [0.108, 0.729, 0.164, 0.4003], [0.031, 0.89, 0.079, 0.9021], [0.015, 0.985, 0.0, -0.5349], [0.038, 0.952, 0.01, -0.8176], [0.059, 0.772, 0.168, 0.9994], [0.052, 0.839, 0.109, 0.9928], [0.052, 0.842, 0.106, 0.9944], [0.065, 0.785, 0.15, 0.9998], [0.011, 0.989, 0.0, -0.6808], [0.0, 0.995, 0.005, 0.5095], [0.087, 0.766, 0.147, 0.9959], [0.0, 0.957, 0.043, 0.3612], [0.038, 0.954, 0.008, -0.8493], [0.025, 0.975, 0.0, -0.8807], [0.0, 0.927, 0.073, 0.34], [0.01, 0.84, 0.15, 0.9974], [0.006, 0.905, 0.089, 0.9912], [0.0, 1.0, 0.0, 0.0], [0.064, 0.791, 0.145, 0.9987], [0.068, 0.903, 0.029, -0.8834], [0.019, 0.981, 0.0, -0.7088], [0.036, 0.964, 0.0, -0.9843], [0.077, 0.794, 0.129, 0.983], [0.026, 0.891, 0.083, 0.9881], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.887, 0.113, 0.9169], [0.006, 0.854, 0.14, 0.996], [0.0, 0.854, 0.146, 0.9455], [0.052, 0.835, 0.113, 0.9997], [0.052, 0.767, 0.181, 0.9893], [0.0, 0.93, 0.07, 0.4588], [0.006, 0.947, 0.046, 0.8934], [0.037, 0.833, 0.13, 0.9995], [0.032, 0.799, 0.169, 1.0], [0.016, 0.933, 0.051, 0.959], [0.034, 0.966, 0.0, -0.6808], [0.105, 0.895, 0.0, -0.9686], [0.016, 0.915, 0.069, 0.9988], [0.035, 0.864, 0.101, 0.9983], [0.024, 0.887, 0.089, 0.9969], [0.009, 0.991, 0.0, -0.6808], [0.017, 0.983, 0.0, -0.296], [0.019, 0.847, 0.135, 0.9983], [0.069, 0.779, 0.152, 0.997], [0.126, 0.766, 0.107, -0.9375], [0.009, 0.854, 0.137, 0.9995], [0.038, 0.866, 0.096, 0.9962], [0.031, 0.859, 0.111, 0.9926], [0.0, 0.994, 0.006, 0.4215], [0.021, 0.979, 0.0, -0.9081], [0.018, 0.976, 0.005, -0.9268], [0.008, 0.992, 0.0, -0.6808], [0.0, 0.804, 0.196, 0.9979], [0.012, 0.836, 0.152, 0.9902], [0.012, 0.988, 0.0, -0.4871], [0.0, 0.801, 0.199, 0.9042], [0.028, 0.845, 0.127, 0.9977], [0.086, 0.77, 0.144, 0.9997], [0.064, 0.936, 0.0, -0.824], [0.046, 0.937, 0.017, -0.8105], [0.039, 0.926, 0.035, -0.4596], [0.025, 0.86, 0.115, 0.9997], [0.012, 0.988, 0.0, -0.5267], [0.026, 0.898, 0.076, 0.9353], [0.029, 0.971, 0.0, -0.5707], [0.018, 0.968, 0.014, 0.2225], [0.072, 0.847, 0.082, 0.902], [0.12, 0.744, 0.136, 0.9289], [0.016, 0.984, 0.0, -0.1759], [0.066, 0.831, 0.102, 0.9812], [0.0, 0.83, 0.17, 0.9013], [0.042, 0.921, 0.038, 0.2023], [0.032, 0.965, 0.002, -0.9913], [0.021, 0.864, 0.115, 0.9975], [0.03, 0.964, 0.006, -0.8481], [0.031, 0.836, 0.133, 0.999], [0.0, 0.923, 0.077, 0.9694], [0.016, 0.887, 0.097, 0.9856], [0.059, 0.787, 0.154, 0.9988], [0.015, 0.976, 0.009, -0.2263], [0.047, 0.74, 0.213, 0.9996], [0.01, 0.99, 0.0, -0.3595], [0.014, 0.822, 0.163, 0.9993], [0.013, 0.836, 0.15, 0.9996], [0.04, 0.879, 0.082, 0.9996], [0.043, 0.745, 0.212, 1.0], [0.054, 0.85, 0.096, 0.9102], [0.016, 0.811, 0.173, 0.9994], [0.03, 0.97, 0.0, -0.6696], [0.025, 0.97, 0.005, -0.9724], [0.009, 0.972, 0.02, 0.3818], [0.028, 0.968, 0.004, -0.8823], [0.052, 0.846, 0.102, 0.9337], [0.059, 0.851, 0.09, 0.6003], [0.032, 0.968, 0.0, -0.5267], [0.081, 0.791, 0.128, 0.999], [0.03, 0.887, 0.083, 0.9231], [0.054, 0.828, 0.118, 0.9925], [0.019, 0.981, 0.0, -0.7906], [0.036, 0.964, 0.0, -0.9551], [0.0, 0.939, 0.061, 0.4767], [0.02, 0.967, 0.014, -0.801], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.022, 0.941, 0.037, 0.8702], [0.036, 0.875, 0.09, 0.9999], [0.04, 0.872, 0.088, 0.9828], [0.108, 0.711, 0.181, 0.8468], [0.063, 0.844, 0.092, 0.9872], [0.017, 0.855, 0.128, 0.9982], [0.003, 0.878, 0.119, 0.999], [0.054, 0.801, 0.145, 0.9991], [0.0, 0.9, 0.1, 0.6997], [0.076, 0.843, 0.081, 0.7051], [0.0, 1.0, 0.0, 0.0], [0.037, 0.946, 0.017, -0.6808], [0.099, 0.804, 0.098, -0.939], [0.029, 0.958, 0.013, -0.9254], [0.027, 0.973, 0.0, -0.7783], [0.0, 1.0, 0.0, 0.0], [0.033, 0.874, 0.093, 0.9973], [0.008, 0.992, 0.0, -0.1027], [0.054, 0.822, 0.124, 0.9977], [0.034, 0.878, 0.089, 0.993], [0.042, 0.848, 0.11, 0.6677], [0.0, 0.859, 0.141, 0.7096], [0.023, 0.96, 0.016, -0.5204], [0.074, 0.739, 0.187, 0.8779], [0.015, 0.856, 0.129, 0.9995], [0.038, 0.942, 0.019, -0.2732], [0.024, 0.858, 0.117, 0.9989], [0.016, 0.984, 0.0, -0.8821], [0.028, 0.969, 0.004, -0.9825], [0.005, 0.934, 0.061, 0.9894], [0.024, 0.882, 0.095, 0.9999], [0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.822, 0.178, 0.9673], [0.0, 1.0, 0.0, 0.0], [0.021, 0.964, 0.014, -0.5621], [0.046, 0.808, 0.146, 0.9997], [0.005, 0.912, 0.083, 0.988], [0.036, 0.964, 0.0, -0.7783], [0.057, 0.814, 0.13, 0.9979], [0.074, 0.746, 0.181, 0.9998], [0.056, 0.832, 0.112, 0.9946], [0.023, 0.927, 0.05, 0.6124], [0.036, 0.868, 0.095, 0.9998], [0.034, 0.842, 0.123, 0.9894], [0.03, 0.97, 0.0, -0.8619], [0.045, 0.946, 0.008, -0.8834], [0.075, 0.813, 0.111, 0.9973], [0.007, 0.948, 0.045, 0.9551], [0.02, 0.872, 0.108, 0.9993], [0.021, 0.971, 0.009, -0.8555], [0.028, 0.809, 0.162, 0.9995], [0.005, 0.844, 0.15, 0.9957], [0.003, 0.878, 0.119, 0.999], [0.062, 0.859, 0.08, 0.7879], [0.0, 1.0, 0.0, 0.0], [0.015, 0.881, 0.104, 0.9997], [0.031, 0.878, 0.091, 0.9944], [0.032, 0.968, 0.0, -0.9804], [0.093, 0.907, 0.0, -0.6808], [0.042, 0.817, 0.141, 0.9979], [0.032, 0.854, 0.114, 0.9992], [0.067, 0.773, 0.161, 0.9993], [0.028, 0.809, 0.162, 0.9995], [0.045, 0.942, 0.014, -0.8689], [0.021, 0.918, 0.061, 0.9516], [0.006, 0.863, 0.131, 0.9951], [0.031, 0.965, 0.004, -0.9246], [0.061, 0.939, 0.0, -0.7856], [0.005, 0.868, 0.127, 0.9981], [0.031, 0.887, 0.082, 0.9996], [0.019, 0.84, 0.141, 0.9868], [0.021, 0.843, 0.136, 0.9994], [0.023, 0.968, 0.009, -0.9353], [0.019, 0.906, 0.074, 0.9958], [0.012, 0.873, 0.114, 0.998], [0.031, 0.884, 0.085, 0.9776], [0.026, 0.858, 0.116, 0.9904], [0.025, 0.895, 0.08, 0.993], [0.0, 1.0, 0.0, 0.0], [0.021, 0.873, 0.106, 0.9821], [0.007, 0.906, 0.087, 0.9912], [0.018, 0.982, 0.0, -0.5267], [0.067, 0.86, 0.073, 0.6318], [0.022, 0.852, 0.126, 0.9831], [0.023, 0.784, 0.193, 0.9895], [0.006, 0.941, 0.053, 0.9018], [0.027, 0.844, 0.129, 0.9956], [0.031, 0.958, 0.011, -0.9681], [0.021, 0.974, 0.005, -0.7644], [0.026, 0.959, 0.015, -0.3818], [0.017, 0.781, 0.201, 0.9996], [0.0, 0.87, 0.13, 0.8126], [0.047, 0.895, 0.058, 0.7677], [0.025, 0.742, 0.233, 0.9996], [0.029, 0.836, 0.135, 0.9999], [0.016, 0.817, 0.167, 0.9989], [0.03, 0.832, 0.138, 0.9992], [0.038, 0.835, 0.127, 0.9989], [0.01, 0.904, 0.087, 0.9987], [0.011, 0.861, 0.128, 0.9988], [0.014, 0.863, 0.123, 0.9912], [0.014, 0.986, 0.0, -0.636], [0.007, 0.826, 0.167, 0.996], [0.0, 0.932, 0.068, 0.8885], [0.011, 0.818, 0.171, 0.9995], [0.024, 0.888, 0.087, 0.9709], [0.005, 0.833, 0.162, 0.9983], [0.023, 0.878, 0.099, 0.9971], [0.055, 0.848, 0.098, 0.9953], [0.046, 0.82, 0.134, 0.992], [0.084, 0.808, 0.109, 0.7681], [0.018, 0.773, 0.209, 1.0], [0.0, 0.856, 0.144, 0.836], [0.072, 0.774, 0.154, 0.9983], [0.011, 0.842, 0.146, 0.992], [0.011, 0.853, 0.136, 0.9928], [0.021, 0.979, 0.0, -0.8807], [0.015, 0.84, 0.145, 0.9994], [0.024, 0.973, 0.004, -0.9428], [0.081, 0.8, 0.119, 0.99], [0.07, 0.763, 0.167, 0.9999], [0.0, 0.898, 0.102, 0.7712], [0.024, 0.925, 0.051, 0.8294], [0.053, 0.931, 0.015, -0.8677], [0.018, 0.982, 0.0, -0.9517], [0.033, 0.912, 0.055, 0.9964], [0.012, 0.941, 0.047, 0.9071], [0.029, 0.806, 0.165, 0.9979], [0.0, 0.909, 0.091, 0.9815], [0.113, 0.756, 0.131, 0.9856], [0.016, 0.984, 0.0, -0.5267], [0.0, 0.942, 0.058, 0.3818], [0.022, 0.86, 0.118, 0.9996], [0.0, 0.718, 0.282, 0.9832], [0.054, 0.818, 0.128, 0.9997], [0.0, 1.0, 0.0, 0.0], [0.046, 0.823, 0.131, 0.9992], [0.076, 0.91, 0.014, -0.9258], [0.01, 0.917, 0.072, 0.9776], [0.009, 0.991, 0.0, -0.296], [0.07, 0.93, 0.0, -0.9081], [0.064, 0.823, 0.113, 0.9565], [0.0, 0.992, 0.008, 0.4215], [0.014, 0.747, 0.239, 0.9983], [0.075, 0.857, 0.068, 0.6368], [0.036, 0.958, 0.006, -0.9757], [0.004, 0.914, 0.082, 0.9974], [0.003, 0.83, 0.167, 0.999], [0.024, 0.849, 0.128, 0.9881], [0.079, 0.85, 0.07, -0.6803], [0.026, 0.884, 0.09, 0.9983], [0.06, 0.75, 0.19, 0.9996], [0.023, 0.896, 0.081, 0.9753], [0.069, 0.921, 0.01, -0.9501], [0.022, 0.899, 0.079, 0.9202], [0.045, 0.809, 0.145, 0.9986], [0.02, 0.839, 0.141, 0.9993], [0.035, 0.869, 0.096, 0.9998], [0.033, 0.808, 0.159, 0.9997], [0.035, 0.799, 0.166, 0.9994], [0.049, 0.842, 0.109, 0.9989], [0.021, 0.97, 0.009, -0.9512], [0.073, 0.758, 0.169, 0.9986], [0.059, 0.941, 0.0, -0.9771], [0.005, 0.902, 0.094, 0.9659], [0.026, 0.867, 0.106, 0.9993], [0.026, 0.867, 0.106, 0.9993], [0.037, 0.812, 0.151, 0.9988], [0.023, 0.973, 0.005, -0.8493], [0.027, 0.831, 0.142, 0.9936], [0.023, 0.834, 0.143, 0.9987], [0.031, 0.868, 0.1, 0.9964], [0.0, 0.889, 0.111, 0.7964], [0.0, 1.0, 0.0, 0.0], [0.01, 0.916, 0.073, 0.999], [0.026, 0.858, 0.116, 0.9995], [0.011, 0.98, 0.009, -0.2003], [0.0, 0.984, 0.016, 0.3612], [0.007, 0.905, 0.088, 0.9791], [0.025, 0.89, 0.085, 0.9962], [0.012, 0.982, 0.007, -0.2263], [0.0, 0.949, 0.051, 0.9568], [0.029, 0.885, 0.085, 0.9935], [0.045, 0.765, 0.189, 0.9998], [0.042, 0.801, 0.157, 0.9993], [0.024, 0.968, 0.007, -0.6369], [0.039, 0.957, 0.005, -0.9371], [0.014, 0.941, 0.045, 0.9873], [0.02, 0.933, 0.046, 0.8541], [0.041, 0.959, 0.0, -0.296], [0.0, 0.573, 0.427, 0.9801], [0.025, 0.916, 0.059, 0.8126], [0.029, 0.824, 0.147, 0.9962], [0.025, 0.82, 0.155, 0.999], [0.02, 0.973, 0.006, -0.9765], [0.019, 0.967, 0.013, -0.5191], [0.041, 0.801, 0.157, 0.9811], [0.038, 0.962, 0.0, -0.5267], [0.055, 0.832, 0.113, 0.9856], [0.038, 0.962, 0.0, -0.5267], [0.067, 0.885, 0.048, -0.8365], [0.0, 1.0, 0.0, 0.0], [0.014, 0.856, 0.13, 0.9996], [0.041, 0.876, 0.083, 0.9942], [0.022, 0.969, 0.01, -0.8105], [0.0, 0.917, 0.083, 0.6597], [0.041, 0.959, 0.0, -0.7269], [0.021, 0.979, 0.0, -0.6458], [0.029, 0.895, 0.076, 0.999], [0.015, 0.98, 0.005, -0.8271], [0.142, 0.769, 0.089, -0.9954], [0.022, 0.88, 0.099, 0.9723], [0.076, 0.818, 0.107, 0.9162], [0.023, 0.977, 0.0, -0.6808], [0.042, 0.955, 0.002, -0.9932], [0.01, 0.857, 0.133, 0.9994], [0.01, 0.905, 0.085, 0.9937], [0.026, 0.893, 0.081, 0.6124], [0.006, 0.936, 0.058, 0.9504], [0.055, 0.911, 0.034, -0.8642], [0.0, 0.878, 0.122, 0.993], [0.042, 0.834, 0.124, 0.998], [0.023, 0.891, 0.086, 0.9986], [0.0, 0.922, 0.078, 0.991], [0.0, 0.923, 0.077, 0.8074], [0.017, 0.851, 0.132, 0.9948], [0.009, 0.866, 0.125, 0.9999], [0.051, 0.844, 0.105, 0.9962], [0.0, 1.0, 0.0, 0.0], [0.005, 0.889, 0.106, 0.9983], [0.039, 0.811, 0.15, 0.991], [0.09, 0.855, 0.055, -0.9873], [0.0, 0.89, 0.11, 0.7096], [0.024, 0.892, 0.084, 0.9949], [0.0, 1.0, 0.0, 0.0], [0.04, 0.878, 0.082, 0.936], [0.021, 0.971, 0.009, -0.5053], [0.012, 0.978, 0.01, -0.2003], [0.012, 0.983, 0.006, -0.3736], [0.026, 0.862, 0.112, 0.9992], [0.025, 0.91, 0.065, 0.9886], [0.044, 0.89, 0.067, 0.9259], [0.0, 0.711, 0.289, 0.9643], [0.024, 0.915, 0.06, 0.952], [0.04, 0.814, 0.146, 0.9967], [0.009, 0.917, 0.074, 0.9915], [0.025, 0.864, 0.11, 0.9852], [0.059, 0.838, 0.103, 0.9877], [0.013, 0.875, 0.112, 0.9985], [0.051, 0.941, 0.009, -0.9246], [0.007, 0.976, 0.016, 0.4404], [0.005, 0.92, 0.074, 0.9816], [0.011, 0.956, 0.033, 0.9012], [0.011, 0.856, 0.133, 0.9977], [0.022, 0.877, 0.101, 0.9929], [0.024, 0.971, 0.006, -0.9883], [0.014, 0.901, 0.084, 0.9779], [0.01, 0.905, 0.085, 0.9607], [0.09, 0.689, 0.221, 0.8779], [0.05, 0.95, 0.0, -0.802], [0.02, 0.851, 0.13, 0.9923], [0.024, 0.971, 0.005, -0.7556], [0.043, 0.941, 0.017, -0.9216], [0.04, 0.771, 0.189, 0.9991], [0.024, 0.853, 0.123, 0.9972], [0.0, 1.0, 0.0, 0.0], [0.027, 0.872, 0.101, 0.9864], [0.002, 0.872, 0.126, 0.9992], [0.015, 0.981, 0.004, -0.9238], [0.05, 0.914, 0.036, -0.4915], [0.055, 0.842, 0.104, 0.991], [0.009, 0.894, 0.096, 0.995], [0.029, 0.825, 0.146, 0.9991], [0.007, 0.869, 0.124, 0.9914], [0.029, 0.877, 0.094, 0.9906], [0.073, 0.927, 0.0, -0.9705], [0.011, 0.86, 0.129, 0.9987], [0.069, 0.922, 0.009, -0.9042], [0.0, 0.886, 0.114, 0.7717], [0.024, 0.811, 0.165, 0.9998], [0.034, 0.847, 0.12, 0.9991], [0.042, 0.862, 0.096, 0.9872], [0.033, 0.879, 0.087, 0.9953], [0.0, 1.0, 0.0, 0.0], [0.026, 0.882, 0.091, 0.9977], [0.022, 0.888, 0.089, 0.9982], [0.087, 0.779, 0.134, 0.9962], [0.04, 0.847, 0.113, 0.9876], [0.018, 0.875, 0.107, 0.9982], [0.009, 0.983, 0.008, -0.368], [0.043, 0.825, 0.132, 0.9992], [0.089, 0.826, 0.085, -0.9022], [0.02, 0.856, 0.125, 0.9965], [0.008, 0.846, 0.146, 0.9919], [0.0, 0.898, 0.102, 0.9902], [0.004, 0.892, 0.104, 0.9878], [0.005, 0.975, 0.019, 0.6808], [0.049, 0.875, 0.076, 0.8689], [0.04, 0.87, 0.089, 0.9825], [0.042, 0.841, 0.117, 0.7003], [0.022, 0.886, 0.092, 0.9927], [0.019, 0.971, 0.01, -0.6189], [0.013, 0.832, 0.155, 0.9977], [0.005, 0.971, 0.024, 0.7464], [0.056, 0.807, 0.136, 0.9996], [0.026, 0.908, 0.066, 0.9799], [0.008, 0.918, 0.074, 0.9964], [0.027, 0.886, 0.087, 0.9967], [0.041, 0.813, 0.146, 0.9987], [0.032, 0.959, 0.009, -0.8955], [0.007, 0.835, 0.158, 0.9984], [0.036, 0.767, 0.198, 0.9966], [0.034, 0.835, 0.131, 0.9994], [0.007, 0.88, 0.113, 0.9971], [0.042, 0.769, 0.188, 0.9997], [0.054, 0.792, 0.154, 0.999], [0.024, 0.976, 0.0, -0.8807], [0.011, 0.925, 0.065, 0.9886], [0.054, 0.754, 0.192, 0.9998], [0.036, 0.896, 0.067, 0.3089], [0.031, 0.802, 0.167, 0.9993], [0.027, 0.877, 0.096, 0.9992], [0.019, 0.976, 0.005, -0.8814], [0.025, 0.975, 0.0, -0.9042], [0.01, 0.973, 0.017, 0.8343], [0.073, 0.927, 0.0, -0.7783], [0.047, 0.944, 0.009, -0.7269], [0.03, 0.815, 0.155, 1.0], [0.018, 0.9, 0.082, 0.9988], [0.046, 0.818, 0.136, 0.9999], [0.059, 0.931, 0.01, -0.9081], [0.011, 0.877, 0.112, 0.9949], [0.0, 0.888, 0.112, 0.9897], [0.031, 0.969, 0.0, -0.7783], [0.059, 0.811, 0.13, 0.9974], [0.07, 0.898, 0.032, -0.6597], [0.071, 0.816, 0.113, 0.9909], [0.045, 0.848, 0.107, 0.99], [0.042, 0.769, 0.188, 0.9997], [0.004, 0.832, 0.164, 0.9909], [0.01, 0.891, 0.099, 0.9827], [0.032, 0.963, 0.005, -0.893], [0.0, 0.945, 0.055, 0.9134], [0.0, 0.857, 0.143, 0.9217], [0.011, 0.985, 0.004, -0.4019], [0.006, 0.796, 0.198, 0.9991], [0.047, 0.811, 0.141, 0.9995], [0.016, 0.981, 0.004, -0.9626], [0.01, 0.834, 0.157, 0.994], [0.0, 0.807, 0.193, 0.9845], [0.018, 0.982, 0.0, -0.296], [0.024, 0.87, 0.106, 0.999], [0.021, 0.859, 0.12, 0.7003], [0.015, 0.855, 0.131, 0.9995], [0.019, 0.971, 0.01, -0.2732], [0.027, 0.968, 0.005, -0.9694], [0.019, 0.938, 0.043, 0.8674], [0.02, 0.923, 0.057, 0.8475], [0.036, 0.821, 0.143, 0.9996], [0.021, 0.88, 0.099, 0.9476], [0.0, 0.956, 0.044, 0.6688], [0.009, 0.824, 0.167, 0.9988], [0.051, 0.835, 0.114, 0.9983], [0.006, 0.938, 0.056, 0.97], [0.014, 0.873, 0.114, 0.9798], [0.025, 0.86, 0.115, 0.9829], [0.043, 0.728, 0.229, 0.9999], [0.048, 0.872, 0.08, 0.9826], [0.013, 0.983, 0.004, -0.6369], [0.018, 0.982, 0.0, -0.296], [0.03, 0.866, 0.104, 0.998], [0.069, 0.804, 0.127, 0.9989], [0.019, 0.972, 0.009, -0.8969], [0.013, 0.987, 0.0, -0.3736], [0.018, 0.906, 0.076, 0.9947], [0.047, 0.942, 0.011, -0.9186], [0.024, 0.972, 0.004, -0.8919], [0.012, 0.883, 0.105, 0.9989], [0.102, 0.752, 0.145, 0.9922], [0.051, 0.845, 0.104, 0.9971], [0.102, 0.789, 0.108, -0.5984], [0.01, 0.99, 0.0, -0.296], [0.008, 0.85, 0.143, 0.9756], [0.023, 0.923, 0.054, 0.872], [0.038, 0.962, 0.0, -0.6808], [0.013, 0.979, 0.009, -0.296], [0.008, 0.914, 0.078, 0.9607], [0.13, 0.792, 0.078, -0.9062], [0.016, 0.78, 0.204, 0.9995], [0.093, 0.816, 0.091, 0.1665], [0.026, 0.965, 0.009, -0.9159], [0.015, 0.84, 0.145, 0.9994], [0.041, 0.88, 0.079, 0.8053], [0.032, 0.786, 0.182, 0.9974], [0.024, 0.82, 0.156, 0.9973], [0.02, 0.927, 0.053, 0.9133], [0.011, 0.828, 0.161, 0.9972], [0.01, 0.849, 0.142, 0.9547], [0.016, 0.979, 0.005, -0.734], [0.058, 0.88, 0.063, 0.6428], [0.038, 0.844, 0.118, 0.9665], [0.141, 0.759, 0.1, -0.9875], [0.067, 0.82, 0.113, 0.9335], [0.0, 1.0, 0.0, 0.0], [0.052, 0.799, 0.149, 0.9957], [0.015, 0.879, 0.106, 0.9967], [0.09, 0.713, 0.197, 0.6486], [0.101, 0.849, 0.051, -0.9923], [0.022, 0.868, 0.11, 0.9989], [0.033, 0.778, 0.189, 0.9964], [0.069, 0.931, 0.0, -0.5267], [0.014, 0.949, 0.037, 0.6562], [0.07, 0.782, 0.148, 0.9732], [0.049, 0.82, 0.131, 0.9995], [0.037, 0.963, 0.0, -0.5267], [0.015, 0.859, 0.126, 0.9999], [0.036, 0.89, 0.074, 0.9922], [0.011, 0.989, 0.0, -0.296], [0.003, 0.849, 0.149, 0.9953], [0.074, 0.926, 0.0, -0.9657], [0.025, 0.975, 0.0, -0.9633], [0.013, 0.976, 0.01, 0.0], [0.011, 0.97, 0.02, 0.9916], [0.045, 0.854, 0.101, 0.9932], [0.0, 0.799, 0.201, 0.9022], [0.007, 0.878, 0.116, 0.9944], [0.015, 0.963, 0.023, 0.0516], [0.049, 0.815, 0.136, 0.9976], [0.045, 0.823, 0.132, 0.9985], [0.022, 0.915, 0.063, 0.5396], [0.058, 0.802, 0.14, 0.9962], [0.047, 0.794, 0.159, 0.9998], [0.007, 0.833, 0.159, 0.9999], [0.102, 0.789, 0.108, -0.5984], [0.031, 0.964, 0.006, -0.9574], [0.018, 0.982, 0.001, -0.9933], [0.0, 0.991, 0.009, 0.1779], [0.021, 0.811, 0.168, 0.9997], [0.076, 0.776, 0.147, 0.9977], [0.005, 0.906, 0.089, 0.9968], [0.016, 0.848, 0.136, 0.9392], [0.062, 0.938, 0.0, -0.5267], [0.0, 0.863, 0.137, 0.9952], [0.052, 0.93, 0.018, -0.9118], [0.013, 0.959, 0.028, 0.34], [0.016, 0.967, 0.017, 0.0258], [0.048, 0.818, 0.134, 0.9963], [0.005, 0.909, 0.086, 0.9934], [0.021, 0.979, 0.0, -0.9081], [0.008, 0.888, 0.104, 0.9919], [0.109, 0.777, 0.114, -0.6372], [0.009, 0.849, 0.142, 0.9867], [0.03, 0.757, 0.213, 0.9999], [0.026, 0.837, 0.137, 0.9996], [0.021, 0.972, 0.007, -0.982], [0.136, 0.764, 0.1, -0.9787], [0.015, 0.979, 0.006, -0.4767], [0.025, 0.908, 0.067, 0.9363], [0.0, 1.0, 0.0, 0.0], [0.022, 0.978, 0.0, -0.7088], [0.034, 0.966, 0.0, -0.9423], [0.053, 0.926, 0.021, -0.807], [0.027, 0.839, 0.134, 0.999], [0.035, 0.965, 0.0, -0.7783], [0.042, 0.86, 0.098, 0.9947], [0.045, 0.699, 0.256, 0.9959], [0.0, 1.0, 0.0, 0.0], [0.012, 0.988, 0.0, -0.296], [0.031, 0.959, 0.01, -0.9558], [0.046, 0.934, 0.02, -0.4215], [0.036, 0.863, 0.102, 0.999], [0.0, 1.0, 0.0, 0.0], [0.032, 0.968, 0.0, -0.296], [0.02, 0.98, 0.0, -0.6808], [0.077, 0.754, 0.169, 0.9978], [0.035, 0.87, 0.095, 0.9982], [0.043, 0.893, 0.064, 0.923], [0.014, 0.913, 0.073, 0.878], [0.023, 0.971, 0.005, -0.9268], [0.023, 0.77, 0.207, 0.9992], [0.006, 0.884, 0.11, 0.9928], [0.064, 0.936, 0.0, -0.7783], [0.0, 0.87, 0.13, 0.7845], [0.011, 0.911, 0.078, 0.9788], [0.028, 0.809, 0.163, 0.9997], [0.039, 0.778, 0.182, 0.9997], [0.009, 0.908, 0.084, 0.9825], [0.047, 0.821, 0.132, 0.9939], [0.029, 0.812, 0.158, 0.9995], [0.06, 0.934, 0.005, -0.9753], [0.009, 0.912, 0.078, 0.9611], [0.017, 0.924, 0.059, 0.9885], [0.014, 0.857, 0.129, 0.9978], [0.004, 0.942, 0.055, 0.9325], [0.019, 0.824, 0.157, 0.9991], [0.016, 0.979, 0.005, -0.7998], [0.011, 0.831, 0.158, 0.9997], [0.083, 0.811, 0.106, 0.9602], [0.039, 0.812, 0.149, 0.9994], [0.111, 0.773, 0.116, -0.6487], [0.029, 0.971, 0.0, -0.296], [0.007, 0.88, 0.113, 0.9995], [0.013, 0.922, 0.065, 0.9708], [0.0, 0.856, 0.144, 0.9517], [0.007, 0.825, 0.168, 0.9979], [0.05, 0.933, 0.017, -0.5994], [0.0, 1.0, 0.0, 0.0], [0.006, 0.994, 0.0, -0.296], [0.0, 0.978, 0.022, 0.7184], [0.024, 0.809, 0.167, 0.9995], [0.044, 0.837, 0.119, 0.9982], [0.032, 0.968, 0.0, -0.5267], [0.009, 0.865, 0.126, 0.9984], [0.013, 0.98, 0.008, -0.6292], [0.024, 0.958, 0.017, -0.128], [0.02, 0.972, 0.008, -0.6597], [0.01, 0.909, 0.081, 0.9906], [0.019, 0.898, 0.082, 0.9994], [0.01, 0.837, 0.153, 0.9999], [0.013, 0.814, 0.173, 0.9996], [0.02, 0.848, 0.131, 0.9994], [0.018, 0.969, 0.013, -0.1007], [0.008, 0.992, 0.0, -0.5803], [0.034, 0.966, 0.0, -0.6808], [0.035, 0.899, 0.067, 0.9957], [0.018, 0.982, 0.0, -0.3595], [0.019, 0.826, 0.154, 0.9997], [0.021, 0.958, 0.021, 0.6249], [0.02, 0.821, 0.158, 0.9999], [0.029, 0.947, 0.024, 0.4871], [0.036, 0.871, 0.093, 0.9917], [0.015, 0.974, 0.011, 0.0], [0.0, 0.869, 0.131, 0.8176], [0.041, 0.733, 0.226, 0.9983], [0.059, 0.803, 0.138, 0.9983], [0.008, 0.98, 0.012, 0.2732], [0.006, 0.903, 0.091, 0.989], [0.031, 0.822, 0.147, 0.9998], [0.042, 0.791, 0.167, 1.0], [0.028, 0.797, 0.174, 0.9985], [0.021, 0.837, 0.142, 1.0], [0.011, 0.986, 0.003, -0.6249], [0.029, 0.905, 0.066, 0.9902], [0.002, 0.985, 0.014, 0.9186], [0.035, 0.963, 0.002, -0.9598], [0.0, 1.0, 0.0, 0.0], [0.065, 0.848, 0.086, 0.7955], [0.036, 0.88, 0.084, 0.9952], [0.028, 0.972, 0.0, -0.6808], [0.029, 0.872, 0.099, 0.9987], [0.045, 0.951, 0.004, -0.9886], [0.065, 0.777, 0.158, 0.9994], [0.026, 0.87, 0.104, 0.9877], [0.019, 0.799, 0.181, 0.9999], [0.044, 0.817, 0.139, 0.9997], [0.014, 0.937, 0.049, 0.9937], [0.014, 0.845, 0.141, 0.9994], [0.0, 0.903, 0.097, 0.6597], [0.096, 0.839, 0.064, -0.2732], [0.031, 0.835, 0.133, 0.9905], [0.106, 0.76, 0.134, 0.9911], [0.048, 0.933, 0.018, -0.8611], [0.041, 0.959, 0.0, -0.4098], [0.022, 0.893, 0.085, 0.9898], [0.049, 0.789, 0.162, 0.9998], [0.016, 0.875, 0.108, 0.9949], [0.0, 0.963, 0.037, 0.3818], [0.014, 0.894, 0.093, 0.9999], [0.021, 0.869, 0.11, 0.9994], [0.017, 0.968, 0.015, 0.7477], [0.09, 0.807, 0.102, 0.8547], [0.023, 0.859, 0.118, 0.9981], [0.03, 0.854, 0.116, 0.9944], [0.021, 0.859, 0.12, 0.985], [0.0, 1.0, 0.0, 0.0], [0.024, 0.758, 0.219, 0.9996], [0.041, 0.959, 0.0, -0.8291], [0.031, 0.969, 0.0, -0.673], [0.011, 0.95, 0.039, 0.7345], [0.016, 0.975, 0.009, -0.3703], [0.013, 0.98, 0.007, -0.5719], [0.012, 0.871, 0.117, 0.9981], [0.03, 0.966, 0.004, -0.9186], [0.01, 0.864, 0.125, 0.9924], [0.071, 0.77, 0.159, 0.9998], [0.028, 0.881, 0.091, 0.9974], [0.027, 0.971, 0.001, -0.9795], [0.024, 0.814, 0.162, 0.999], [0.034, 0.803, 0.163, 0.9998], [0.029, 0.971, 0.0, -0.5267], [0.009, 0.933, 0.058, 0.9937], [0.027, 0.967, 0.006, -0.9317], [0.02, 0.969, 0.011, -0.2263], [0.011, 0.87, 0.119, 0.9957], [0.009, 0.883, 0.108, 0.9971], [0.002, 0.914, 0.084, 0.9943], [0.015, 0.925, 0.06, 0.9779], [0.055, 0.839, 0.106, 0.9978], [0.005, 0.986, 0.009, 0.4449], [0.05, 0.771, 0.179, 0.9886], [0.016, 0.814, 0.169, 0.9993], [0.031, 0.841, 0.128, 0.9996], [0.044, 0.847, 0.109, 0.9999], [0.056, 0.768, 0.176, 0.9984], [0.025, 0.969, 0.007, -0.9423], [0.017, 0.811, 0.172, 0.9998], [0.007, 0.859, 0.133, 0.9915], [0.011, 0.942, 0.047, 0.8172], [0.032, 0.961, 0.007, -0.9429], [0.026, 0.971, 0.003, -0.8762], [0.006, 0.876, 0.118, 0.9997], [0.028, 0.972, 0.0, -0.7088], [0.009, 0.838, 0.153, 0.998], [0.061, 0.935, 0.004, -0.997], [0.0, 0.869, 0.131, 0.9493], [0.024, 0.976, 0.0, -0.9081], [0.021, 0.979, 0.0, -0.9081], [0.039, 0.804, 0.158, 0.9999], [0.032, 0.968, 0.0, -0.9693], [0.076, 0.801, 0.123, 0.995], [0.019, 0.972, 0.009, -0.5255], [0.046, 0.949, 0.005, -0.9827], [0.0, 0.807, 0.193, 0.9984], [0.036, 0.813, 0.152, 0.9998], [0.056, 0.829, 0.114, 0.9719], [0.015, 0.875, 0.109, 0.9939], [0.035, 0.952, 0.013, -0.9528], [0.025, 0.868, 0.107, 0.9964], [0.008, 0.815, 0.177, 0.9996], [0.011, 0.915, 0.073, 0.9728], [0.058, 0.847, 0.095, 0.9966], [0.033, 0.841, 0.126, 0.9984], [0.027, 0.821, 0.152, 0.9992], [0.007, 0.806, 0.187, 0.9957], [0.013, 0.841, 0.145, 0.9943], [0.034, 0.966, 0.0, -0.296], [0.018, 0.838, 0.144, 0.9954], [0.028, 0.917, 0.055, 0.9604], [0.011, 0.89, 0.099, 0.9993], [0.045, 0.811, 0.144, 0.6486], [0.017, 0.983, 0.0, -0.5267], [0.02, 0.883, 0.096, 0.9965], [0.132, 0.799, 0.069, -0.9853], [0.002, 0.931, 0.067, 0.9975], [0.02, 0.975, 0.005, -0.6908], [0.009, 0.984, 0.006, -0.4404], [0.031, 0.969, 0.0, -0.5267], [0.038, 0.781, 0.181, 0.9999], [0.017, 0.973, 0.01, -0.4939], [0.037, 0.812, 0.152, 0.9998], [0.014, 0.834, 0.152, 0.9963], [0.0, 0.963, 0.037, 0.2023], [0.011, 0.901, 0.087, 0.9969], [0.012, 0.768, 0.22, 0.9849], [0.021, 0.979, 0.0, -0.7783], [0.021, 0.863, 0.115, 0.9757], [0.0, 0.764, 0.236, 0.946]]\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "# Content based recommender system where items are represented by vader sentiment analysis scores\n",
    "\n",
    "item_ids = articles['contentId'].tolist()\n",
    "item_representation_matrix = [list(vader.polarity_scores(row['title'] + \" \" + row['text']).values()) for _, row in articles.iterrows()]\n",
    "\n",
    "print(item_representation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_item_profile(item_id):\n",
    "    idx = item_ids.index(item_id)\n",
    "    item_profile = item_representation_matrix[idx]\n",
    "    return item_profile\n",
    "\n",
    "def get_item_profiles(ids):\n",
    "    item_profiles_list = [get_item_profile(x) for x in ids]\n",
    "    item_profiles = lil_matrix(item_profiles_list)\n",
    "    return item_profiles\n",
    "\n",
    "def build_users_profile(person_id, interactions_indexed_df):\n",
    "    interactions_person_df = interactions_indexed_df.loc[person_id]\n",
    "    user_item_profiles = get_item_profiles(interactions_person_df['contentId'])\n",
    "    \n",
    "    user_item_strengths = np.array(interactions_person_df['eventRating']).reshape(-1,1)\n",
    "    #Weighted average of item profiles by the interactions strength\n",
    "    user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\n",
    "    user_profile_norm = sklearn.preprocessing.normalize(np.asarray(user_item_strengths_weighted_avg))\n",
    "    return user_profile_norm\n",
    "\n",
    "def build_users_profiles(): \n",
    "    interactions_indexed_df = train_set[train_set['contentId'].isin(articles['contentId'])].set_index('personId')\n",
    "    user_profiles = {}\n",
    "    for person_id in interactions_indexed_df.index.unique():\n",
    "        user_profiles[person_id] = build_users_profile(person_id, interactions_indexed_df)\n",
    "    return user_profiles\n",
    "\n",
    "user_profiles = build_users_profiles()\n",
    "len(user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Content-Based'\n",
    "    \n",
    "    def __init__(self, items_df=None):\n",
    "        self.item_ids = item_ids\n",
    "        self.items_df = items_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\n",
    "        #Computes the cosine similarity between the user profile and all item profiles\n",
    "        cosine_similarities = cosine_similarity(user_profiles[person_id], item_representation_matrix)\n",
    "        #Gets the top similar items\n",
    "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
    "        #Sort the similar items by similarity\n",
    "        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_items\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        similar_items = self._get_similar_items_to_user_profile(user_id)\n",
    "        #Ignores items the user has already interacted\n",
    "        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['contentId', 'eventRating']).head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'contentId', \n",
    "                                                          right_on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "content_based_recommender_model = ContentBasedRecommender(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Based Filtering model 1: Recall_N:\n",
      "1355 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.022630480167014615, 'recall@10': 0.044926931106471814}\n",
      "Content-Based Filtering model 1: NDCG:\n",
      "1355 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'ndcg': 1.0, 'ndcg_comp': 0.46307337336062665}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_rand</th>\n",
       "      <th>comp_rand</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>_person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>258</td>\n",
       "      <td>3609194402293569455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>258</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>232</td>\n",
       "      <td>-1443636648652872475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>187</td>\n",
       "      <td>-2626634673110551643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>137</td>\n",
       "      <td>-3596626804281480007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>118</td>\n",
       "      <td>2416280733544962613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>117</td>\n",
       "      <td>3636910968448833585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>116</td>\n",
       "      <td>-2979881261169775358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>108</td>\n",
       "      <td>3302556033962996625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>103</td>\n",
       "      <td>-9016528795238256703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ndcg  ndcg_rand  comp_rand  interacted_count           _person_id\n",
       "0     1.0   0.536927   0.463073               258  3609194402293569455\n",
       "36    1.0   0.536927   0.463073               258 -1032019229384696495\n",
       "106   1.0   0.536927   0.463073               232 -1443636648652872475\n",
       "83    1.0   0.536927   0.463073               187 -2626634673110551643\n",
       "97    1.0   0.536927   0.463073               137 -3596626804281480007\n",
       "42    1.0   0.536927   0.463073               118  2416280733544962613\n",
       "60    1.0   0.536927   0.463073               117  3636910968448833585\n",
       "95    1.0   0.536927   0.463073               116 -2979881261169775358\n",
       "18    1.0   0.536927   0.463073               108  3302556033962996625\n",
       "2     1.0   0.536927   0.463073               103 -9016528795238256703"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Content-Based Filtering model 1: Recall_N:')\n",
    "pop_global_metrics, pop_detailed_results_df = recall_n_evaluator.evaluate_model(content_based_recommender_model)\n",
    "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\n",
    "pop_detailed_results_df.head(10)\n",
    "\n",
    "print('Content-Based Filtering model 1: NDCG:')\n",
    "pop_global_metrics, pop_detailed_results_df = recall_ndcg_evaluator.evaluate_model(content_based_recommender_model, k=5)\n",
    "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\n",
    "pop_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Based Filtering model 2: Recall_N:\n",
      "1355 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.019791231732776617, 'recall@10': 0.037828810020876825}\n",
      "Content-Based Filtering model 2: NDCG:\n",
      "1355 users processed\n",
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'ndcg': 1.0, 'ndcg_comp': 0.46307337336062665}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcg</th>\n",
       "      <th>ndcg_rand</th>\n",
       "      <th>comp_rand</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>_person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>258</td>\n",
       "      <td>3609194402293569455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>258</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>232</td>\n",
       "      <td>-1443636648652872475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>187</td>\n",
       "      <td>-2626634673110551643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>137</td>\n",
       "      <td>-3596626804281480007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>118</td>\n",
       "      <td>2416280733544962613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>117</td>\n",
       "      <td>3636910968448833585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>116</td>\n",
       "      <td>-2979881261169775358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>108</td>\n",
       "      <td>3302556033962996625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536927</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>103</td>\n",
       "      <td>-9016528795238256703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ndcg  ndcg_rand  comp_rand  interacted_count           _person_id\n",
       "0     1.0   0.536927   0.463073               258  3609194402293569455\n",
       "36    1.0   0.536927   0.463073               258 -1032019229384696495\n",
       "106   1.0   0.536927   0.463073               232 -1443636648652872475\n",
       "83    1.0   0.536927   0.463073               187 -2626634673110551643\n",
       "97    1.0   0.536927   0.463073               137 -3596626804281480007\n",
       "42    1.0   0.536927   0.463073               118  2416280733544962613\n",
       "60    1.0   0.536927   0.463073               117  3636910968448833585\n",
       "95    1.0   0.536927   0.463073               116 -2979881261169775358\n",
       "18    1.0   0.536927   0.463073               108  3302556033962996625\n",
       "2     1.0   0.536927   0.463073               103 -9016528795238256703"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8\n",
    "# Content based recommender system where items are represented by the vector:\n",
    "# [Positive Sentiment score, Negative Sentiment Score, Length of the message (in tokens), Ratio of stopwords/uncommon characters, Number of Personal Pronouns]\n",
    "\n",
    "personal_pronouns = [\"i\", \"me\", \"my\", \"mine\", \"you\", \"your\", \"yours\", \"he\", \"him\", \"his\", \"she\", \"her\", \"hers\", \"it\", \"its\", \"they\", \"them\", \"their\", \"theirs\", \"we\", \"us\", \"our\", \"ours\"]\n",
    "\n",
    "item_representation_matrix = []\n",
    "\n",
    "for index, row in articles.iterrows():\n",
    "\tfull_article = row['title'] + \" \" + row['text']\n",
    "\tscores = vader.polarity_scores(full_article)\n",
    "\ttokens = word_tokenize(full_article)\n",
    "\tstopwords_and_uncommon_chars = [token for token in tokens if token.lower() in stopwords_list or not token.isalpha()]\n",
    "\tnum_of_personal_pronouns = len([token for token in tokens if token.lower() in personal_pronouns])\n",
    "\t\n",
    "\titem_representation_matrix += [[scores['pos'], scores['neg'], len(tokens), len(stopwords_and_uncommon_chars) / len(tokens), num_of_personal_pronouns]]\n",
    "\n",
    "user_profiles = build_users_profiles()\n",
    "len(user_profiles)\n",
    "\n",
    "content_based_recommender_model = ContentBasedRecommender(articles)\n",
    "\n",
    "print('Content-Based Filtering model 2: Recall_N:')\n",
    "pop_global_metrics, pop_detailed_results_df = recall_n_evaluator.evaluate_model(content_based_recommender_model)\n",
    "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\n",
    "pop_detailed_results_df.head(10)\n",
    "\n",
    "print('Content-Based Filtering model 2: NDCG:')\n",
    "pop_global_metrics, pop_detailed_results_df = recall_ndcg_evaluator.evaluate_model(content_based_recommender_model, k=5)\n",
    "print('\\nGlobal metrics:\\n%s' % pop_global_metrics)\n",
    "pop_detailed_results_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
